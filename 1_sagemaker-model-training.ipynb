{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting (AAAI'21 Best Paper)\n",
    "--------------\n",
    "이 실습은 Informer의 original github 코드를 기반으로 SageMaker에서 학습하는 방법을 가이드하고자 만들었습니다. 모든 라이선스는 [여기](https://github.com/zhouhaoyi/Informer2020) 구현된 원본 소스코드의 라이선스 정책을 따르고 있으며, [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436) 논문에서 자세한 설명을 확인할 수 있습니다.\n",
    "\n",
    "<p align=\"center\">\n",
    "<center><img src=\"./img/informer.png\" height=\"90\" width=\"450\" alt=\"\"><center>\n",
    "<br><br>\n",
    "<b>Figure 1.</b> The architecture of Informer.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 패키지 설치 및 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (2.59.3)\n",
      "Collecting sagemaker[local]\n",
      "  Downloading sagemaker-2.60.0.tar.gz (444 kB)\n",
      "\u001b[K     |████████████████████████████████| 444 kB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (20.3.0)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.18.45)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.19.2)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.18.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (3.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (20.9)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.1.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25,!=1.25.1,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.26.6)\n",
      "Requirement already satisfied: docker-compose>=1.25.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: docker==5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.0.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (1.21.45)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker[local]) (2.8.1)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: cached-property<2,>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.5.1)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (1.6.0)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker-compose>=1.25.2->sagemaker[local]) (0.19.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from docker==5.0.0->sagemaker[local]) (2.7.2)\n",
      "Requirement already satisfied: six>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from dockerpty<1,>=0.4.1->docker-compose>=1.25.2->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker[local]) (3.10.0.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema<4,>=2.5.1->docker-compose>=1.25.2->sagemaker[local]) (0.17.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker[local]) (2.4.7)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.4.4)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker==5.0.0->sagemaker[local]) (2.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->sagemaker[local]) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker[local]) (2021.1)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.60.0-py2.py3-none-any.whl size=619337 sha256=837da1c488ca6b687d817606c8cf3929d629aa9a891f70d4264b29cc32d8f282\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/f4/cc/c5/9b8e770d5df966cb7b20b7db187bab42bcd95afe1615b97f28\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.59.3\n",
      "    Uninstalling sagemaker-2.59.3:\n",
      "      Successfully uninstalled sagemaker-2.59.3\n",
      "Successfully installed sagemaker-2.60.0\n",
      "Collecting sagemaker-experiments\n",
      "  Using cached sagemaker_experiments-0.1.35-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.18.45)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.21.45)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.27->sagemaker-experiments) (1.26.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.45->boto3>=1.16.27->sagemaker-experiments) (1.15.0)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.35\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (2.60.0)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (3.7.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (3.18.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (20.9)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.19.2)\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.18.45)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.45 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.21.45)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.22.0,>=1.21.45->boto3>=1.16.32->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Stopping docker: \u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "Starting docker:\t.\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U 'sagemaker[local]'\n",
    "    !{sys.executable} -m pip install -U sagemaker-experiments\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !/bin/bash ./local/local_mode_setup.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 설정\n",
    "\n",
    "Sagemaker 학습에 필요한 기본적인 package를 import 합니다. <br>\n",
    "[boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)는 AWS 리소스와 동작하는 python 클래스를 제공하며, HTTP API 호출을 숨기는 추상화 모델입니다. boto3를 통해 python에서 Amazon EC2 인스턴스, S3 버켓과 같은 AWS 리소스와 동작할 수 있습니다.<br>\n",
    "[sagemaker python sdk](https://sagemaker.readthedocs.io/en/stable/)는 Amazon SageMaker에서 기계 학습 모델을 교육 및 배포하기 위한 오픈 소스 라이브러리입니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "# import splitfolders\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import strftime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments 관리\n",
    "\n",
    "Amazon SageMaker에는 실험을 관리할 수 있는 [SageMaker Experiments](https://aws.amazon.com/ko/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings/) 서비스가 있습니다. 반복적인 실험에 대해 로깅을 남기기 위한 실험 이름 (create_experiment)과 trial (create_trial) 이름을 설정하는 함수입니다. <br> 이러한 메타 정보를 이용하여 향후 ML의 실험 관리가 용이해 질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[\n",
    "                                              {\n",
    "                                                  'Key': 'modelname',\n",
    "                                                  'Value': 'informer'\n",
    "                                              },\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, set_param, i_type, i_cnt, spot):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    \n",
    "    algo = 'dp'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_tag = 'test'\n",
    "    if i_type == 'ml.p3.16xlarge':\n",
    "        i_tag = 'p3'\n",
    "    elif i_type == 'ml.p3dn.24xlarge':\n",
    "        i_tag = 'p3dn'\n",
    "    elif i_type == 'ml.p4d.24xlarge':\n",
    "        i_tag = 'p4d'    \n",
    "        \n",
    "    trial = \"-\".join([i_tag,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 저장소와 학습 script 위치 설정\n",
    "SageMaker에는 학습에 사용할 데이터 위치와 학습 코드의 위치를 설정합니다. 편의를 위해 default_bucket을 사용했으나, 실제 활용 시에는 이미 생성한 bucket을 활용하는 것도 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-west-2-256572302554\n"
     ]
    }
   ],
   "source": [
    "prefix = 'ETDataset'\n",
    "\n",
    "sess = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3_data_path = f's3://{default_bucket}/{prefix}'\n",
    "source_dir = 'Informer2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 실험 데이터 가져오기\n",
    "\n",
    "논문에서 사용한 ETT 데이터셋은 [ETDataset](https://github.com/zhouhaoyi/ETDataset)에서 다운로드할 수 있습니다. ETT 데이터의 데모 형태는 아래 figure에서 볼 수 있으며, 각 데이터셋의 input은 zero-mean normalized가 되어 있습니다.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./img/data.png\" height = \"168\" alt=\"\" align=center />\n",
    "<br><br>\n",
    "<b>Figure 3.</b> An example of the ETT data.\n",
    "</p>\n",
    "데이터셋은 단기 주기적 패턴, 장기 주기적 패턴, 장기 추세 및 많은 불규칙한 패턴을 결합합니다. figure 3와 같이 전체적인 관점을 제시하며, 분명한 seasonal trend를 보여 줍니다. target은 'oil temperature'이며, 일부 단기적으로 국지적인 연속성을 유지합니다. 그러나 다른 변수(전력 부하)는 단기 일별 패턴(24시간마다)과 장기 주별 패턴(7일마다)을 표시합니다.\n",
    "\n",
    "첫 번째 row는 헤더 정보이며, \"날짜\", \"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\" 및 \"OT\"를 포함합니다. 각 열 이름의 세부 의미는 표 1에 나와 있습니다.\n",
    "</p>\n",
    "\n",
    "| Field | date | HUFL | HULL | MUFL | MULL | LUFL | LULL | OT |\n",
    "| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n",
    "| Description | The recorded **date** |**H**igh **U**se**F**ul **L**oad | **H**igh **U**se**L**ess **L**oad | **M**iddle **U**se**F**ul **L**oad | **M**iddle **U**se**L**ess **L**oad | **L**ow **U**se**F**ul **L**oad | **L**ow **U**se**L**ess **L**oad | **O**il **T**emperature (target) |\n",
    "\n",
    "<p align=\"center\"><b>Table 1.</b> Description for each columm.</p>\n",
    "아래는 AWS CLI 명령어를 활용하여 github에서 데이터셋을 받은 후 미리 지정한 S3 bucket으로 업로드를 하는 명령어 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ETDataset'...\n",
      "remote: Enumerating objects: 187, done.\u001b[K\n",
      "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
      "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
      "remote: Total 187 (delta 66), reused 13 (delta 2), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (187/187), 3.85 MiB | 13.20 MiB/s, done.\n",
      "Resolving deltas: 100% (66/66), done.\n",
      "upload: ETDataset/.git/HEAD to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/HEAD\n",
      "upload: ETDataset/.git/hooks/pre-applypatch.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/pre-applypatch.sample\n",
      "upload: ETDataset/.git/description to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/description\n",
      "upload: ETDataset/.git/hooks/post-update.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/post-update.sample\n",
      "upload: ETDataset/.git/hooks/pre-rebase.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/pre-rebase.sample\n",
      "upload: ETDataset/.git/hooks/applypatch-msg.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/applypatch-msg.sample\n",
      "upload: ETDataset/.git/hooks/commit-msg.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/commit-msg.sample\n",
      "upload: ETDataset/.git/logs/HEAD to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/logs/HEAD\n",
      "upload: ETDataset/.git/hooks/pre-receive.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/pre-receive.sample\n",
      "upload: ETDataset/.git/hooks/update.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/update.sample\n",
      "upload: ETDataset/.git/config to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/config\n",
      "upload: ETDataset/.git/index to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/index\n",
      "upload: ETDataset/.git/hooks/pre-commit.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/pre-commit.sample\n",
      "upload: ETDataset/.git/objects/pack/pack-f2d9b22a71c0db50c1999a6bdcda1378a640e0eb.idx to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/objects/pack/pack-f2d9b22a71c0db50c1999a6bdcda1378a640e0eb.idx\n",
      "upload: ETDataset/.git/hooks/pre-push.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/pre-push.sample\n",
      "upload: ETDataset/.git/hooks/prepare-commit-msg.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/prepare-commit-msg.sample\n",
      "upload: ETDataset/.git/logs/refs/heads/main to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/logs/refs/heads/main\n",
      "upload: ETDataset/.git/refs/heads/main to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/refs/heads/main\n",
      "upload: ETDataset/.git/hooks/fsmonitor-watchman.sample to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/hooks/fsmonitor-watchman.sample\n",
      "upload: ETDataset/.git/info/exclude to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/info/exclude\n",
      "upload: ETDataset/.git/refs/remotes/origin/HEAD to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/refs/remotes/origin/HEAD\n",
      "upload: ETDataset/.git/packed-refs to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/packed-refs\n",
      "upload: ETDataset/.git/logs/refs/remotes/origin/HEAD to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/logs/refs/remotes/origin/HEAD\n",
      "upload: ETDataset/README.md to s3://sagemaker-us-west-2-256572302554/ETDataset/README.md\n",
      "upload: ETDataset/README_CN.md to s3://sagemaker-us-west-2-256572302554/ETDataset/README_CN.md\n",
      "upload: ETDataset/LICENSE to s3://sagemaker-us-west-2-256572302554/ETDataset/LICENSE\n",
      "upload: ETDataset/img/ETT data demo.png to s3://sagemaker-us-west-2-256572302554/ETDataset/img/ETT data demo.png\n",
      "upload: ETDataset/img/appendix_auto_correlation.png to s3://sagemaker-us-west-2-256572302554/ETDataset/img/appendix_auto_correlation.png\n",
      "upload: ETDataset/ETT-small/ETTh2.csv to s3://sagemaker-us-west-2-256572302554/ETDataset/ETT-small/ETTh2.csv\n",
      "upload: ETDataset/.git/objects/pack/pack-f2d9b22a71c0db50c1999a6bdcda1378a640e0eb.pack to s3://sagemaker-us-west-2-256572302554/ETDataset/.git/objects/pack/pack-f2d9b22a71c0db50c1999a6bdcda1378a640e0eb.pack\n",
      "upload: ETDataset/ETT-small/ETTh1.csv to s3://sagemaker-us-west-2-256572302554/ETDataset/ETT-small/ETTh1.csv\n",
      "upload: ETDataset/img/appendix_dataset_year.png to s3://sagemaker-us-west-2-256572302554/ETDataset/img/appendix_dataset_year.png\n",
      "upload: ETDataset/ETT-small/ETTm2.csv to s3://sagemaker-us-west-2-256572302554/ETDataset/ETT-small/ETTm2.csv\n",
      "upload: ETDataset/ETT-small/ETTm1.csv to s3://sagemaker-us-west-2-256572302554/ETDataset/ETT-small/ETTm1.csv\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(prefix):\n",
    "    !git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "        \n",
    "!aws s3 sync ./ETDataset/ s3://{default_bucket}/{prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 실험 설정\n",
    "\n",
    "학습 시 사용한 소스코드와 output 정보를 저장할 위치를 선정합니다. 이 값은 필수로 설정하지 않아도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_location = f's3://{default_bucket}/sm_codes'\n",
    "output_path = f's3://{default_bucket}/poc_informer/output' \n",
    "checkpoint_s3_bucket = f's3://{default_bucket}/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험에서 표준 출력으로 보여지는 metrics 값을 정규 표현식을 이용하여 SageMaker에서 값을 capture할 수 있습니다. 이 값은 필수로 설정하지 않아도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'Epoch', 'Regex': 'Epoch: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "    {'Name': 'train_loss', 'Regex': 'Train Loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "    {'Name': 'valid_loss', 'Regex': 'Valid Loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "    {'Name': 'test_loss', 'Regex': 'Test Loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 실험 조건을 테스트하기 위해 hyperparameters로 argument 값들을 노트북에서 설정할 수 있으며, 이 값은 학습 스크립트에서 argument인 변수로 받아서 활용이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'model' : 'informer', # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "        'data' : 'ETTh1', # data\n",
    "        'root_path' : 'ETT-small/', # root path of data file\n",
    "        'data_path' : 'ETTh1.csv', # data file\n",
    "        'features' : 'M', # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "        'target' : 'OT', # target feature in S or MS task\n",
    "        'freq' : 'h', # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "        'checkpoints' : 'informer_checkpoints', # location of model checkpoints\n",
    "\n",
    "        'seq_len' : 96, # input sequence length of Informer encoder\n",
    "        'label_len' : 48, # start token length of Informer decoder\n",
    "        'pred_len' : 24, # prediction sequence length\n",
    "        # Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "        'enc_in' : 7, # encoder input size\n",
    "        'dec_in' : 7, # decoder input size\n",
    "        'c_out' : 7, # output size\n",
    "        'factor' : 5, # probsparse attn factor\n",
    "        'd_model' : 512, # dimension of model\n",
    "        'n_heads' : 8, # num of heads\n",
    "        'e_layers' : 2, # num of encoder layers\n",
    "        'd_layers' : 1, # num of decoder layers\n",
    "        'd_ff' : 2048, # dimension of fcn in model\n",
    "        'dropout' : 0.05, # dropout\n",
    "        'attn' : 'prob', # attention used in encoder, options:[prob, full]\n",
    "        'embed' : 'timeF', # time features encoding, options:[timeF, fixed, learned]\n",
    "        'activation' : 'gelu', # activation\n",
    "        'distil' : True, # whether to use distilling in encoder\n",
    "        'output_attention' : False, # whether to output attention in ecoder\n",
    "        'mix' : True,\n",
    "        'padding' : 0,\n",
    "        'freq' : 'h',\n",
    "        'do_predict' : True,\n",
    "        'batch_size' : 32,\n",
    "        'learning_rate' : 0.0001,\n",
    "        'loss' : 'mse',\n",
    "        'lradj' : 'type1',\n",
    "        'use_amp' : False, # whether to use automatic mixed precision training\n",
    "\n",
    "        'num_workers' : 0,\n",
    "        'itr' : 1,\n",
    "        'train_epochs' : 1,  ## Training epochs\n",
    "        'patience' : 3,\n",
    "        'des' : 'exp',\n",
    "        'use_multi_gpu' : True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산학습과 spot 학습을 사용할지를 선정할 수 있습니다. <br>\n",
    "분산학습의 경우 [SageMaker data parallel library](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)를 사용하고자 할 경우 distribution을 아래와 같이 설정한 후 사용할 수 있습니다. (학습 스크립트 일부 수정 필요) <br>\n",
    "[spot 학습](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)을 사용하고자 할 경우 학습 파라미터에 spot 파라미터를 True로 변경한 다음, 자원이 없을 때 대기하는 시간인 max_wait (초)를 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'informer-poc-exp1'\n",
    "# instance_type = 'ml.p3.16xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "# instance_type = 'local_gpu'\n",
    "instance_type = 'ml.c5.4xlarge'\n",
    "instance_count = 1\n",
    "do_spot_training = True\n",
    "max_wait = None\n",
    "max_run = 3*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_job_name : informer-dist \n",
      "train_instance_type : ml.p3.16xlarge \n",
      "train_instance_count : 1 \n",
      "image_uri : None \n",
      "distribution : {'smdistributed': {'dataparallel': {'enabled': True}}}\n"
     ]
    }
   ],
   "source": [
    "image_uri = None\n",
    "train_job_name = 'sagemaker'\n",
    "\n",
    "\n",
    "train_job_name = 'informer-dist'\n",
    "distribution = {}\n",
    "\n",
    "if instance_type in ['ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu']:\n",
    "    distribution[\"smdistributed\"]={ \n",
    "                        \"dataparallel\": {\n",
    "                            \"enabled\": True\n",
    "                        }\n",
    "                }\n",
    "else:\n",
    "    distribution = None\n",
    "\n",
    "if do_spot_training:\n",
    "    max_wait = max_run\n",
    "\n",
    "print(\"train_job_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {} \\nimage_uri : {} \\ndistribution : {}\".format(train_job_name, instance_type, instance_count, image_uri, distribution))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "    from pathlib import Path\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_data_path = 'file:///home/ec2-user/SageMaker/timeseries_practise/ETDataset/'\n",
    "    source_dir = f'{Path.cwd()}/Informer2020'\n",
    "    do_spot_training = False\n",
    "    checkpoint_s3_bucket=None\n",
    "    max_wait = None\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "\n",
    "    s3_data_path = f's3://{default_bucket}/{prefix}'\n",
    "    source_dir = 'Informer2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습을 위한 Estimator 선언\n",
    "\n",
    "AWS 서비스 활용 시 role (역할) 설정은 매우 중요합니다. 이 노트북에서 사용하는 role은 노트북과 training job을 실행할 때 사용하는 role이며, role을 이용하여 다양한 AWS 서비스에 대한 접근 권한을 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::256572302554:role/TeamRole'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='main_informer.py',\n",
    "    source_dir=source_dir,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py36',\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=256,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_run=max_run,\n",
    "    checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "    use_spot_instances=do_spot_training,  # spot instance 활용\n",
    "    max_wait=max_wait\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 학습 수행 - 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: informer-poc-exp1-p3-1-dp-s-1011-04501633927859\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, hyperparameters, instance_type, instance_count, do_spot_training)\n",
    "\n",
    "# Now associate the estimator with the Experiment and Trial\n",
    "estimator.fit(\n",
    "    inputs={'training': s3_data_path}, \n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 명령어를 이용하여 시작된 학습에 대한 로그를 노트북에서 확인합니다. 이 로그는 CloudWatch에서도 확인이 가능합니다. <br> \n",
    "아래 명령어를 실행해도 학습이 시작되는 것이 아니며, 실행된 training job의 로그만 보는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-11 04:51:01 Starting - Launching requested ML instances...ProfilerReport-1633927859: InProgress\n",
      ".........\n",
      "2021-10-11 04:52:43 Starting - Preparing the instances for training............\n",
      "2021-10-11 04:54:58 Downloading - Downloading input data\n",
      "2021-10-11 04:54:58 Training - Downloading the training image..................\n",
      "2021-10-11 04:57:56 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-10-11 04:57:57,234 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-10-11 04:57:57,312 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:00,337 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:00,337 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:00,750 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,037 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,038 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,041 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,042 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,042 sagemaker-training-toolkit INFO     Host: ['algo-1']\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,043 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2021-10-11 04:58:03,121 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"attn\": \"prob\",\n",
      "        \"label_len\": 48,\n",
      "        \"data\": \"ETTh1\",\n",
      "        \"train_epochs\": 30,\n",
      "        \"lradj\": \"type1\",\n",
      "        \"freq\": \"h\",\n",
      "        \"do_predict\": true,\n",
      "        \"num_workers\": 0,\n",
      "        \"data_path\": \"ETTh1.csv\",\n",
      "        \"features\": \"M\",\n",
      "        \"loss\": \"mse\",\n",
      "        \"use_multi_gpu\": true,\n",
      "        \"des\": \"exp\",\n",
      "        \"d_ff\": 2048,\n",
      "        \"patience\": 3,\n",
      "        \"model\": \"informer\",\n",
      "        \"embed\": \"timeF\",\n",
      "        \"factor\": 5,\n",
      "        \"mix\": true,\n",
      "        \"seq_len\": 96,\n",
      "        \"dec_in\": 7,\n",
      "        \"padding\": 0,\n",
      "        \"batch_size\": 32,\n",
      "        \"itr\": 1,\n",
      "        \"pred_len\": 24,\n",
      "        \"checkpoints\": \"informer_checkpoints\",\n",
      "        \"distil\": true,\n",
      "        \"c_out\": 7,\n",
      "        \"target\": \"OT\",\n",
      "        \"n_heads\": 8,\n",
      "        \"d_model\": 512,\n",
      "        \"output_attention\": false,\n",
      "        \"root_path\": \"ETT-small/\",\n",
      "        \"dropout\": 0.05,\n",
      "        \"activation\": \"gelu\",\n",
      "        \"enc_in\": 7,\n",
      "        \"d_layers\": 1,\n",
      "        \"e_layers\": 2,\n",
      "        \"learning_rate\": 0.0001,\n",
      "        \"use_amp\": false\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"informer-poc-exp1-p3-1-dp-s-1011-04501633927859\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-256572302554/sm_codes/informer-poc-exp1-p3-1-dp-s-1011-04501633927859/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main_informer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main_informer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"activation\":\"gelu\",\"attn\":\"prob\",\"batch_size\":32,\"c_out\":7,\"checkpoints\":\"informer_checkpoints\",\"d_ff\":2048,\"d_layers\":1,\"d_model\":512,\"data\":\"ETTh1\",\"data_path\":\"ETTh1.csv\",\"dec_in\":7,\"des\":\"exp\",\"distil\":true,\"do_predict\":true,\"dropout\":0.05,\"e_layers\":2,\"embed\":\"timeF\",\"enc_in\":7,\"factor\":5,\"features\":\"M\",\"freq\":\"h\",\"itr\":1,\"label_len\":48,\"learning_rate\":0.0001,\"loss\":\"mse\",\"lradj\":\"type1\",\"mix\":true,\"model\":\"informer\",\"n_heads\":8,\"num_workers\":0,\"output_attention\":false,\"padding\":0,\"patience\":3,\"pred_len\":24,\"root_path\":\"ETT-small/\",\"seq_len\":96,\"target\":\"OT\",\"train_epochs\":30,\"use_amp\":false,\"use_multi_gpu\":true}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main_informer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main_informer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-256572302554/sm_codes/informer-poc-exp1-p3-1-dp-s-1011-04501633927859/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"activation\":\"gelu\",\"attn\":\"prob\",\"batch_size\":32,\"c_out\":7,\"checkpoints\":\"informer_checkpoints\",\"d_ff\":2048,\"d_layers\":1,\"d_model\":512,\"data\":\"ETTh1\",\"data_path\":\"ETTh1.csv\",\"dec_in\":7,\"des\":\"exp\",\"distil\":true,\"do_predict\":true,\"dropout\":0.05,\"e_layers\":2,\"embed\":\"timeF\",\"enc_in\":7,\"factor\":5,\"features\":\"M\",\"freq\":\"h\",\"itr\":1,\"label_len\":48,\"learning_rate\":0.0001,\"loss\":\"mse\",\"lradj\":\"type1\",\"mix\":true,\"model\":\"informer\",\"n_heads\":8,\"num_workers\":0,\"output_attention\":false,\"padding\":0,\"patience\":3,\"pred_len\":24,\"root_path\":\"ETT-small/\",\"seq_len\":96,\"target\":\"OT\",\"train_epochs\":30,\"use_amp\":false,\"use_multi_gpu\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"informer-poc-exp1-p3-1-dp-s-1011-04501633927859\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-256572302554/sm_codes/informer-poc-exp1-p3-1-dp-s-1011-04501633927859/source/sourcedir.tar.gz\",\"module_name\":\"main_informer\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main_informer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--activation\",\"gelu\",\"--attn\",\"prob\",\"--batch_size\",\"32\",\"--c_out\",\"7\",\"--checkpoints\",\"informer_checkpoints\",\"--d_ff\",\"2048\",\"--d_layers\",\"1\",\"--d_model\",\"512\",\"--data\",\"ETTh1\",\"--data_path\",\"ETTh1.csv\",\"--dec_in\",\"7\",\"--des\",\"exp\",\"--distil\",\"True\",\"--do_predict\",\"True\",\"--dropout\",\"0.05\",\"--e_layers\",\"2\",\"--embed\",\"timeF\",\"--enc_in\",\"7\",\"--factor\",\"5\",\"--features\",\"M\",\"--freq\",\"h\",\"--itr\",\"1\",\"--label_len\",\"48\",\"--learning_rate\",\"0.0001\",\"--loss\",\"mse\",\"--lradj\",\"type1\",\"--mix\",\"True\",\"--model\",\"informer\",\"--n_heads\",\"8\",\"--num_workers\",\"0\",\"--output_attention\",\"False\",\"--padding\",\"0\",\"--patience\",\"3\",\"--pred_len\",\"24\",\"--root_path\",\"ETT-small/\",\"--seq_len\",\"96\",\"--target\",\"OT\",\"--train_epochs\",\"30\",\"--use_amp\",\"False\",\"--use_multi_gpu\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_ATTN=prob\u001b[0m\n",
      "\u001b[34mSM_HP_LABEL_LEN=48\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=ETTh1\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_EPOCHS=30\u001b[0m\n",
      "\u001b[34mSM_HP_LRADJ=type1\u001b[0m\n",
      "\u001b[34mSM_HP_FREQ=h\u001b[0m\n",
      "\u001b[34mSM_HP_DO_PREDICT=true\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_WORKERS=0\u001b[0m\n",
      "\u001b[34mSM_HP_DATA_PATH=ETTh1.csv\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=M\u001b[0m\n",
      "\u001b[34mSM_HP_LOSS=mse\u001b[0m\n",
      "\u001b[34mSM_HP_USE_MULTI_GPU=true\u001b[0m\n",
      "\u001b[34mSM_HP_DES=exp\u001b[0m\n",
      "\u001b[34mSM_HP_D_FF=2048\u001b[0m\n",
      "\u001b[34mSM_HP_PATIENCE=3\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=informer\u001b[0m\n",
      "\u001b[34mSM_HP_EMBED=timeF\u001b[0m\n",
      "\u001b[34mSM_HP_FACTOR=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIX=true\u001b[0m\n",
      "\u001b[34mSM_HP_SEQ_LEN=96\u001b[0m\n",
      "\u001b[34mSM_HP_DEC_IN=7\u001b[0m\n",
      "\u001b[34mSM_HP_PADDING=0\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_ITR=1\u001b[0m\n",
      "\u001b[34mSM_HP_PRED_LEN=24\u001b[0m\n",
      "\u001b[34mSM_HP_CHECKPOINTS=informer_checkpoints\u001b[0m\n",
      "\u001b[34mSM_HP_DISTIL=true\u001b[0m\n",
      "\u001b[34mSM_HP_C_OUT=7\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=OT\u001b[0m\n",
      "\u001b[34mSM_HP_N_HEADS=8\u001b[0m\n",
      "\u001b[34mSM_HP_D_MODEL=512\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_ATTENTION=false\u001b[0m\n",
      "\u001b[34mSM_HP_ROOT_PATH=ETT-small/\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.05\u001b[0m\n",
      "\u001b[34mSM_HP_ACTIVATION=gelu\u001b[0m\n",
      "\u001b[34mSM_HP_ENC_IN=7\u001b[0m\n",
      "\u001b[34mSM_HP_D_LAYERS=1\u001b[0m\n",
      "\u001b[34mSM_HP_E_LAYERS=2\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_USE_AMP=false\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so smddprun /opt/conda/bin/python3.6 -m mpi4py main_informer.py --activation gelu --attn prob --batch_size 32 --c_out 7 --checkpoints informer_checkpoints --d_ff 2048 --d_layers 1 --d_model 512 --data ETTh1 --data_path ETTh1.csv --dec_in 7 --des exp --distil True --do_predict True --dropout 0.05 --e_layers 2 --embed timeF --enc_in 7 --factor 5 --features M --freq h --itr 1 --label_len 48 --learning_rate 0.0001 --loss mse --lradj type1 --mix True --model informer --n_heads 8 --num_workers 0 --output_attention False --padding 0 --patience 3 --pred_len 24 --root_path ETT-small/ --seq_len 96 --target OT --train_epochs 30 --use_amp False --use_multi_gpu True\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.177.25<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO comm 0x55d756955ac0 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO comm 0x55fd4d668a80 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO comm 0x5558255fa060 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO comm 0x55e172acad00 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO comm 0x5601a76755d0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO comm 0x55562ebebc90 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO comm 0x564c56d5e030 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO comm 0x561e6e974980 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO comm 0x55d759622810 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:75 [0] NCCL INFO comm 0x55fd503357d0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:48:48 [2] NCCL INFO comm 0x5558282c6db0 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:50:50 [3] NCCL INFO comm 0x55e175797a50 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:52:52 [4] NCCL INFO comm 0x5601aa342320 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO comm 0x561e716416d0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO comm 0x564c59a2ad80 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO comm 0x5556318b89e0 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Running smdistributed.dataparallel v1.2.0\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:args.local_rank : 7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:args.local_rank : 0\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:args.local_rank : 4\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:args.local_rank : 2\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:args.local_rank : 5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=0, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=0, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=7, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=7, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=4, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=4, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:args.local_rank : 3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:args.local_rank : 6\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=2, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=2, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=5, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=5, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:os.environ.get('SM_CHANNEL_TRAINING') : /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:os.environ['SM_MODEL_DIR'] : /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:os.environ['SM_NUM_GPUS'] : 8\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:json.loads(os.environ['SM_HOSTS']) : ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>: os.environ['SM_CURRENT_HOST'] : algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:args.local_rank : 1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=3, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=3, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=6, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=6, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Args in experiment:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Namespace(activation='gelu', attn='prob', batch_size=4, c_out=7, checkpoints='/opt/ml/model', cols=None, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='exp', detail_freq='h', device=device(type='cuda'), distil=False, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, inverse=False, itr=1, label_len=48, learning_rate=0.0001, local_rank=1, loss='mse', lradj='type1', mix=False, model='informer', n_heads=8, num_workers=0, output_attention=False, padding=0, patience=3, pred_len=24, rank=1, root_path='/opt/ml/input/data/training/ETT-small/', s_layers=[3, 2, 1], seq_len=96, target='OT', train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=True, world_size=8)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:75:696 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:>>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:train 8521\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:val 2857\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.232 algo-1:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.232 algo-1:75 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.233 algo-1:52 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.233 algo-1:55 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.265 algo-1:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.265 algo-1:53 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.266 algo-1:50 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.268 algo-1:54 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.350 algo-1:45 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.350 algo-1:55 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.350 algo-1:75 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.350 algo-1:52 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.350 algo-1:53 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.350 algo-1:50 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.350 algo-1:48 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.350 algo-1:54 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.351 algo-1:48 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.350 algo-1:45 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.351 algo-1:75 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.351 algo-1:53 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.351 algo-1:50 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.350 algo-1:54 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.351 algo-1:52 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.351 algo-1:55 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.351 algo-1:48 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.351 algo-1:45 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.351 algo-1:54 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.351 algo-1:75 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.351 algo-1:50 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.351 algo-1:53 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.351 algo-1:52 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.351 algo-1:55 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.352 algo-1:75 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.352 algo-1:54 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.352 algo-1:50 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.352 algo-1:48 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.352 algo-1:45 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.352 algo-1:53 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.352 algo-1:52 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.352 algo-1:55 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.508 algo-1:55 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.508 algo-1:55 INFO hook.py:591] name:module.enc_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.508 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.508 algo-1:55 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.508 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.508 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.508 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.508 algo-1:55 INFO hook.py:591] name:module.enc_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.508 algo-1:75 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.508 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.508 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.weight count_params:10752\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.dec_embedding.value_embedding.tokenConv.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.dec_embedding.temporal_embedding.embed.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.509 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.509 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.509 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.509 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.509 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.509 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.509 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.509 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.510 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.510 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.510 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.510 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.510 algo-1:48 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.510 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.510 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.510 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.attn_layers.1.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.encoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-10-11 04:58:15.511 algo-1:54 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.511 algo-1:53 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.511 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.511 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.511 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.511 algo-1:50 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-10-11 04:58:15.511 algo-1:45 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-10-11 04:58:15.512 algo-1:53 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.511 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-10-11 04:58:15.512 algo-1:50 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.self_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.query_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.key_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-10-11 04:58:15.512 algo-1:75 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.value_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.cross_attention.out_projection.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.512 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.512 algo-1:48 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.512 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.513 algo-1:48 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.conv1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.513 algo-1:48 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.conv2.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.513 algo-1:48 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.conv2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-10-11 04:58:15.513 algo-1:48 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.norm1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.norm1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-10-11 04:58:15.513 algo-1:55 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.norm2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.norm2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.norm3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.layers.0.norm3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.decoder.norm.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.projection.weight count_params:3584\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:591] name:module.projection.bias count_params:7\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.513 algo-1:52 INFO hook.py:593] Total Trainable Params: 10542087\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-10-11 04:58:15.514 algo-1:52 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 1 | loss: 0.6570933\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.1540s/iter; left time: 1213.2839s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 1 | loss: 0.4946429\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.1539s/iter; left time: 1213.1189s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 1 | loss: 0.4603826\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.1540s/iter; left time: 1213.6732s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 1 | loss: 0.6423901\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.1539s/iter; left time: 1213.1496s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 1 | loss: 0.5651056\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.1540s/iter; left time: 1213.3877s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 1 | loss: 0.2501343\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.1540s/iter; left time: 1213.4358s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 1 | loss: 0.3963644\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.1540s/iter; left time: 1213.4474s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 1 | loss: 0.7534978\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.1540s/iter; left time: 1213.4542s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 1 | loss: 0.3901394\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0554s/iter; left time: 431.2100s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 1 | loss: 0.4272603\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0554s/iter; left time: 431.2923s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 1 | loss: 0.2502193\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0554s/iter; left time: 431.4340s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 1 | loss: 0.4812543\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0555s/iter; left time: 431.4677s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 1 | loss: 0.3133632\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0554s/iter; left time: 431.3617s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 1 | loss: 0.3905171\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0554s/iter; left time: 431.4514s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 1 | loss: 0.4832999\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0554s/iter; left time: 431.3364s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 1 | loss: 0.3707128\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0554s/iter; left time: 431.4204s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 1 cost time: 24.927814722061157\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 1 cost time: 24.925410747528076\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 1 cost time: 24.932629346847534\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 1 cost time: 24.928243398666382\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 1 cost time: 24.928266763687134\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 1 cost time: 24.929131984710693\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 1 cost time: 24.933276653289795\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 1 cost time: 24.936282634735107\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4674417, Valid Loss: 0.9966353, Test Loss: 0.7994354,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation loss decreased (inf --> 0.996635).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4737742, Valid Loss: 0.9970868, Test Loss: 0.7990001,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation loss decreased (inf --> 0.997087).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4839248, Valid Loss: 0.9966977, Test Loss: 0.7987869,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation loss decreased (inf --> 0.996698).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4719268, Valid Loss: 0.9964529, Test Loss: 0.7991788,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation loss decreased (inf --> 0.996453).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4646799, Valid Loss: 0.9967515, Test Loss: 0.7996446,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation loss decreased (inf --> 0.996751).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4854621, Valid Loss: 0.9967089, Test Loss: 0.7990081,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation loss decreased (inf --> 0.996709).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4666430, Valid Loss: 0.9965463, Test Loss: 0.7989758,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation loss decreased (inf --> 0.996546).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 1, Steps: 266 | Train Loss: 0.4776236, Valid Loss: 0.9964682, Test Loss: 0.7987433,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation loss decreased (inf --> 0.996468).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 0.0001\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 2 | loss: 0.4437069\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3439s/iter; left time: 2619.1016s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 2 | loss: 0.5897316\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3440s/iter; left time: 2619.2492s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 2 | loss: 0.6213523\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3440s/iter; left time: 2619.2368s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 2 | loss: 0.2530579\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3440s/iter; left time: 2619.3252s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 2 | loss: 0.3419662\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3439s/iter; left time: 2619.1635s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 2 | loss: 0.5257560\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3440s/iter; left time: 2619.2516s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 2 | loss: 0.5897478\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3440s/iter; left time: 2619.2485s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 2 | loss: 0.3912165\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3440s/iter; left time: 2619.2936s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 2 | loss: 0.4142987\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0544s/iter; left time: 408.9220s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 2 | loss: 0.3653196\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0544s/iter; left time: 409.0427s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 2 | loss: 0.1823082\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0544s/iter; left time: 409.0663s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 2 | loss: 0.3134041\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0544s/iter; left time: 409.0197s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 2 | loss: 0.4179175\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0544s/iter; left time: 409.1321s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 2 | loss: 0.4715829\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0545s/iter; left time: 409.2230s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 2 | loss: 0.3350126\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0544s/iter; left time: 409.0664s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 2 | loss: 0.2723444\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0544s/iter; left time: 409.1169s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 2 cost time: 15.929589748382568\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 2 cost time: 16.119924068450928\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 2 cost time: 16.031923055648804\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 2 cost time: 15.930410385131836\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 2 cost time: 16.125333309173584\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 2 cost time: 14.603060960769653\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 2 cost time: 14.857861995697021\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 2 cost time: 15.611660718917847\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.3955636, Valid Loss: 1.0108212, Test Loss: 0.8746909,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.4079436, Valid Loss: 1.0099916, Test Loss: 0.8748767,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.4093246, Valid Loss: 1.0095446, Test Loss: 0.8770651,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.4071265, Valid Loss: 1.0109088, Test Loss: 0.8756235,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.4030787, Valid Loss: 1.0091982, Test Loss: 0.8767024,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.3943363, Valid Loss: 1.0102127, Test Loss: 0.8775485,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.3963850, Valid Loss: 1.0117815, Test Loss: 0.8758669,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 2, Steps: 266 | Train Loss: 0.4074462, Valid Loss: 1.0104364, Test Loss: 0.8764560,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 5e-05\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 3 | loss: 0.4354135\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3406s/iter; left time: 2503.3286s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 3 | loss: 0.5619190\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3406s/iter; left time: 2503.3006s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 3 | loss: 0.4881280\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3406s/iter; left time: 2503.2949s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 3 | loss: 0.3460692\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3406s/iter; left time: 2503.1635s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 3 | loss: 0.2127138\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3406s/iter; left time: 2503.3510s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 3 | loss: 0.2755222\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3406s/iter; left time: 2503.3035s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 3 | loss: 0.3789501\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3406s/iter; left time: 2503.3452s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 3 | loss: 0.4691122\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3407s/iter; left time: 2503.4481s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 3 | loss: 0.3134675\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0571s/iter; left time: 414.0476s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 3 | loss: 0.1890389\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0571s/iter; left time: 414.0437s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 3 | loss: 0.3690211\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0571s/iter; left time: 414.0290s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 3 | loss: 0.2476234\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0571s/iter; left time: 413.9470s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 3 | loss: 0.3123263\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0571s/iter; left time: 414.1085s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 3 | loss: 0.4455422\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0571s/iter; left time: 414.0636s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 3 | loss: 0.3076446\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0571s/iter; left time: 414.1465s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 3 | loss: 0.2906605\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0571s/iter; left time: 414.1923s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 3 cost time: 16.629549741744995\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 3 cost time: 16.563201665878296\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 3 cost time: 16.561297178268433\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 3 cost time: 14.88392686843872\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 3 cost time: 16.009664297103882\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 3 cost time: 15.075634002685547\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 3 cost time: 16.136800050735474\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 3 cost time: 15.12086796760559\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3394080, Valid Loss: 0.9359550, Test Loss: 1.0178061,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation loss decreased (0.996709 --> 0.935955).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3437567, Valid Loss: 0.9360846, Test Loss: 1.0162652,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation loss decreased (0.996698 --> 0.936085).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3352667, Valid Loss: 0.9370329, Test Loss: 1.0187322,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation loss decreased (0.997087 --> 0.937033).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3295880, Valid Loss: 0.9365953, Test Loss: 1.0160946,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation loss decreased (0.996546 --> 0.936595).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3357511, Valid Loss: 0.9347565, Test Loss: 1.0156070,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation loss decreased (0.996453 --> 0.934757).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3324815, Valid Loss: 0.9361979, Test Loss: 1.0155970,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation loss decreased (0.996751 --> 0.936198).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3370528, Valid Loss: 0.9363222, Test Loss: 1.0176076,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation loss decreased (0.996468 --> 0.936322).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 3, Steps: 266 | Train Loss: 0.3307503, Valid Loss: 0.9358726, Test Loss: 1.0170676,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation loss decreased (0.996635 --> 0.935873).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 2.5e-05\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 4 | loss: 0.3785053\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3463s/iter; left time: 2452.8818s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 4 | loss: 0.4145578\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3463s/iter; left time: 2452.8941s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 4 | loss: 0.1921607\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3463s/iter; left time: 2452.7816s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 4 | loss: 0.3272767\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3463s/iter; left time: 2452.8942s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 4 | loss: 0.3142554\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3463s/iter; left time: 2452.8616s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 4 | loss: 0.1782971\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3463s/iter; left time: 2452.8941s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 4 | loss: 0.2359667\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3463s/iter; left time: 2452.8333s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 4 | loss: 0.3480287\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3463s/iter; left time: 2453.0586s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 4 | loss: 0.1822565\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0560s/iter; left time: 391.1385s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 4 | loss: 0.2650618\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0560s/iter; left time: 391.1762s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 4 | loss: 0.3053505\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0560s/iter; left time: 390.9900s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 4 | loss: 0.3676643\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0560s/iter; left time: 391.0989s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 4 | loss: 0.2432924\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0560s/iter; left time: 391.0814s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 4 | loss: 0.2728057\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0560s/iter; left time: 391.1489s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 4 | loss: 0.2088663\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0560s/iter; left time: 391.2592s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 4 | loss: 0.2246323\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0560s/iter; left time: 391.3162s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 4 cost time: 16.455738306045532\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 4 cost time: 14.770580768585205\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 4 cost time: 15.157612323760986\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 4 cost time: 16.455182552337646\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 4 cost time: 16.007297039031982\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 4 cost time: 15.925772428512573\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 4 cost time: 16.50819182395935\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 4 cost time: 15.130061388015747\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2633822, Valid Loss: 0.8879294, Test Loss: 0.9007974,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation loss decreased (0.936198 --> 0.887929).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2725986, Valid Loss: 0.8869556, Test Loss: 0.9009504,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation loss decreased (0.936085 --> 0.886956).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2644796, Valid Loss: 0.8872763, Test Loss: 0.9002355,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation loss decreased (0.937033 --> 0.887276).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2637241, Valid Loss: 0.8859560, Test Loss: 0.8999135,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation loss decreased (0.936322 --> 0.885956).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2635039, Valid Loss: 0.8871185, Test Loss: 0.9005789,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation loss decreased (0.935873 --> 0.887118).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2630875, Valid Loss: 0.8871909, Test Loss: 0.8997490,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation loss decreased (0.936595 --> 0.887191).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2623963, Valid Loss: 0.8870694, Test Loss: 0.9002730,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation loss decreased (0.934757 --> 0.887069).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 4, Steps: 266 | Train Loss: 0.2649093, Valid Loss: 0.8874505, Test Loss: 0.9017637,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation loss decreased (0.935955 --> 0.887451).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 5 | loss: 0.3384198\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3495s/iter; left time: 2382.5000s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 5 | loss: 0.3109660\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3495s/iter; left time: 2382.4830s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 5 | loss: 0.2470661\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3495s/iter; left time: 2382.4604s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 5 | loss: 0.2722012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3495s/iter; left time: 2382.2535s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 5 | loss: 0.2055901\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3495s/iter; left time: 2382.3514s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 5 | loss: 0.2772949\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3495s/iter; left time: 2382.5205s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 5 | loss: 0.2499771\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3495s/iter; left time: 2382.4613s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 5 | loss: 0.1759849\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3495s/iter; left time: 2382.6463s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 5 | loss: 0.1889868\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0564s/iter; left time: 378.7688s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 5 | loss: 0.3076311\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0564s/iter; left time: 378.7636s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 5 | loss: 0.1958152\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0564s/iter; left time: 378.7919s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 5 | loss: 0.1628064\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0564s/iter; left time: 378.8149s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 5 | loss: 0.2871208\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0564s/iter; left time: 378.7901s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 5 | loss: 0.2352522\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0564s/iter; left time: 378.6894s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 5 | loss: 0.2718806\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0564s/iter; left time: 378.8159s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 5 | loss: 0.2225834\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0564s/iter; left time: 379.0343s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 5 cost time: 17.09791326522827\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 5 cost time: 17.297640800476074\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 5 cost time: 16.657744884490967\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 5 cost time: 17.068948984146118\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 5 cost time: 15.53718090057373\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 5 cost time: 15.297357082366943\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 5 cost time: 16.762288808822632\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 5 cost time: 16.658011198043823\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2398498, Valid Loss: 0.8348659, Test Loss: 0.8881923,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation loss decreased (0.886956 --> 0.834866).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2346923, Valid Loss: 0.8353978, Test Loss: 0.8884842,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation loss decreased (0.887929 --> 0.835398).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2355551, Valid Loss: 0.8352928, Test Loss: 0.8872247,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation loss decreased (0.887276 --> 0.835293).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2375119, Valid Loss: 0.8349157, Test Loss: 0.8901422,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation loss decreased (0.887118 --> 0.834916).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2322026, Valid Loss: 0.8353180, Test Loss: 0.8885193,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation loss decreased (0.887191 --> 0.835318).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2324138, Valid Loss: 0.8358392, Test Loss: 0.8884228,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation loss decreased (0.885956 --> 0.835839).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2341949, Valid Loss: 0.8359692, Test Loss: 0.8881810,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation loss decreased (0.887069 --> 0.835969).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 5, Steps: 266 | Train Loss: 0.2347421, Valid Loss: 0.8348580, Test Loss: 0.8887611,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation loss decreased (0.887451 --> 0.834858).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 6.25e-06\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 6 | loss: 0.2871842\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3513s/iter; left time: 2301.4588s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 6 | loss: 0.1697067\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3514s/iter; left time: 2301.7007s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 6 | loss: 0.2287235\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3514s/iter; left time: 2301.7900s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 6 | loss: 0.2357044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3514s/iter; left time: 2301.8695s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 6 | loss: 0.2103609\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3514s/iter; left time: 2301.7482s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 6 | loss: 0.2640262\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3514s/iter; left time: 2301.8352s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 6 | loss: 0.1582395\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3514s/iter; left time: 2301.7881s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 6 | loss: 0.3541024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3514s/iter; left time: 2301.8701s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 6 | loss: 0.2430672\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0607s/iter; left time: 391.3674s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 6 | loss: 0.1946390\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0607s/iter; left time: 391.3468s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 6 | loss: 0.3246246\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0607s/iter; left time: 391.3332s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 6 | loss: 0.2544585\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0607s/iter; left time: 391.2976s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 6 | loss: 0.2859277\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0607s/iter; left time: 391.2944s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 6 | loss: 0.1997904\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0607s/iter; left time: 391.3793s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 6 | loss: 0.1655208\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0607s/iter; left time: 391.3516s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 6 | loss: 0.2463708\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0607s/iter; left time: 391.3864s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 6 cost time: 17.55231809616089\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 6 cost time: 15.707345008850098\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 6 cost time: 17.77445912361145\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 6 cost time: 17.2614107131958\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 6 cost time: 16.88871717453003\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 6 cost time: 16.151957273483276\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 6 cost time: 17.319981575012207\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 6 cost time: 17.244827270507812\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2232532, Valid Loss: 0.8301699, Test Loss: 0.9119656,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation loss decreased (0.835398 --> 0.830170).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2252775, Valid Loss: 0.8294491, Test Loss: 0.9130566,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation loss decreased (0.834858 --> 0.829449).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2248161, Valid Loss: 0.8300255, Test Loss: 0.9120578,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation loss decreased (0.834916 --> 0.830025).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2209809, Valid Loss: 0.8308514, Test Loss: 0.9131230,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation loss decreased (0.835839 --> 0.830851).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2281153, Valid Loss: 0.8298403, Test Loss: 0.9130212,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation loss decreased (0.834866 --> 0.829840).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2223248, Valid Loss: 0.8300992, Test Loss: 0.9147105,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation loss decreased (0.835969 --> 0.830099).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2236381, Valid Loss: 0.8300369, Test Loss: 0.9137489,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation loss decreased (0.835293 --> 0.830037).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 6, Steps: 266 | Train Loss: 0.2212935, Valid Loss: 0.8310900, Test Loss: 0.9164507,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation loss decreased (0.835318 --> 0.831090).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 3.125e-06\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 7 | loss: 0.2889484\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3464s/iter; left time: 2177.1822s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 7 | loss: 0.2659307\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3464s/iter; left time: 2177.1019s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 7 | loss: 0.1669143\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3464s/iter; left time: 2177.2038s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 7 | loss: 0.1765884\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3464s/iter; left time: 2177.1726s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 7 | loss: 0.2138778\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3464s/iter; left time: 2177.2551s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 7 | loss: 0.2329659\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3464s/iter; left time: 2177.1792s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 7 | loss: 0.3148045\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3464s/iter; left time: 2177.1858s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 7 | loss: 0.1554704\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3464s/iter; left time: 2177.1705s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 7 | loss: 0.2782121\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0547s/iter; left time: 338.3001s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 7 | loss: 0.2084096\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0547s/iter; left time: 338.3312s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 7 | loss: 0.2341632\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0547s/iter; left time: 338.2900s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 7 | loss: 0.1807214\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0547s/iter; left time: 338.3463s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 7 | loss: 0.2809023\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0547s/iter; left time: 338.2971s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 7 | loss: 0.1855416\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0547s/iter; left time: 338.2947s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 7 | loss: 0.1723935\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0547s/iter; left time: 338.2836s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 7 | loss: 0.2275342\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0547s/iter; left time: 338.3091s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 7 cost time: 14.731028079986572\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 7 cost time: 16.5067458152771\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 7 cost time: 16.146750450134277\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 7 cost time: 15.03850531578064\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 7 cost time: 15.932062864303589\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 7 cost time: 16.44947576522827\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 7 cost time: 14.783807277679443\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 7 cost time: 14.782892227172852\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2178123, Valid Loss: 0.8190027, Test Loss: 0.9029623,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation loss decreased (0.830170 --> 0.819003).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2177910, Valid Loss: 0.8189632, Test Loss: 0.9006112,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation loss decreased (0.829449 --> 0.818963).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2199317, Valid Loss: 0.8190629, Test Loss: 0.9009187,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation loss decreased (0.830025 --> 0.819063).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2146737, Valid Loss: 0.8188278, Test Loss: 0.9024192,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation loss decreased (0.830851 --> 0.818828).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2145189, Valid Loss: 0.8189938, Test Loss: 0.9008893,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation loss decreased (0.831090 --> 0.818994).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2184982, Valid Loss: 0.8194812, Test Loss: 0.9013426,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation loss decreased (0.830037 --> 0.819481).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2216365, Valid Loss: 0.8185470, Test Loss: 0.9012124,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation loss decreased (0.829840 --> 0.818547).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 7, Steps: 266 | Train Loss: 0.2162417, Valid Loss: 0.8182865, Test Loss: 0.8994424,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation loss decreased (0.830099 --> 0.818287).  Saving model ...\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 1.5625e-06\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 8 | loss: 0.1954736\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3498s/iter; left time: 2105.6141s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 8 | loss: 0.1904512\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3498s/iter; left time: 2105.6565s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 8 | loss: 0.2745288\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3498s/iter; left time: 2105.7161s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 8 | loss: 0.2913693\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3499s/iter; left time: 2105.7615s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 8 | loss: 0.2339290\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3498s/iter; left time: 2105.6506s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 8 | loss: 0.3331103\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3498s/iter; left time: 2105.6372s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 8 | loss: 0.1485141\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3498s/iter; left time: 2105.6748s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 8 | loss: 0.2050881\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3499s/iter; left time: 2105.8577s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 8 | loss: 0.2926516\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0549s/iter; left time: 325.1093s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 8 | loss: 0.2706214\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0549s/iter; left time: 325.1005s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 8 | loss: 0.1779022\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0549s/iter; left time: 325.0957s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 8 | loss: 0.1684983\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0549s/iter; left time: 325.1046s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 8 | loss: 0.2051554\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0549s/iter; left time: 325.0646s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 8 | loss: 0.1683014\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0549s/iter; left time: 325.2092s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 8 | loss: 0.2334509\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0549s/iter; left time: 325.2044s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 8 | loss: 0.2584705\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0549s/iter; left time: 325.0802s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 8 cost time: 15.742851257324219\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 8 cost time: 15.384130716323853\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 8 cost time: 16.518774271011353\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 8 cost time: 17.006317377090454\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 8 cost time: 16.751797914505005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 8 cost time: 16.442151308059692\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 8 cost time: 14.9717698097229\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 8 cost time: 16.442554473876953\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2146223, Valid Loss: 0.8271137, Test Loss: 0.9007997,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2199357, Valid Loss: 0.8262398, Test Loss: 0.9029858,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2118386, Valid Loss: 0.8275056, Test Loss: 0.9037164,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2119051, Valid Loss: 0.8268108, Test Loss: 0.9013583,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2183144, Valid Loss: 0.8270580, Test Loss: 0.9016004,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2139155, Valid Loss: 0.8274388, Test Loss: 0.9017881,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2129610, Valid Loss: 0.8266848, Test Loss: 0.9036530,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 8, Steps: 266 | Train Loss: 0.2147451, Valid Loss: 0.8278371, Test Loss: 0.9026686,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:EarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 7.8125e-07\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 9 | loss: 0.2072633\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3466s/iter; left time: 1994.0942s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 9 | loss: 0.3387358\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3466s/iter; left time: 1994.0390s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 9 | loss: 0.1595550\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3466s/iter; left time: 1994.0198s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 9 | loss: 0.2551779\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3466s/iter; left time: 1994.1110s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 9 | loss: 0.2859170\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3466s/iter; left time: 1994.0588s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 9 | loss: 0.2334371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3466s/iter; left time: 1994.1228s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 9 | loss: 0.1373038\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3466s/iter; left time: 1994.1206s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 9 | loss: 0.2012734\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3466s/iter; left time: 1994.1451s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 9 | loss: 0.1970441\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0560s/iter; left time: 316.6292s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 9 | loss: 0.1885504\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0560s/iter; left time: 316.7348s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 9 | loss: 0.1699123\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0560s/iter; left time: 316.7119s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 9 | loss: 0.1881815\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0560s/iter; left time: 316.7183s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 9 | loss: 0.2306233\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0560s/iter; left time: 316.7513s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 9 | loss: 0.2658355\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0560s/iter; left time: 316.7876s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 9 | loss: 0.2638377\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0561s/iter; left time: 316.8757s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 9 | loss: 0.2508928\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0560s/iter; left time: 316.7046s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 9 cost time: 15.01966643333435\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 9 cost time: 16.381091356277466\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 9 cost time: 16.433539152145386\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 9 cost time: 15.28133511543274\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 9 cost time: 16.277992010116577\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 9 cost time: 14.945029973983765\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 9 cost time: 15.815886735916138\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 9 cost time: 16.896281242370605\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2118430, Valid Loss: 0.8266560, Test Loss: 0.9068838,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2137508, Valid Loss: 0.8271705, Test Loss: 0.9081392,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2114328, Valid Loss: 0.8267619, Test Loss: 0.9058612,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2110367, Valid Loss: 0.8275133, Test Loss: 0.9093947,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2178135, Valid Loss: 0.8277627, Test Loss: 0.9091053,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2147686, Valid Loss: 0.8273438, Test Loss: 0.9079068,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2127972, Valid Loss: 0.8264572, Test Loss: 0.9075108,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 9, Steps: 266 | Train Loss: 0.2132600, Valid Loss: 0.8278848, Test Loss: 0.9066569,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:EarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Updating learning rate to 3.90625e-07\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 100, epoch: 10 | loss: 0.2307870\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.3472s/iter; left time: 1904.9859s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 100, epoch: 10 | loss: 0.2887070\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.3472s/iter; left time: 1905.0580s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 100, epoch: 10 | loss: 0.1439771\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.3472s/iter; left time: 1905.1871s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 100, epoch: 10 | loss: 0.2817283\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.3472s/iter; left time: 1905.1020s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 100, epoch: 10 | loss: 0.2353435\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.3472s/iter; left time: 1905.1595s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 100, epoch: 10 | loss: 0.1979058\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.3472s/iter; left time: 1905.0647s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 100, epoch: 10 | loss: 0.1744135\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.3472s/iter; left time: 1905.2272s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 100, epoch: 10 | loss: 0.3415633\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.3472s/iter; left time: 1905.2898s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011iters: 200, epoch: 10 | loss: 0.2540396\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:#011speed: 0.0558s/iter; left time: 300.6220s\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011iters: 200, epoch: 10 | loss: 0.2107299\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:#011speed: 0.0558s/iter; left time: 300.5850s\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011iters: 200, epoch: 10 | loss: 0.2119405\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:#011speed: 0.0558s/iter; left time: 300.6802s\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011iters: 200, epoch: 10 | loss: 0.2845039\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:#011speed: 0.0558s/iter; left time: 300.6188s\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011iters: 200, epoch: 10 | loss: 0.1821288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011speed: 0.0558s/iter; left time: 300.6183s\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011iters: 200, epoch: 10 | loss: 0.1713686\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:#011speed: 0.0558s/iter; left time: 300.6592s\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011iters: 200, epoch: 10 | loss: 0.1625192\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:#011speed: 0.0558s/iter; left time: 300.6154s\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011iters: 200, epoch: 10 | loss: 0.2442283\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:#011speed: 0.0558s/iter; left time: 300.6910s\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 10 cost time: 15.137558698654175\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 10 cost time: 16.658802270889282\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 10 cost time: 14.844817161560059\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 10 cost time: 15.527300119400024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 10 cost time: 14.94344162940979\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 10 cost time: 16.162594079971313\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 10 cost time: 16.476057052612305\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 10 cost time: 16.117708683013916\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2149855, Valid Loss: 0.8294168, Test Loss: 0.9091606,\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2124751, Valid Loss: 0.8280554, Test Loss: 0.9102722,\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2115419, Valid Loss: 0.8279662, Test Loss: 0.9113445,\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2117008, Valid Loss: 0.8284304, Test Loss: 0.9110572,\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2170235, Valid Loss: 0.8270583, Test Loss: 0.9113795,\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2101473, Valid Loss: 0.8270864, Test Loss: 0.9096733,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2136028, Valid Loss: 0.8274619, Test Loss: 0.9109507,\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch: 10, Steps: 266 | Train Loss: 0.2104142, Valid Loss: 0.8282228, Test Loss: 0.9124190,\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:EarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Early stopping\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:>>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:test 2857\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:mse:0.9050368666648865, mae:0.7190903425216675\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:mse:0.9008887410163879, mae:0.7174561619758606\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:mse:0.9026115536689758, mae:0.7181438207626343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:mse:0.9021982550621033, mae:0.7180482149124146\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:mse:0.9021413326263428, mae:0.7177210450172424\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:mse:0.9011688232421875, mae:0.7175973057746887\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:mse:0.9018130302429199, mae:0.7178573608398438\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:pred 1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:mse:0.9014025926589966, mae:0.7179064154624939\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Saving classification report to /opt/ml/model/test_report.json\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:>>>>>>>predicting : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:self.target : OT\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:pred 1\u001b[0m\n",
      "\n",
      "2021-10-11 05:05:30 Uploading - Uploading generated training model\u001b[34m2021-10-11 05:05:26,286 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-10-11 05:06:07 Completed - Training job completed\n",
      "ProfilerReport-1633927859: IssuesFound\n",
      "Training seconds: 654\n",
      "Billable seconds: 196\n",
      "Managed Spot Training savings: 70.0%\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 결과 확인\n",
    "\n",
    "학습이 완료된 다음 S3에 저장된 산출물을 확인합니다.<br> model 결과물은 model.tar.gz에 저장되어 있고, 이외 학습 중 로그, 결과 산출물 등은 output.tar.gz에 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-256572302554/poc_informer/output/informer-poc-exp1-p3-1-dp-s-1011-04501633927859/output/\n",
      "2021-10-11 05:05:40   56.8 MiB model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifacts_dir = estimator.model_data.replace('model.tar.gz', '')\n",
    "print(artifacts_dir)\n",
    "!aws s3 ls --human-readable {artifacts_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> S3에 저장된 학습 결과 산출물을 모두 노트북에 다운로드 받은 다음, 압축을 풉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-256572302554/poc_informer/output/informer-poc-exp1-p3-1-dp-s-1011-04501633927859/output/model.tar.gz to model/model.tar.gz\n",
      "data/\n",
      "data/__pycache__/\n",
      "data/__pycache__/__init__.cpython-36.pyc\n",
      "data/__pycache__/data_loader.cpython-36.pyc\n",
      "data/data_loader.py\n",
      "data/__init__.py\n",
      "data/.ipynb_checkpoints/\n",
      "data/.ipynb_checkpoints/data_loader-checkpoint.py\n",
      "sagemaker_lambda/\n",
      "sagemaker_lambda/create_model.py\n",
      "sagemaker_lambda/lambda.zip\n",
      "sagemaker_lambda/.ipynb_checkpoints/\n",
      "sagemaker_lambda/.ipynb_checkpoints/create_model-checkpoint.py\n",
      "informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/\n",
      "informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/checkpoint.pth\n",
      ".zip\n",
      "main_informer.py\n",
      "utils/\n",
      "utils/metrics.py\n",
      "utils/timefeatures.py\n",
      "utils/tools.py\n",
      "utils/masking.py\n",
      "utils/__pycache__/\n",
      "utils/__pycache__/masking.cpython-36.pyc\n",
      "utils/__pycache__/__init__.cpython-36.pyc\n",
      "utils/__pycache__/tools.cpython-36.pyc\n",
      "utils/__pycache__/timefeatures.cpython-36.pyc\n",
      "utils/__pycache__/metrics.cpython-36.pyc\n",
      "utils/__init__.py\n",
      "utils/.ipynb_checkpoints/\n",
      "utils/.ipynb_checkpoints/tools-checkpoint.py\n",
      "codebuild-buildspec.yml\n",
      "scripts/\n",
      "scripts/ETTh2.sh\n",
      "scripts/ETTh1.sh\n",
      "scripts/WTH.sh\n",
      "scripts/ETTm1.sh\n",
      "data_dive_deep.ipynb\n",
      "exp/\n",
      "exp/exp_basic.py\n",
      "exp/__pycache__/\n",
      "exp/__pycache__/__init__.cpython-36.pyc\n",
      "exp/__pycache__/exp_basic.cpython-36.pyc\n",
      "exp/__pycache__/exp_informer.cpython-36.pyc\n",
      "exp/exp_informer.py\n",
      "exp/__init__.py\n",
      "exp/.ipynb_checkpoints/\n",
      "exp/.ipynb_checkpoints/exp_basic-checkpoint.py\n",
      "exp/.ipynb_checkpoints/__init__-checkpoint.py\n",
      "exp/.ipynb_checkpoints/exp_informer-checkpoint.py\n",
      "dist/\n",
      "dist/sm_dist.py\n",
      "dist/ddp_dist.py\n",
      "dist/__pycache__/\n",
      "dist/__pycache__/sm_dist.cpython-36.pyc\n",
      "dist/__pycache__/__init__.cpython-36.pyc\n",
      "dist/__init__.py\n",
      "dist/.ipynb_checkpoints/\n",
      "dist/.ipynb_checkpoints/ddp_dist-checkpoint.py\n",
      "dist/.ipynb_checkpoints/sm_dist-checkpoint.py\n",
      "__pycache__/\n",
      "__pycache__/sm_dist.cpython-36.pyc\n",
      "requirements.txt\n",
      "test_report.json\n",
      "pipelines/\n",
      "pipelines/__version__.py\n",
      "pipelines/get_pipeline_definition.py\n",
      "pipelines/_utils.py\n",
      "pipelines/__init__.py\n",
      "pipelines/informer/\n",
      "pipelines/informer/__init__.py\n",
      "pipelines/informer/pipeline.py\n",
      "pipelines/run_pipeline.py\n",
      "README.md\n",
      "predictor.py\n",
      "postprocess.py\n",
      "models/\n",
      "models/embed.py\n",
      "models/model.py\n",
      "models/decoder.py\n",
      "models/__pycache__/\n",
      "models/__pycache__/model.cpython-36.pyc\n",
      "models/__pycache__/attn.cpython-36.pyc\n",
      "models/__pycache__/__init__.cpython-36.pyc\n",
      "models/__pycache__/decoder.cpython-36.pyc\n",
      "models/__pycache__/embed.cpython-36.pyc\n",
      "models/__pycache__/encoder.cpython-36.pyc\n",
      "models/attn.py\n",
      "models/__init__.py\n",
      "models/encoder.py\n",
      "models/.ipynb_checkpoints/\n",
      "models/.ipynb_checkpoints/embed-checkpoint.py\n",
      "models/.ipynb_checkpoints/attn-checkpoint.py\n",
      "models/.ipynb_checkpoints/encoder-checkpoint.py\n",
      "models/.ipynb_checkpoints/model-checkpoint.py\n",
      "models/.ipynb_checkpoints/__init__-checkpoint.py\n",
      "models/.ipynb_checkpoints/decoder-checkpoint.py\n",
      "LICENSE\n",
      "results/\n",
      "results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/\n",
      "results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/metrics.npy\n",
      "results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/real_prediction.npy\n",
      "results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/true.npy\n",
      "results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/training_config.npy\n",
      "results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/pred.npy\n",
      ".ipynb_checkpoints/\n",
      ".ipynb_checkpoints/predictor-checkpoint.py\n",
      ".ipynb_checkpoints/postprocess-checkpoint.py\n",
      ".ipynb_checkpoints/README-checkpoint.md\n",
      ".ipynb_checkpoints/main_informer-checkpoint.py\n",
      ".ipynb_checkpoints/data_dive_deep-checkpoint.ipynb\n",
      ".ipynb_checkpoints/requirements-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "model_dir = './model'\n",
    "\n",
    "!rm -rf $model_dir\n",
    "\n",
    "import json , os\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "!aws s3 cp {artifacts_dir}model.tar.gz {model_dir}/model.tar.gz\n",
    "!tar -xvzf {model_dir}/model.tar.gz -C {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 학습 결과의 Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 스크립트에는 마지막 단계에 최종 학습된 모델을 이용하여 predict를 실행한 결과를 real_prediction.npy에 저장한 후 output.tar.gz로 압축하여 S3에 업로드 합니다. 이 결과를 다시 노트북에서 load한 후 plot하여 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "setting = 'informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0'\n",
    "\n",
    "# the prediction will be saved in ./results/{setting}/real_prediction.npy\n",
    "prediction = np.load(f'./model/results/{setting}/real_prediction.npy')\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 386
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prediction[0,:,-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "학습 스크립트에는 마지막 단계에 최종 학습된 모델을 이용하여 테스트 데이터에 대한 추론 결과를 pred.npy에, 실제 결과는 true.npy에 저장한 후 output.tar.gz로 압축하여 S3에 업로드 합니다. 이 결과를 다시 노트북에서 load한 후 plot하여 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2856, 24, 7), (2856, 24, 7))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "preds = np.load(f'./model/results/{setting}/pred.npy')\n",
    "trues = np.load(f'./model/results/{setting}/true.npy')\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "preds.shape, trues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 380
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw OT (Oil Temperature) prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[0,:,-1], label='GroundTruth')\n",
    "plt.plot(preds[0,:,-1], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAHwCAYAAAAByRFLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAABYlAAAWJQFJUiTwAACHyUlEQVR4nO3ddXhUZ9rH8e+ZuIcQnODuLqV4jbpT93ZrW9ttt92ty1Z2+7bdujs16i4UKJRSILg7hASHCPFkzvvHSUZIsGQyZ+T3ua65cs6ZM2fuQDK555n7uR/DNE1ERERERMQ+DrsDEBEREREJd0rKRURERERspqRcRERERMRmSspFRERERGympFxERERExGZKykVEREREbKakXERERETEZkrKRURERERspqRcRERERMRmSspFRERERGympFxERERExGZKykVEREREbBZpdwD+YBjGBiAZ2GhzKCIiIiIS2toB+aZptj+SB4VFUg4kx8XFpXXv3j3N7kBEREREJHStWLGC4uLiI35cuCTlG7t3756WmZlpdxwiIiIiEsIGDhzI/PnzNx7p41RTLiIiIiJiMyXlIiIiIiI2U1IuIiIiImIzJeUiIiIiIjZTUi4iIiIiYjMl5SIiIiIiNlNSLiIiIiJiMyXlIiIiIiI2U1IuIiIiImIzJeUiIiIiIjZTUi4iIiIiYjMl5SIiIiIiNlNSLiIiIiJiMyXlIiIiIiI2U1IuIiIiImIzJeUNaetiKCuyOwoRERERCXCRdgcQsirL4fVjwVkBzftAxlDIGGJ9TWlld3QiIiIiEkCUlDeUbYuhosTazplv3f580dpPbl2VoFfdmveBiCj7YhURERERWykpbygl+dCkG+xcWfO+/C2wbAss+8zaj4yDVgPcI+mth0BCY//GKyIiIiK2UVLeUDqOhRv+hOK9sGUeZP1p3bZkQnmh97kVxbDpd+tWrXEn75KX9K7g0BQAERERkVCkpLyhxTWCzsdaN4DKCtixDLLmuBP13M01H7d7rXVb+L61H5MCGYPdiXqrgRCT5L/vQ0REREQajJJyf4uIhBZ9rduQq61j+Vthy5yqRH0ObF0IlWXejyvNg7W/WDcAwwHNerrLXTKGQKN2YBj+/G5ERERExAeUlAeC5BbQ4zTrBlBeAlsXuUfSs/6Ewp3ejzGdsG2JdZv7mnUsqQV0GAPtR0OH0ZDc0q/fhoiIiIjUjZLyQBQVC22GWjcA04S9Gz1KXuZYJTCm0/txBVth0QfWDSC9iztJb3c0xKX68ZsQERERkcOlpDwYGAaktbdufSdax0ryITvTnahvmQul+d6P27Xaus15xSp3adm/ahR9jFX2EhXr929FRERERGpSUh6sYpOtDi8dx1r7lRVWycv6qbBhOmz+EypL3eebTiuJz86Emf8HkbHQZpg7SW/RFxwRtnwrIiIiIuFOSXmoiIiE1gOt26i/Q3kxbJ5tJejrp0HOQsB0n19RYh1fPw2mPACxqdB+ZFWSPhYad9SkURERERE/UVIeqqLivEfSi/bAxpnuJH33Wu/zS3JhxdfWDSC5lfek0aTmfgxeREREJLwoKQ8X8WnQ41TrBpC3BdZPdyfp+7Z7n5+fbfVIr+6T3qSbx6TRERCb4s/oRUREREKakvJwldIa+l9o3UwTdq5yJ+gbZ9acNLpzpXX78yUwIqDtUdB1AnQ5wSp1EREREZE6U1IuVu14027WbehfrEmjOQtgwzRrND3rT+/FjMxK2DjDuv34T0jvCl1PgK4nQuvBmjAqIiIicoSUlEtNEZGQMdi6jbodyopg8x/ukfSti7zP37XKuv3+DMQ3hs7HWaPoHcdBTJIt34KIiIhIMFFSLocWHQ+dxls3gIJtsPpHWP0DrJsKFcXuc4t2uxcwioiGdiPdZS6pGfbELyIiIhLglJTLkUtqDgMvtW5lRbDhN1j1nZWo79vmPq+yDNZNsW7f/R2a9bYS9K4nQIv+4HDY9z2IiIhIyHp39ib6Z6TSq1XwNKZQUi71Ex1fVU9+AjidsHUBrPoBVn0P25d4n7t9iXX77QlIbA5djrfq0DuMtlo4ioiIiNTT4i253P/VMgCuG92Rm4/pTFRE4A8EKikX33E4oNVA6zbuX5C72Ro9X/W9NZruLHefu28bzH/bukVW9VTvcoJ1S2pm3/cgIiIiQauswsntnyym0mktmDhv0x4igmQxRCXl0nBS28CQq61baQGs+9VK0Ff/CMV73OdVFFvlL6u+s/ZbDayqQ58AzXpqZVERERE5LM9NXcuq7QUAxEVF8PhZfXA4giOPUFIu/hGTBD1Os27OSsiaA6u/t5L0Xau9z83OtG6/PgyNO0H/i6HfBZDY1J7YRUREJOAtz8nnhanuFctvP74rbRsn2BjRkVFSLv7niIC2w63bsQ/C7nVVI+g/wKZZVh/0arvXwi/3wa8PWaPnAy6zSl3UC11ERESqlFc6uX3yIiqqylYGtm3EpUe1szeoI6SkXOzXuCMcdaN1K94La36xRtFX/wRl1kdQOCtgxdfWLbk19L/IuqnNooiISNh75bf1LMuxViOPjnTwxNl9iAiSspVqSsolsMQ1gj7nWLeyQlj+Jcx/x1q8qFr+Fpj+GEx/3OqdPuASq/48Mtq+uEVERMQWa7YX8Mwva1z7tx3bhY5NEm2MqG6UlEvgik6wasn7XQA7V1nJ+aIPrAWKADBh7S/WLaEJ9D3fStDTO9satoiIiPhHpdPk9smLKat0AtC3dQpXHd3e5qjqJvCbNooANOkKxz8Ct62Ec96CjuMAj4+lCnfCrP/Bc4PgzRNh0YdQXnygq4mIiEgIeGPmBhZm5QIQFWHwxNl9iQyCnuS10Ui5BJfIaOh5hnXbuwkWvGfdCnLc52z63bp9dwf0OdcaPW/Rx76YRURExOc27Crkvz+tcu3/dVxnujZPsjGi+gnOtxIiAI3aWosU3boULvgYup0MhkdXltI8mPsqvDwSXhkD896AknzbwhURERHfcDpN/jF5MaUVVtlKjxbJXDemo81R1Y9GyiX4OSKgy/HWrWA7LHzfqj/fu8F9Ts4C6/bjv6DnmdboecYQLUwkIiIShN6dvYk5G62FCCMcBk+c3YeoIC1bqRbc0YvsL6kZjLwN/jofLv0aep8DETHu+8uLYOF78MZx8MIw+ON5KNx94OuJiIhIQMnaU8TjP6x07V83uiO9WqXYGJFvaKRcQpPDAe1HWbcJe2DxxzD/bdix3H3OzpXw4z/hl/uh43hIbglxqRCbUnXz2I5LtfZjkiFCvzYiIiJ2ME2TOz9bTFGZtdBg56aJ/HV8J5uj8g1lFxL64tNg2LUw9C+QnWkl50s+hfJC6/7KMmuxosMVnbRfsr5fEn+wxD46USUzIiIidfTh3Cx+X2t9wu0w4Imz+xATGRqrfCspl/BhGNB6kHU7/t+w9DOr9jx73pFdp6zAuuVvOfIYHJHQejD0PQ96nG4l6iIiInJIObnFPPLtCtf+VSM70L9NIxsj8i0l5RKeYpJg4KXWbcdK2LoISvKgJNf9tbh62/N4PmDW/XmdFdbqpJv/gO//AV1PtBZH6jBWZTEiIiIHYJom//x8CftKKwBon57Abcd2sTkq31IWINK0m3U7HE4nlOZ7JOueCXveARJ5j/uqS2YAKkpg2WfWLbGZ1VO97/nQrKfvv0cREZEg9tn8bKat2glYH3w/cXYfYqNCo2ylmpLyBlZSXhlyPzRhzeGwSk7qWnaybycsnQwLJ8G2xR7Ht8OsZ61b8z7W6HnvcyAh3RdRi4iIBK0d+SU88PUy1/6lw9sxuF2ajRE1DLVEbECTM7dwzP9NZ9PuwkOfLOEhsQkMuw6unQHXzYLhN1qj5J62LYYf7oQnu8IH58PyL6Gi1J54RUREbGSaJv/6Yin5JVbZSkZaHHec0NXmqBqGkvIG8tWiHO6YvIgte4uZ+PJs1u/cZ3dIEmia9YTjH4Fbl8OFk61FjTx7qjsrYNV38PElVoL+7d9gSyaY9ahpFxERCSLfLN7Kz8u3u/YfP7MP8dGhWeihpLyBpMRFuVaW2pZfwsRXZrNme4HNUUlAioiEzsfCOW/C31fDyU9DxlDvc4r3wtzX4LVx8PwQmPEk5GXbEq6IiIg/7N5Xyn1fuctWLhjahqM6hW5Zp5LyBjK6SxPevGwwcVX15DsLSjnvldms2Jpvc2QS0OJSYdDlcOVP1qqko+6AlDbe5+xaDVMehKd6wjunwaKPoEwlUiIiElru+2oZewrLAGiREstdEw6zKUOQUlLegI7qlM5blw8mIdpKzHcXlnH+q7NZmp1nc2QSFBp3hHH/gpsXwaXfQL8LrcWHXExYPw0+vwb+2wW+uB42zLA6xIiIiASxH5Zu45vFW137j57Zm6TYKBsjanhKyhvY0A6NeefKoSTFWPVPuUXlXPDqbBZm5dobmAQPhwPaj4TTX7DKW854GTqMATxWBi3bBwvfh7dPhv/1ZffX97JgQaZdEYuIiNRZblEZd3+x1LV/9sDWjOna1MaI/ENJuR8MbNuI964aSnKslZjnl1Rw0Wt/Mm/jHpsjk6ATnWCtBnrJl3DrUhh/LzTu7H1O7mYaZz5D3y/GM++FK6FUk4xFRCR4PPjNcnbts7qONU2K4Z6TetgckX8oKfeTvhmpfHDNMBrFWx+97Cut4JI35jB7/W6bI5OgldIaRv4NbpwLV01hV7eLyMdd3uIwTAbtmEzx/4bCuqk2BioiInJ4pq7cwWfz3Y0MHjmjNynxdShbKS2Ald9CYfDkWUrK/ahnyxQ+vGY46YnRABSVVXLZm3OYuWaXzZFJMKtwmjy7KoVhi09iUMnzXFt2C79XulcFjSvcAu+eDl/eaK0qKiIiEoDyS8q567Mlrv1T+7bk2B7NDvIID6YJ25fD78/AWyfD4+3hwwtg9Q8NFK3vKSn3s67Nk/jwmuE0TbL6UZeUO7ni7blMXbXD5sgkGG3aXci5L//Bkz+vpsJpUkYUM6OOYt2E97k/4iZyzQT3yQvehReGwcrv7AtYRETkAB79bgXb8ksAaJwQzf2n9jz4A0ryYflX8NVfrY5kLw6Hn++FjTPAWW6ds/bnBo7ad5SU26BT00Q++stwWqTEAlBW4eQv72R6NccXORjTNPl4bhYnPjOD+ZtzXccHtW3E9zeP5JKj2nPChbdwXNl/+K5yiPuBBVvhw/Nh8pVB9ZGeiIiEtplrdvHBnCzX/oOn9SItIdr7JNOEbUth5lPw5knwRHv4+GKY/w7k17J2R/Pe0LxPA0fuO6G5JFIQaJ+ewMd/Gc55r8wmO7eYskon172Xyf/O78+JvVvYHZ4EsD2FZdz12WJ+XOZ+ExfpMLj12C5cO7ojEQ6rK8uwDo05f9xgrp+SygmVc3g46g3Sjao++UsnW+0UT3zCWknUMGp5JhERkYZXWFrBPz5d7No/oWdzTuzd3NopybPmRa39BdZOgYKcA18oNgU6jLUW5Ot0DCQ1b+DIfUtJuY0y0uL5+NrhXPDqbDbtLqLCafLXDxZQXunktH6t7A5PAtC0VTu4ffJidhaUuo51aJLAMxP707t1So3z/zquE3+s380PG4Ywu7Q7j8ZPYoJzunVn0S6YfAUs+RRO/r+ge/ESEZHQ8MQPK8nOLQYgNS6Sfx9lYsz8P1jzC2T9CWblgR/coi90OtZKxFsNslbJDlKGaZp2x9DgDMPIHDBgwIDMzMDs27wtr4QLXpvN+p3WqowOA544uy9nD2xtc2QSKIrLKnns+xW8/ccmr+MXD2vLP0/sTlzVAlW12ZpXzIRnZpBbZNXX3dpuIzcVPY/h+VFfbAoc/yj0u0Cj5iIi4SR/K0x9BLYvhbhGkNDEusU3rtpOd3+NT7da8/rw78Sf63dz9Su/MNKxlDGOhZySsJzY0oM0wIhNhY7jrCS843hIOsyJoH40cOBA5s+fP980zYFH8rjgfTsRQpqnxPLhNcO48NU/WbNjH04Tbp+8iIpKJ+cNaXPoC0hIW5qdxy0fLWTtDne/8fTEGP5zdh/Gdjv0YgotUuL4z9l9ufqdeQA8tbEdTU78mAvyXoPMN62TSvLgy+th6adwytOQqp87EZGQt+wL+OYWKN57+I+JjKtK0hvXksBXJ/FViXx8OkTF1ryG0wnbFlO+6ifiZ3zG/JhVRBpVq1GX1jydlv2t0fBOx0CrgUE9Gn4wGikPILv3lXLR63NYsTXfdezB03pyyfB29gUltql0mrz82zqe+nk15ZXu39NjezTjsTN70zgx5oiud/9Xy3hr1kYAoiMcfH7DUfQsXWTNWt+70X1idCIccz8MutJaTVREREJLSR58dwcs/rDhnys6yTuBj4iGTbOg8CBd5+IaWaPg1aPhiU0aPk4fqutIuZLyAJNbVMbFr89hSXae69jdJ3XnqpEdbIxK/C1rTxF/+3gRczxWfY2PjuC+U3pw7qAMjDp8dFhaUcmZL8xiWY71pq9DkwS+vvFoEoxS+PURmP0C4PF60HYEnPosNO5Y329HREQCxcaZ8Pm1kOfudEJKBhz/b4iKg8KdVbddVbed1hyk6u2KEp+H5DQN9qb2pHG/k6wR8VYDwHHgssxAp6T8IIIpKQfIKy7n0jfmsDAr13XsjhO6cv2YTvYFJX5hmiafL8jm3i+Xsa+0wnW8f5tUnjq3H+3SEw7y6ENbv3MfJz87k6Iya9LM2QNb899z+lp3Zs2BL2+AXavdD4iMhbH/guE3BPULpIhI2KsohV8fhlnP4jUA0+c8qxNXbM1mATWYJpTtqyVh3y+JL9zlPu6sqPVSuUYyUyt6M62yL+XtxvD81cfVacApECkpP4hgS8oBCkrKueKtuczd6K7zuvWYLtx8TGcbo5KGlFtUxr8+X8q3S7a6jkU4DG4a15kbxnYkMsI3pSSfZm7hb58scu0/PbEfp/ev6vZTXgK/PQEzn/ae7d5qIJz2PDTt7pMYRETEj7Yvg8+usSZzVotrBCc/BT3PaLjnNU0oybXWxagegS/N5511cdw/LxonDhKiI/jx1lG0bhTfcHH4mZLygwjGpBysvp1XvT2PP9a7F3m5cWwn/nZcF7++mywsreDPDbv5bfUuZq7dRV5xOaO7NOG8wRkMbNsoZN7Z2mnmml387ZOFbM93z3Bp1ziepyb2o3+bRj5/vts+WshnC6zuKwnREXx700jvUfiti+CLG2C7e7ljHFEw+g44+laIiPJ5TCIi4mNOp1WaOOUBqCxzH+84Dk57AZL9vy7Kki15nP7C71Q6rfzzodN6cnGIzZ1TUn4QwZqUg9UK75p35zFjjbs90DWjOnDXhG4NlgxXOk2W5eQxY80uflu9k/mb93pNNPTUoUkC5w3O4MwBrUk/womHAiXllTzxwyre+H2D1/Hzh7Th7pO6kxDTMDPM95VWcMqzM9mwy2rD2atVMp9edxQxkR4lKpXl8PvTMP0J7xfzZr3gtOes2fAiIhKY8rZYteMbZ7iPRcbCsQ/BkKttaX9bVuHk1OdmsnJbAQBD26fxwdXDcDhCa3BPSflBBHNSDlbidv378/l1pXum8mVHteO+U3r4LDHPzi1m5pqd/LZmF7+v3eXqaX24Ih0Gx3RvxsQhGYzq3MS1qqQc2PKcfG75aAGrt7tbHTZOiOaxs/pwbI+G77u6NDuPM1743fWG68qj23PPyT1qnrhjpVVrnj3PfcyIgBE3weg7a293JSIi9ln8CXz7Nyh1N42gRT8481Vo0sW2sP774yqem7oWgNgoBz/cPKrec6UCkZLygwj2pBysd5c3TprPT8vdS6tfMLQND5/Wq07vMPeVVjB73W5mrt3Fb2t2uhYuOpBuzZMY1aUJR3dKJyEmksmZW/h6UY7XZMRqLVJiOWdga84ZlEFGWujUiPmK02ny2sz1/PfH1ZRVOl3Hx3VryuNn9aFJkv8+cXhj5gYe/Ga5e/+yQYzrVssbAmclzH7RmiRUUew+3rizNWreZpgfohURkYMq3msl40s/dR8zHHD0bTD6HxAZbVto787exD1fuGvaQ7mznJLygwiFpBygvNLJLR8t5NvF7omA5wxszWNn9TnkyHSl02RJdp5rNHz+pr1UOA/8f5+eGMOozumM7JLOiE7pNE2qORpaVFbBt4u38tHcLOZtqrnwgGHA0Z3SOXdQBsf1bOZdGhGmcnKL+dvHi7zmCcRGObj7pB5cOLSN3+vzTdPkqrfnMaXqU5i0hGi+u2kkzVMOMPq9ex18dRNsmulx0IBh18Mx90GkSphERGyxbip8cT0U5LiPNWoHZ7wCbYbaFhbUbDBwVMfGvHvl0JD9VF1J+UGESlIOUFHp5O+fLOKLhe5futP7teS/5/St0Z1jy94iZqzZxcw17gmaBxIT6WBI+zRGdW7CyC7pdG2WdEQJ4tod+/h4XhafZm5hd2FZjfsbxUdxRv/WTBycQdfmSYd93YbgdJps2lPE0uw8luXksywnj215vu+7Wpuc3GIKy9xdTfq0TuGpif3o2CTRL89fmz2FZUx45jfXJNNhHdJ4/6phB36xdDqtlUB/vg/KCtzHm/eBs9+EdLXuFBEblJdYAwPh1nygvBh+eQD+fNH7eP+L4YRHIcbev7nfL9nKDZPmUz0O2C8jlfeuGkpiA82ZCgRKyg8ilJJysEa9//HpYiZnbnEdO6lPCx45vRdzN+5lxpqdzFyzi/W7Dl6S0r1FsjUa3rkJg9o1Ijaq/iPZZRVOpqzYzkfzspi+eie1/Xj1y0hl4uAMTunbssF/KSsqnazbWehKwJfm5LE8J7/Wsht/chhww9hO3DS+M1E+anVYH7PX7+aCV2e7XjRvO7YLN40/RPvN3Cxreea1v7iPRSXASf+FvueH3x9GEbHPrGetxDSxGQy7DgZeansy6hdbF1mtDneudB+Lbwyn/A+6n2xfXFWmrtrBNe/Mc81d6tY8iY+uGU5KfGh38FJSfhChlpSDNdp795dLmfTn5sN+TJOkGEZ2TmdU5yaM6JTe4LXLObnFTM7cwkdzs8jOLa5xf3x0BCf3acHEwRkMaFP/1oqlFZWs3raPpTl5riR8xdZ8Siuch36wH7VrHM+T5/ZlYNs0u0Px8tTPq3lmyhrAetPw4TXDGdL+EDGaJsx5BX6627tDS+9z4aQnITa5ASMWEQHmvWkNEHiKTYHBV8PQa4NuifbD4qyE35+Bqf8Gp8en4J2Pt+b5JDa1L7Yqs9fv5tI35rj+BndIT+Cjvwz367wpuygpP4hQTMrBqgd+4OvlvDVrY633x0Y5GNK+sWs0vEuzRFt6ijudJr+v28WHc7P4edl2r8mN1To1TeS8wRmc0b8VjQ+jtWJRWQUrtuazNDufpdl5LM3JZ832goPWyXtKS4imV6sUerZMplfLFDo0SfBLbVuEw6B944SAbP9UUenkgtf+ZM6GPYA1Yff7m0eSGn8YE4O2LobJV8DuNe5jjdrD2a9bCw+JiDSEFV/Dx5eAeYDBl8hY6HchHPVXSGtf56fJKypn2dY8lmVbn7juLSqneXIMLVPjaJkaR6uqry1SYn3yqfNB7d1otTrc/If7WFQ8HP9vGHhZQHxKuWDzXi567U9XuWbrRnF8cu1wWqTE2RyZf4REUm4YRmvgQeAEoDGwFfgCeMA0zZozCQ//uiGZlIOVmD/+wypemr4OgB4tkhnZxRoNH9jWNyUpvrSnsIzPF2Tz0dzNXq0Aq0VFGBzboxnnDspgZFVrxf1fDJdm57F+V2GtpTG1aZESS8+WKfRqlez62jw5Vose1WJrXjETnpnhaol5bI9mvHLxwMP7tyorhO/vgAXvuY85ImH8fTD8RnDYX6YjIiFk4+/w7hlQWbXoWot+0P8i+ON52Ou99gOGA3qcDiNuhpb9DnrZXftK3SWP2Xkszckja0/NT3sPJD0x2krWU+KqkvZYV9LeMjWOxgnRdRuYMU1YOAm+/4f3fJ5Wg+DMV6BxxyO/ZgNYsTWf816Z7ZrH1jQphk+uHU7bxqHX+vBAgj4pNwyjIzALaAp8CawEhgBjgVXACNM0dx/4Cge9dsgm5dW27C0iLirisEaZA4FpmizMyuWjuVl8vSjHa/JjtRYpsURGGEf0Yti2cTy9WqbQs5U1At6zZXLQ/JsEip+Xb+fqd9w9yR84tSeXHtXu8C+wZDJ8fYv3H42O4+GMlwLiI1URCQHblsKbJ7r7cKd1gCt+skpVnJWw4iuY+TRsXVjzsR3GwIhbMNuPZmt+qevT1uU5eSzNzmdbfsNO/I+OdNAyJdaVpFsj7R77KXHERe83oFa4G76+CVZ+4z5mRFhtDkf+DSICY9Lkup37mPjyH+zaZ5UzpiVE89E1w+jcLAzq+z2EQlL+I3AccJNpms96HP8/4FbgZdM0r63jtUM+KQ9mhaVWa8UP525m/ubcw3qMw7BKXnpWJd69WqXQo2UyybGhPXnEX+7/apmrLCo6wsHnNxxFz5Yph3+BPeth8pWQM999LKEpnPmytbyziEhd7d0Erx8H+7ZZ+4nN4MqfrPZ/nkwTNky3kvP1U2tcZjkdeL7sZL53DsHJwT/Ji4ow6No8qWrQJ4XmybFsyy8hJ7fY41bCtvwS1/Lx9dEoPspVFnNZ09UMX3IfRqF7AUHSOloLAbUOnPLArD1FnPvyH2yt6maWFBvJB1cPo1erI/jbESKCOik3DKMDsA7YCHQ0TXdxmGEYSVhlLAbQ1DTNg7cUqf36SsqDxJrtBXw0N4vPFmSzp6q1YvWLYc8WVSUorVLo3jy55kiC+ExpRSVnPD+L5VvzAejQJIGvbzyahCPpllNRBlMftiYjeRpxM4y7ByL0BkpEjlDhLnjjeNhtrQpJTDJc9i206OM6pdJpsn5n9aR/qwTFzFnIRc4vOckxmwjDO+/Z5GzKq5Un8UnlaEqJJjbKQY8Wya55Rz1bptClWRLRkYcuwauodLKjoJStecVk53on7dX7B2tPXM3ASQdjK5dF/MjFkb943znoSjjuIYgOnHKQ7fklnPPSH2zeUwRYjRzevXJIwDU08JdgT8qvAl4FXjFN8y+13F89in6MaZpTDnKdA2Xd3QYMGBCvpDx4lFU4WbQll7ioiMN+MRTfWrdzH6c8O5OiqtKiswe25r/n9D3yC62dAp//BQp3uo+1GghnvV6viVciEmZK98Hbp7g/gYuIofz8yayO7+s152jF1gKKy2uWRAJkGNu5OuI7zo2YRqzhnRyXxDRmX98raTT6eiISGjXYt7GvtIKtucVkV42u5+wtomjXZhJ2L6J5wXLal62il7GeZMO7dHMXqWSNfIL+4yc2WGx1sXtfKee9Mps1O6x5YtGRDt68bDAjOqXbHJl96pqUB0YREnSt+rr6APevwUrKuwAHTMoldERHOhjcLjzfYQeKjk0Seei0Xq5V2CZnbuHoTumc3r/VkV2o03i4bpaVmK/71TqWnQkvj4KTn4LeZ/s4chEJORVlVH50ERFVCbkTg0fj/sbbbxZSVjnzEA+2NIqPol2rnmxtdRS/pZUzZMdkUpa+hVGSC0Bs6W5i5zwBC1+wupgMux5SjvD17jAkOgvoXDCfztvmW28wsjNh33b3CbWMQf1YOYi7yq9iz8+JnJ+3hHtO7k58tP0pXF5xOZe8MceVkEc6DF64YEBYJ+T1Yf//qKW64CjvAPdXH0892EUO9I6kagR9QJ0iEwljZw1sze9rd/HZgmwA/vX5EvplpNIu/Qg/Nk1sChd+Cn88C1MeBGcFlObDp1datZ4Tngioj2JFxF4FJeUsz8m3Vl3O3stJa+9nXPl01/33lF/O+7t6AbW3QmyWHOOq/+5VNe+oRcr+Xbd6w7G3w/x3rI4t+VUL8pXtgz+egz9fhj7nwlE3QdNudftGyoth2xIr8a6+7Vl/eI9NaAItB7Cy6QTundOaPeVWSecHczYze/1unprYj34ZqXWLywcKSyu44q25LMuxyhwdBjw1sR/H9GhmW0zBLlCS8kOp/i2yv9ZGJMw8eHov5m/ey8bdRRSWVXLjB/P59LqjiIk8wpp+h8OqJ293tNXTfO9G6/iC92Dzn3D2G151oSISHvYWlrlWXK5uRbjBtSK1yT2R7zEu0p2QP1V+Fu9XHuPaz0iLo1fLFNeE/54tk2maFHt4Tx6TCMOvhyFXW52jfn8Gdq6w7nOWw8L3rVuXCXD0LdBm2IGv5ay0VtZ0JeDzYcdyaxDiUKIToWV/69ZqoHVLaQ2GQTfgxxFl/PPzJXy3xJrcumFXIWe9OIubxnXmhrEdifTzytAl5ZVc/c48Mje5u1U/dmYfTunb0q9xhJpAqSn/D/B34O+maT5Zy/3PATcA15um+WIdrq+JniL1sDQ7jzNe+N21VPKVR7fnnpN71P2CJfnw7W2w5BP3sYhoOO5hGHJNQCx+ISK+tyO/xKv/99Ls/FpXfK72l4ivuSvqA9f+V1En8Ev7f9CrdQq9WlpJ+GEtcHa4nE5Y8xP8/rT34jzVMoZZyXnn4yFvszv5zp5vtV8sLzr0cziioHkvaDnAnYCndwbHwQc6TNPks/nZ3PfVMvaVuhP9/m1SeXpiP7/1AS+vdHLde5n8ssLdDea+U3pw+QjNEaqmiZ4Hv76ScpF6emPmBh78Zrl7/7JBjOtWj48pqxfC+O7v3n/Iup4Ipz0P8ZpTIBLsVm8v4OtFOa5e4DsLSg/rcREOg+tTZvO3Ynf3poquJxM58Z1DJq8+s/lPa+R81bc174uMg4rDXEOjcWd38t1qADTrBVGHOZJfi6w9Rdz28ULmbnSPUsdHR3DfKT04d1BGgy6MV+k0ufnDBXyzeKvr2O3Hd+WGsZ0a7DmDUbAn5R2BtRy8JaIDaKKWiCL2ME2Tq96ex5SV1uhIWkI03900kuYpdf/jAsCuNTD5cqvuslpSSzjrVavURUSC0vb8Ekb/Zyol5bXXfVeLjnTQvXkSPapWXO7VMoXuBX8Q/cmFYFZ1UWk3Ei6cXK9kts52roLf/weLP7JKWg4mqaWVeLeqGgVv0Q/iUn0eUqXT5KXp63jq59VUePRFP65HMx49s3eDLJrndJrc+dliPp63xXXsujEd+ccJday3D2FBnZSDFg8SCQZ7CsuY8MxvbM+3RruGdUjj/auGEVGXJaM9VZTCz/fBnx7VaYYDRt0Oo+4ImNXqROTwfTw3izs+Xex1LD46wqsHeK9WKXRqmkiUZ0101hx4+1T3SHSz3nD5txBr8yI0ednWa9S8N63JoDEp3gl4ywGQ3MKvIS3ZksctHy1g3U73eGV6Ygz/OacPY7v6bgVl0zR54OvlrkXlAC4d3pb7T+3ZoCPzwSoUkvKOwCygKfAlsAIYCozFapV4lGmau+t4bSXlIj4ye/1uLnh1NtWDM7cd24Wbxnf2zcVX/QBfXAfFe9zH2gy3Vq5LzfDNc4iIX/z9k0VMzrRGVc8fksGVR3egfXrCwd/E71hpLQ5U1aaQ1LbWap1JzRs+4MNVXgJFuyGphTWB3WbFZZU8+v0K3vljk9fxS4a35a4J3X2y0N5/f1zFc1PXuvbPHtiaJ87qg6O+AzIhqq5Juf0/TVVM01wHDALewkrG/wZ0BP4HDK9rQi4ivjWsQ2P+Os6dhD/9y2rmbNhzkEccga4nwHW/Wx9VV9v8B7x0NKz42jfPISJ+MXej+3Xh7IGt6dQ08eAJed4WeO9Md0Ienw4Xfx5YCTlYJTQprQIiIQeIi47gwdN68eblg2mS5C5beeePTZz87AyWZh+o2/TheWHaWq+E/KTeLXhcCXmDCIyfqCqmaWaZpnm5aZotTNOMNk2zrWmaN5um6aO/+CLiC38d14khVYs7OU247eOFVFQevG70sCW3hEu+hLF3g1E1wlOSCx9dBN/cZvX9FZGAtiO/hE27rQncMZEOerdKPfgDivbAu2dCvrUmAtGJcNFkaNyxYQMNIWO7NuXHW0ZxnEef8HU7Czn9+d95fupaKp1HXhnx9qyNPPHDKtf+uG5NeWpiv/qXLEqtAiopF5HgEBnh4Jnz+5Eca9V6b9lbzIqtBb57AkcEjL4dLv8OUjzKVua9Dq+Ogx0rfPdcIuJzczxGyftlpBIdeZB0o6wIJk2EXVXJnyMKJr5r9eyWI5KWEM3LFw/kibP6kFBVtlLhNPnPj6s475U/yNpzGC0bq3wyL4v7vlrm2h/eoTEvXDjg4P+XUi/6lxWROmmREsfILk1c+wu35Pr+SdoMg2tnQPdT3Md2LIdXxlqTrQJkToyIeJvrUdI2uN1B2ptWlsMnl8GWOVUHDDjjJeg4rkHjC2WGYXDu4Ay+u3kkA9qkuo7P3biXCc/MYHLmFg41n/DbxVv5h8ck3f5tUnnt0kHERvmpHWWYUlIuInXWr3Wqa3txVm7DPElcIzj3XTj5KYisaodWUQzf3GL9MS9uoOcVkTrz7KE9uP0BknLThK9vhjU/uo9NeBx6n93A0YWHto0T+Pgvw7nt2C6ucpN9pRX8/ZNF3DBpPnsLy2p93K8rt3Pzhwtck/l7tEjmrcuGkBCjLlgNTUm5iNRZ34xU1/aihhgpr2YYMOgKuHoqNOnuPr78C3hppLXIh4gEhPySclZsywfAYeA1WutlygPWEvbVRv4NhtZYP1DqITLCwU3jO/PpdUfRPt294ud3S7ZxwjO/MWPNTq/zZ63dxbXvzXf1Pu/YJIF3rxxCSnyUX+MOV0rKRaTOerVKpnq+z5od+7yWfm4QzXrA1b/CwMvdx/I2w5sT4Lf/gLOyYZ9fRA4pc9NeV2VZj5bJJMXWktD98QLMfMq93/8iGHePfwIMQ/0yUvn2pqO5YGgb17Ht+aVc/PocHvh6GSXllWRu2stV78yjrMKatJ+RFsf7Vw1rkIWIpHZKykWkzuKjI+nSLAmwPolesqV+rbcOS3Q8nPI0nPuOezERsxJ+fRjeOQ3ytx704SLSsA5ZT75kMvx4l3u/ywQ4+RnrEzFpMPHRkfz7jN68dskgGidEu46/+ftGTnl2Jpe/OYeiMmtgo3lyLJOuGlb/FZvliCgpF5F66etRV96gJSz763EaXDsTMoa6j22cAS+NgNU/HvhxItKgPPuT10jK106Bzz0W584YBme/oVV7/eiYHs344ZZRjO/mXvFzzY595JdYn3Q2TojmvauGkpEWb1eIYUtJuYjUi1ddeUNN9jyQ1DZw2Xcw6nagapStaDdMOhd+uAsqSv0bj0iYKymvZFGW+xMzr6Q8OxM+uhic5dZ+k+5wwYfWp1/iV02SYnjt0kH8+4zexHl0VEmOjeSdK4fQqWmijdGFLyXlIlIvfTNSXNt+T8rBGmEbdzdc+pW17HW12S/Aa8fArrUHfqyI+NSS7DzKqhYSa5+e4F5hctdaeP8cKC+09lMy4OLPrO5KYgvDMLhgaBu+veloju3RjIFtG/HulUPp2TLl0A+WBqGkXETqpUuzJGKjrJeSnLwSdhSU2BNI+1Fw7e/Q5QT3sW2L4eVRsHCSepqL+MEcr3ryqoQ7fyu8e4b1KRZYifhFn1mr94rtOjRJ5NVLBvHpdUd5ffIp/qekXETqJSrCQS+PkZXFWX6Y7HkgCY3h/A/hhMchomoiU3khfHEdfHYNlPpw1VERqaFGPXlxLrx/ttUlCSAqHi6cDE262BOgSABTUi4i9ea3fuWHwzBg2LVw1S/QuJP7+JKPrZ7m2fPti00khFU6TTI9Fg0a1sKAD86D7UutA0aE1TWp9SCbIhQJbErKRaTePJPyhXbUldemRV+4Zjr0u8h9bO8GeP04mPUsOJ32xSYSglZuy6egaq2CEYk5tP5kAmz+w33Cac9D52Ntik4k8CkpF5F669vae7KnGSj12zGJcPrzcNbrEG31U8dZDj/dDZPOgX077I1PJITMqxolP80xkzcr/4WRu9l95/H/hn7n2xSZSHBQUi4i9dYmLZ7UqmWY80sq2Li7yOaI9tP7bLj2N2g5wH1s7S/w4ghY96t9cYl4Wv4VfHMrbMm0O5I6mbdhB/dGvsMz0S8QbVa1I41Ogonvw/Ab7A1OJAgoKReRejMMw2sRocV215XXJq0DXPEjHHWT+1jhDqsrxM/3QmW5fbGJ7N0Eky+HeW/A68dYP5PlNnUyqgOzYDuXr72ZKyJ/cB9M7wrXTIXuJ9sXmEgQUVIuIj4RkHXl+4uMhuMestqxJTRxH//9GXjjeNizwb7YJLyt+h6cVj02ptP6mXx5VHCMmmfNpfKlUQwwl7sOmd1OgaunQHpnGwMTCS5KykXEJ/rZvYjQkeg0Hq6bBR3HuY9lZ1pJ0JLJ9sUl4Wv1DzWP7VpljZr/cn/grk477014cwKRhdsAqDQNPk65EmPiuxCTZHNwIsFFSbmI+EQfj/KVpTn5lFcGeHeTxKZw4adw7IPgiLSOlebDp1fClzdAWaG98Un4KN0Hm35374/5J0QlWNumE2Y+Zb1hzA6gUfPyEvjqr/DNLdbkaWCvmchl5f9gZ7/rrdakInJElJSLiE+kJ8bQKjUOgLIKJ6u2BcFCPQ4HjLgZrvwJGrVzH1/wHrx7JjgrbQtNwsj6aVBZZm036wVj/gHXz4J2I93n7FwJrx0LUx60f9Q8bwu8OQHmv+M6tMbRnlPKHmaGs4+1aJCIHDEl5SLiM/2Coa68Nq0Gwl9mQO9z3MeyZsPij+2LScLHmh/d212Ot742ageXfAUn/tdaBRPArIQZT8IrYyBngb+jtGyYAS+Phhz3Ilwl3c/mlKJ72WI2JTrCQR+PFqkicviUlIuIz/QNprry/cUmw5mvendn+fXhoOqAIUHINGH1T+79zse7tx0OGHK1Nf+h7dHu4zuWw6vjrZ/PijL/xfnH8/DOaVC0qyq+SJjwBFO7P0QJMYD1GhAbFeGfmERCjJJyEfEZ77aIefYFUleGAaPvgPh0az9/C8x52d6YJLRtXQT7rEmSxKXVvgR9Wnu49GuY8IT3qPlv/6kaNV/YsDGWFcKnV8GP/7SeFyChqTWSP/QvzNm013WqSldE6k5JuYj4TK9WKTiq5net3lHAvqolt4NKTBKMudO9/9uTULTHvngktK3xGCXvdAw4DjDK7HDA0L/Adb9Dm6Pcx3csg1fHwa+PNMyo+Z71Vi37Uo+uRK0Hw1+mQ7sRAMzd6P79UFIuUndKykXEZxJiIunSzGqDZpqwNDsIR8sBBl4GaR2t7dI8q45XpCGsrqWe/GDSOsBl38IJj0OkNbHaGjV/Al4da428+8qan62R+B3L3McGXm49f3JLAApKylmekw9YHzQNaNvId88vEmaUlIuIT3lO8gq6uvJqEVFwzP3u/TmvwN6NdkUjoWrfTnebQyPC6p9/OBwOGHZt1aj5cPfx7UutUfOpj9Zv1NzphOn/gffPgZKqN9YR0XDqs3DK0xAZ4zp1weZcnKa13a15MilxUXV/XpEwp6RcRHzKc2XPRVtybYuj3rqfAq2HWNuVZdakOhFfWvszUJXRZgyFuCMcZW7c0Rq1Pv5R96i5swKmP2Yl59uWHHlMJXnw0UUw9WF3bMmt4IofYMAlNU73LF0Z0k6j5CL1oaRcRHzKc7LnoqwgLV8B67P44x5y7y/5xL42dBKavEpXjqvbNRwRMPx6a9Q8Y5j7+PYlVunJtMegsvzwrrVjpZXMr/rWfazdSLhmutU2tBZzNnjUk7dXPblIfSgpFxGf6to8iZhI66UlO7eYnQUBujz44WgzDLqd7N7/+V6rWF6kvirLYd2v7v0uJ9Tveo07wuXfwXGPQGSsdcxZAdMerRo1X3rwxy//El4bD7vXuo8NvxEu/gISm9T6kNKKSq/1CDTJU6R+lJSLiE9FRTjo1cpdV744mEtYAMbfZ9X7Amz4DdZOsTceCQ2bZ0OpNUGSlDbQpFv9r+mIgKNuhGtnukuvALYttkbNpz9Rc9TcWQm/3A8fXwJl+6xjUfFw1utw/CMQEXnAp1uanUdphROANmnxNEuOrf/3IBLGlJSLiM95l7Dk2haHTzTpAgMvde//fK+VyIjUx+of3NtdjrPKpXwlvbNVA37sQxBRNSnTWQ5TH7FGw7dXdVMp2gPvnQUzn3I/tlE7uPJn6H32IZ9mzgb1JxfxJSXlIuJznit7LgzGRYT2N/pOiEqwtncsg0Uf2huPBL81B1jF01ccETDipqpR88Hu41sXwcujrTeXr4yG9VPd93U6Fq6ZBs17HdZTzPOc5NlekzxF6ktJuYj43P4j5Waw12EnNbMSnGq/PgzlxfbFI8FtzwbYtdrajoyD9iMb7rmadIErfoRjH/QeNf/9Gcjd7D5v1B1wwUeH3QHG6TSZp5U8RXxKSbmI+FzbxvGufsV5xeVs2l1kc0Q+MPxGa2lxgIIcmP2ivfFI8PIcJe8wGqLiGvb5HBEw4ma4dkbNLirRSXDeJBj3rwOvJlqL1TsKyCu26tPTE6Npn57gy4hFwpKSchHxOcMwQqdfebWYRBhzp3t/5lNQuNu+eCR4edaTd65jK8S6aNIVrvjJWhgrvrE1GfSaqdDtpCO+1FyPVoiD2qZh+LImXiRMKSkXkQbRz2tlzxCoKwdr8ZTGna3t0nyY8V9745HgU7oPNs507/szKQerm8rRt8Lt6+Cqn61JoXUwZ6NH6Yr6k4v4hJJyEWkQITdSDhARZY0yVpvzqlUfLHK4Nky3VogFaNoTUjPsiaMeI9umaXqNlA9RPbmITygpF5EG0cdjsufS7DzKK532BeNL3U5yr5zoLIdfHzr4+SKevFbxbICuK36wZW8x2/JLAEiIjqB7iySbIxIJDUrKRaRBNEmKoVWqNYGttMLJqm0FNkfkI4YBx3kk4ks/hexM++KR4GGa3pM8gzQpn+vRCnFA20ZERiiVEPEF/SaJSIPx7FceMiUsABlDoPup7v2f7rUSLpGD2bYYCrZa23GNvPuHBxHPpFytEEV8R0m5iDSYkFrZc3/j7wOjqoXcppneI6AitVnt8TPS6ZgjakEYSOZsUFIu0hCUlItIg/Gc7Lk4FFb29JTeCQZd7t7/+T5wVtoXjwS+NZ715CfYF0c97N5XyrqdhQBERRj0b5Nqb0AiIURJuYg0mN6tUnBUNXlYvb2AwtIKewPytdH/gOhEa3vnClg4yd54JHAV7oIt86xtwwEdx9kbTx15ruLZu1UKsVHBOdovEoiUlItIg0mIiaRzU6szg9O0urCElMSm1kqJ1aY+AmUhsHqp+N6an4GqeQcZQyE+OMs+PFshqj+5iG8pKReRBtWndYhO9qw2/AZIbGZtF2yF2S/YG48EJs/SFX8vGORDnpM81Z9cxLeUlItIg/JaRChUVvb0FJ0AY//p3p/5tFWqIFKtshzW/ureD9JWiIWlFSzNyXftD2zbyMZoREKPknIRaVD9PJLyhaHWgaVav4sgvYu1XVYA05+wNx4JLFl/QmnVG9KUDGjaw9546mjB5lwqnVYJTtdmSaTGR9sckUhoUVIuIg2qa/MkoiOtl5rs3GJ27Su1OaIGEBEJxzzg3p/3OuxeZ188ElhW/+De7nxcvZa4t9Mcz/7k7TVKLuJrSspFpEFFRTjo1TLZtb84FOvKAbpOgDZHWdvOCpjyoL3xSOBYHfyreALM06JBIg1KSbmINLi+XiUsIVhXDtbo53EPufeXf+FugSfha+9G2LXK2o6MhXYjbQ2nrsornSzYnOvaH6LOKyI+p6RcRBpcP6/Jnrm2xdHgWg+CHqe793++F0zTtnAkAHiOkrcfDdHx9sVSD0uz8ygutxbHapUaR4uUOJsjEgk9SspFpMH1aZ3q2l60JRczlBPV8feCI9La3vS7dz2xhB/P//8uIdIKUaPkIg1CSbmINLh2jeNJjrUS1dyicjbvCeEFdhp3hEFXuPd/vg8qQ2wlUzk8ZYWwcaZ7v3Pw1pPP2eBeyVP15CINQ0m5iDQ4wzD2qyvPtS0Wvxh1B0RbK5myaxUsfM/eeMQe66dDZVW3oaY9IDXD3njqyOk0mbfJc6RcnVdEGoKSchHxC8+68sVbQnSyZ7XEJnD0ze79qf+2Rk0lvHiu4hnEXVfW7dxHblE5AGkJ0XRskmhzRCKhSUm5iPhFX8+68lAfKQcYdgMktbC2922HP16wNx7xL9P0nuQZzKUrHvXkg9o2wgjSPusigU5JuYj4RZ+MFNf20pw8yiudNkbjB9HxMPaf7v3fn4Z9O20LJ+Qs+gg+vBCy5tgdSe22LYGCHGs7NhVaD7Y1nPqYu0H9yUX8QUm5iPhF06RYWqbEAlBS7mT19gKbI/KDvhdAk+7Wdtk+mP64vfGEipyF8Pk1sPIbeP8cKN57yIf4nWfpSqdjrFVfg9TcjR6TPNV5RaTBKCkXEb/p69WvPMTrysFKxI65372f+SbsWmtbOCHDc7XUklyY8X+2hXJAXqt4nmBfHPWUnVtMdm4xAHFREfT0WJ1XRHxLSbmI+E3fcFlEyFOX46Ht0da2swKmPGBvPMFuw2+wbor3sT9fhtzN9sRTm8LdsGWutW04oNN4e+OpB8/SlQFtU4mKUNog0lD02yUiftN3v0WEwoJhwLEeI7srvgrcOuhAZ5rwi+ebmqoJh5WlMOUhW0Kq1dqfgaoFsloPgfjgLfnwXDRI9eQiDUtJuYj4Te/WKVQ3bli9vYCisjBZVKf1QOh5pnv/p3usBFOOzMpvIXuetR0RDWe+4r5vycdWrXkgWO3ZCjF4V/EEJeUi/qSkXET8JjEmks5NrR7HThOWZufbHJEfjb8HHFHWdtZsWPWdvfEEG2eldy354Kuhz7nQ9ST3sZ8D4M1OZYV3eU0Qt0LcW1jG6u37AIh0GPRvk2pvQCIhTkm5iPhV2PUrr5bWAQZf5d7/+T4rgZPDs+hDa3VUsFZLHXmbtX3M/WBEWNsbfoM1P9sSnkvWn1BSNYk5uTU062lvPPUwb5O760rPVinERwdvBxmRYKCkXET8qo/HZM+F4VJXXm3U7RBT1b1i9xpY8I698QSL8hJrVdRqR/0VEtKt7SZdYOCl7vt+vtcaVbfL6h/c212OgyBeaMezdGVIu0Y2RiISHpSUi4hf9QvXkXKAhMZw9C3u/amPQuk+28IJGvNeh/wt1nZ8Ogy/3vv+MXdBVIK1vXMFLHzfv/F5WhMaq3iC6slF/E1JuYj4VdfmSURHWi89W/YWs3tfqc0R+dnQ6yCppbVduAP+eM7eeAJdST789l/3/qjbISbJ+5zEpjDiZvf+r49AWaF/4vO0dxPsXGltR8ZC+1H+j8FHissqWbLFvZbAICXlIg1OSbmI+FV0pMNrAZLFW8JgESFP0fEw7l/u/d//Z3VjWfQhbF0MFWH2JuVQ/ngOiqtGbFPbwKDLaz/vqBshsbm1vW8b/PGCf+Lz5DlK3n6U9X8dpBZk7aXCaU2a7dQ0kbSEaJsjEgl9mrUhIn7Xt3UqCzbnArAwK5ex3ZraG5C/9T0f/ngediyH8kKY9T/3fUYEpHeGpj2gWQ9o2tOaLJjaJqjrk+tk306Y5fFJwth/QWRM7edGJ8DYf8LXN1n7vz9t1Zon+vFny7OevHOQt0Lc4J7kqdIVEf9QUi4iftfPc2XPcJvsCeCIgAlPwLunW6t8ejIrrRKInSth2Wfu49FJ0LS7d6LerAfEhfAEvBn/td60gPUmpfc5Bz+/34Uw+wXr365sH0x7DE7+v4aPE6xymQ0z3PtdQqeefEj7EP4ZEwkgSspFxO/6tE5xbS/KysU0TYxwGwVuPxJuWWK10Nu+DLYvhx3LYO/G2s8vK4Atc6ybp6SWVYl6D2jWy9pO73LgEeVgsXcTzH3dvT/+XuvNzMFERFqrp04619rPfAuGXmt1aGloG36zVhYFaNLd+mQjSFVUOpm/WSPlIv6mpFxE/K5d4wSSYyPJL6lgb1E5WXuKadM4eOtv6yy5JfQ8w7pVKy2AHSutBH37cqvEZfsyd131/gpyrNvaX9zHHJHQuFNVol41qt68N6S0btjvx5em/huc5dZ2xlDocsLhPa7zcdBuJGycYX3qMOUBOM8P3Vi8VvEM7lHy5VvzKSqz2kq2TImldaMw/N0UsYGSchHxO4fDoG9GKjPW7AKsfuVhmZTXJiYJMgZbt2qmCQXbaibqO1e5R2c9OStqL4EZfDWc+J/Ar03fvgwWf+TeP+b+w4/ZMOC4h+CVMdb+ym9g0yxoe5Svo3QzTe9JnkGelM/Z4H4DqK4rIv6jpFxEbNG3tTspX5yVy6l9W9ocUQAzDEhuYd06HeM+XlkBe9ZZSWx1or59GeRuqv06c1+FRu2sTiWBbMpDgNX5g87HHXlC3bK/VX++5BNr/6d74KpfGu7NyPalkJ9tbcemQushDfM8fuLVn7y9knIRf7E9KTcMIwq4HugH9Ad6AFHA1aZpvmZjaCLSgPqG+2RPX4iIhCZdrRtnuo97lcAss+rWty6y7vv5XitpbTfClpAPafNsWP191Y4B4++r23XG3QPLv4TKMsieB8u/8C4T8iXP0pVO463/lyBlmibzNrrryYdopFzEbwKhT3kC8DRwGdAc2GZnMCLiH309Jnsuyc6jotJpYzQhproEZuBlVrnKlb9Aq0HWfWYlTL7cKocJNKYJv9zv3u99DjTvVbdrNWoLQ65x7//yAFSU1Su8A/IqXTnM2vcAtW5nIbsLrX+nlLgoOjdNtDkikfARCEl5EXAi0NI0zebAGzbHIyJ+0DQ5lhYpsQCUlDtZvV3LzTeYyGg4922Ib2zt79sOn1wGleW2hlXDmp9h8x/WtiPS6jteH6P+bpWTAOzdAPNeP+jpdVK4G7bMtbYNh3d5URDyKl1p1wiHI8DnH4iEENuTctM0y0zT/N40za12xyIi/tW3daprWyUsDSylNZz9hpU4gpX8eo5K283ptDqlVBt4OaS1r9814xrBqNvd+9OfgOLc+l1zf2t/AbPqU57WgyE+uMs9vJPy4P5eRIKN7Um5iIQvr7ryrFzb4ggbHcbAuLvd+388B8s+ty0cL0snWxMmAaLivZPp+hhytbtnePEemPmUb65bbY1HPXmQr+IJ3km5Oq+I+FdIJeWGYWTWdgO62R2biNTUN8NjEaEteTZGEkZG3ApdT3Tvf3mj1VrRThVl8OvD7v1h10NSM99cOzLGe7Lo7BchN8s3166s8O4PH+StELfllZC1pxiA2CgHvVulHOIRIuJLIZWUi0hw6d0qxdWlbvX2AorKKg7+AKk/hwNOfxEaVZWGlO2Djy6GUhtr+ue/7W7jGNcIRtzk2+v3PNPqOANWX/epj/jmulvmQEnVm8nkVtaKqkFsjscoeb+MVKIjlSKI+JNPfuMMw9hoGIZ5BLf3fPG8+zNNc2BtN2BlQzyfiNRPUmwUnZpY3R0qnSbLcvJtjihMxKXCxHchMs7a37UKvvqr1f3E30r3WbXe1Ub+DWJ9PELrcMCxD7n3F30IWxfX/7qrf3Bvdz4u8BdlOoS5HosGqRWiiP/56m3wOmDVEdxyfPS8IhLkVFduk+a94WSP+upln8GfL/k/jj9fhMId1nZyKxh8VcM8T/uRHu0KTfj5nvq/CVkdOqt4ghYNErGbT1Y4ME1zvC+uIyLhp2/rFCZnbgFgoZJy/+p3vlWCMa+qE+1Pd1tlHm2G+ef5i/bA7/9z74+5E6LiGu75jnnA6iluOmH9NFg3pe4tDHM3w84V1nZEDLQf5bMw7ZBXVM6q7QUAOAzo36aRzRGJhB8VjImIrbSyp81OeAxaDrC2nRXw8aWwb4d/nnvGk1BaVbLUuDP0vaBhn69pNxhwiXv/p3vBWVm3a3mu4tl+FEQn1C82m2Vu3uP64KBnyxQSY4J3VVKRYKWkXERs1a15MtER1ktR1p5i9hQ20KqLUrvIGDj3HYirKlfYtw0mX2F1FmlIeVtgzqvu/fH3+Gd5+jF3QVRVAr1jGSz6oG7X8UzKQ6B0Zc6Gva5t9ScXsUdAJOWGYdxpGMZbhmG8BZxedfjy6mOGYTRQkaGI2C060kGPlsmufY2W2yA1A856DaiaqLhxhvdCPg1h2mNWJxSwRuq7n9qwz1ctqTkc9Vf3/q+PQFnRkV2jrMj6N6oWYv3Jh7RX6YqIHQIiKQdOAC6tuvWtOnaUx7GjbYpLRPygnyZ72q/TeBj7L/f+rP/B8q8a5rl2roaF77v3j7nfv51LjvorJDS1tgtyYPYLR/b4Db9BRYm13aQbNGrr2/j8rKS8ksUeb4a1aJCIPQIiKTdNc4xpmsZBbpfZHaOINByvRYSUlNtn5N88OpQAX1wPu9b6/nl+fci9NH2HsdBhtO+f42BiEmHsXe79mU/Dvp2H//g1oVW6sigrl/JKq6C8Q5ME0hNjbI5IJDwFRFIuIuGtT+tU1/aiLXmYdvTLFquf9xkvQWrVyG9ZAXx8MZQV+u45sjNhhccI/Ph7fXftI9H/Ekjvam2XFcBvTxz8/Gqm6d0KsXPwJ+VerRDbapRcxC5KykXEdu0bJ5AUa03y21NYxpa9xTZHFMbiGlUtLBRr7e9YDl/f7JuFhUwTfrnfvd/jdGg1oP7XrYuISDjWo25+3huH96nA9mWQb7XwJDYFMoY2THx+NGejxyRP9ScXsY2SchGxncNh0NdjtFz9ym3Woi+c9KR7f8kn3p1S6mr9VKseG8CIgHF31/+a9dHlBGg7wtp2VsCU+w/9GM/SlY7j/dMxpgFVOk3mb3In5VrJU8Q+SspFJCB41pUvVgcW+/W/CAZc6t7/8Z+QNafu13M64RePken+F0F657pfzxcMA457yL2/4mvY/OfBH+O1iucJBz4vSKzYms++Uqv9ZbPkGDLSGnDxJhE5KCXlIhIQPEfKF2Xl2ReIuE14Alr0s7ad5VULCx3BhEhPK76ErQut7chYa/XOQNBqIPQ6y73/090HLtUp2mOtgAqAUffVQAPInA0e9eTt0jD82QVHRLwoKReRgODZFnFJdh4VlU77ghFLVGzVwkJVfasLcuDTOiwsVFkOUzxGpIf+BZJb+i7O+hp3DziirO0tc7wnonpa+4u7a0zrwZDQ2D/xNaB5m7yTchGxj5JyEQkITZNjaZ5sTS4sLq9kzY59NkckgNWD+0yPhYU2/AZTHz6yayx8H/ass7ZjUmDELb6MsP7S2sOQa9z7v9xvvZHYn9cqnsG/YJBpmlrJUySAKCkXkYChfuUBqvMx3uUmM5+Cld8e3mPLi63VO6sdfTPEB2DyN+rvVjcVgD3rYd6b3vdXVlgj5dVCoBXixt1F7NpnraqaFBtJ1+ZJNkckEt6UlItIwOjrubKnJnsGllF3QKdj3fufXwu71x36cX++DAVbre3EZjD02oaJr77i06zFk6pNfwxKPOY2bJkLJbnWdlJLaN7br+E1hLke9eSD2jYiwqF6chE7KSkXkYDRT5M9A5fDAWe+AiltrP3SfPj4EigrOvBjivfCzP9z74++A6ITGjbO+hjyF/f3V7Qbfn/Gfd/qH9zbXY6zOrcEuTmeiwapP7mI7ZSUi0jA6NU6xZXrrNpeQHFZpb0Bibf4NJj4DkRULcO+fSl8c+uBu5X8/j/3aHOj9t4tFgNRVCyMv8e9/8fzkJdtba8JrVU8Yb+VPFVPLmI7JeUiEjCSY6Po2CQRsBY1WZaj0fKA07I/nPgf9/7iD63VMPdXsA1mv+jeH3c3REQ1fHz11etsa/EkgIoSmPoI5GZZK5uC9Yakw2j74vORHfklbNptfcoRHemgT+uUQzxCRBqaknIRCSha2TMIDLzUWvyn2g93wpZM73OmPwEVxdZ2897Q80z/xVcfDgcc69G+ceEk7xKc9iMDuwTnMM3d6O660q91KjGRETZGIyKgpFxEAoxXB5YtGikPWCf+F5r3sbYry6z68sLd1v7udTD/bfe54++3kt1g0WE0dK5ueWh6fxIQiqUr7RvZGImIVAuiV0kRCQfeK3vm2haHHEJUHEx8191GMH+LtbCQs9Iq+XBWLTDU9mjoNN6+OOvqmAfAqOVPZAj0J4eaK3mKiP2UlItIQOnWIonoCOulafOeIvYUltkckRxQo3Zw5qvu/fXT4NOrYOmn7mPH3BecnUqa9YB+F3ofS+9qfc9BLr+knBXb8gFwGDCwrUbKRQKBknIRCSgxkRF0b5ns2l+sfuWBrcvxVg/zass+c293PQkyhvg/Jl8Z+y+IjHPvdwmN0pXMTXtdDXO6NU8mKTYIJuCKhAEl5SIScPq19lzZU3XlAW/MndBxnPcxw+HdXjAYJbeAsXdZ25FxNUfOg9Q8j3ryIepPLhIwlJSLSMDRyp5BxhEBZ70OKRnuY33Ph6bd7YvJV0bcDFf8CNfOgKbd7I7GJzw7r6ieXCRwKCkXkYDTZ7/JnuaBFqeRwBGfBud/AE17QMZQOOZ+uyPynTbDIL2z3VH4RHml02sC9aB2qicXCRSRdgcgIrK/DukJJMVEUlBawe7CMrbsLSYjLd7usORQmveG6/+wOwo5iOU5+ZRWOAFolRpHs+RYmyMSkWoaKReRgONwGPTx6leea18wIiEkc5O7dEWj5CKBRUm5iAQkz37li7WIkIhPZG52J+VqhSgSWJSUi0hA8pzsuVCLCIn4xHyPkfIBbZSUiwQSJeUiEpD6eSTlS7bkUVHptC8YkRCQnVvM1rwSAOKjI+jWPMnmiETEk5JyEQlIzZJjaV41Ca24vJK1O/fZHJFIcPOsJ++XkUpkhFIAkUCi30gRCVh9vBYRyrUvEJEQ4Fm6onpykcCjpFxEApZ3Xbkme4rUh+dI+QAl5SIBR0m5iAQsz7ryxWqLKFJnRWUVLN+a79ofkKGkXCTQKCkXkYDV26N8ZeW2AkrKK22MRiR4LcrKo9JprYzbpVkiKfFRNkckIvtTUi4iASs5NoqOTRIAqHSaLMtRCYtIXcxXf3KRgKekXEQCmurKReovU/3JRQKeknIRCWieK3uqA4vIkXM6Ta+kXCPlIoFJSbmIBDTPkfJFmuwpcsTW79pHXnE5AI3io2ifnmBzRCJSGyXlIhLQurdIIirCAGDT7iL2FpbZHJFIcNl/lNwwDBujEZEDUVIuIgEtJjKCHi2SXfuLs1VXLnIk1J9cJDgoKReRgOc12XNzrm1xiAQjz6R8UNs0GyMRkYNRUi4iAc9zsueCrL0HPlFEvOwtLGPdzkIAIh0GfTx6/4tIYFFSLiIBz7NbxPxNe3FWLYIiIgfn+Sa2Z6sUYqMibIxGRA5GSbmIBLy2jeNJS4gGIL+kgvW79tkckUhw8Jrkqf7kIgFNSbmIBDzDMLwWPPFMNETkwOZtVH9ykWChpFxEgoJnQqGkXOTQyiudXr39B7RNtS0WETk0JeUiEhQGtEl1bc9XBxaRQ1qxNZ+ScicArVLjaJESZ3NEInIwSspFJCj0aZ1KpMNa9GTtjn3kFmkRIZGDUX9ykeCipFxEgkJcdAQ9W7oXEVqg0XKRg/LuT66kXCTQKSkXkaDR32Oy5/zNqisXOZj5mzTJUySYKCkXkaChyZ4ihycnt5icvBIA4qIi6NY8yeaIRORQlJSLSNDwrItdlJVLRaXTxmhEApfnJ0n9MlKJjNCfe5FAp99SEQkaLVNiaZ4cC0BhWSWrthfYHJFIYFJ/cpHgo6RcRIKGYRheCcZ8lbCI1MpzpFxJuUhwUFIuIkGlv/qVixxUUVkFy3LyXfuevzMiEriUlItIUNFkT5GDW7wlj0qnCUDnpomkxkfbHJGIHA4l5SISVHq2TCE60nrp2ryniJ0FpTZHJBJYMtUKUSQoKSkXkaASHemgT6sU1776lYt4m6+VPEWCkpJyEQk6muwpUjvTNMnUJE+RoKSkXESCjlb2FKnd+l2F5BaVA5AaH0WH9ASbIxKRw6WkXESCzoC2qa7tRVvyKKvQIkIiAJme/cnbNMIwDBujEZEjoaRcRIJO06RY2qTFA1BW4WRZTp7NEYkEhkzVk4sELSXlIhKUBqhfuUgNqicXCV5KykUkKGmyp4i33KIy1u7YB0Ckw6Bv61R7AxKRI6KkXESC0gAtIiTiZYHHJ0Y9WyYTFx1hXzAicsSUlItIUOraLIn4qqRjW34JObnFNkckYi/Vk4sENyXlIhKUIiMc9MtIde1rtFzCnVbyFAluSspFJGgNUL9yEQDKK50szMp17SspFwk+SspFJGhpsqeIZeXWAorLKwFomRJLi5Q4myMSkSOlpFxEglZ/j7aIy3LyKalKSkTCTeamPa5t1ZOLBCcl5SIStFLjo+nYxFpGvMJpsniLFhGS8JTp0XlFpSsiwUlJuYgEtYFqjSjiVb41qG2ajZGISF0pKReRoKakXMLd1rxisqtagsZFRdCtRZLNEYlIXSgpF5Gg5tmBZcHmvZimaWM0Iv43f1Oua7tvRgpREfrTLhKM9JsrIkGtY5NEkmMjAdhdWMam3UU2RyTiX+pPLhIalJSLSFBzOAyvbhPqVy7hxrPzipJykeClpFxEgp5nCYvqyiWcFJdVsiwn37XfP0NJuUiwUlIuIkFPkz0lXC3ekkuF05pH0bFJAo0Som2OSETqSkm5iAS9vhmpOAxre/X2AgpKyu0NSMRPMjerFaJIqLA9KTcMo7NhGP8wDONXwzCyDMMoMwxju2EYXxqGMdbu+EQk8CXGRNK1eTIAThMWZWkRIQkP8zXJUyRk2J6UAw8BjwHNgO+AJ4HfgZOAXw3DuMnG2EQkSAxsm+raVgmLhAPTNL1+1gcoKRcJaoGQlP8ADDBNs6dpmn8xTfMu0zTPBMYD5cB/DMNoYW+IIhLoPCd7qgOLhIMNuwrZW2SVaqXGR9EhPcHmiESkPmxPyk3TfMs0zQW1HJ8OTAOigaP8HZeIBJeB+7VFdDq1iJCENq9R8jaNcFRPrBCRoBRpdwCHUD1bq+JwTjYMI/MAd3XzTTgiEqjapMWTnhjNrn1lFJRUsG7nPjo303LjErq0aJBIaLF9pPxADMNoi1XCUgT8ZnM4IhLgDMOgv/qVSxjZf6RcRIJbQCblhmHEAO8DMcD9pmke1l9X0zQH1nYDVjZkvCISGNSvXMJFXlE5a3bsAyDCYdA3I8XmiESkvnySlBuGsdEwDPMIbu8d5FoRwLvACOAj4L++iFFEQp8me0q4mJ/l/vnu2TKZ+OhAr0YVkUPx1W/xOqDkCM7Pqe1gVUL+HnAO8DFwkWmamq0lIoelT+sUIh0GFU6TdTsL2VtYphUOJSTNV+mKSMjxSVJumub4+l7DMIxIYBJWQj4JuMQ0zcr6XldEwkdsVAQ9W6WwKCsXgAVZexnXrZm9QYk0AE3yFAk9AVFTbhhGNDAZKyF/B7hYCbmI1MWANqmu7fmbcm2LQ6ShVFQ6WVj1xhOUlIuECtuT8qpJnZ8DpwGvA5ebpum0NyoRCVaa7CmhbuW2AorKrHGrFimxtEyNszkiEfGFQJgZ8hJwIrALyAbuNYwaCyBMM01zmp/jEpEg5JmUL9qSS0Wlk8gI28cfRHzGqxWiRslFQkYgJOXtq76mA/ce5LxpDR+KiAS7FilxtEiJZWteCUVllazcVkCvVmoXJ6HDq55ckzxFQobtw0emaY4xTdM4xO1+u+MUkeDhOXqo1ogSajTJUyQ02Z6Ui4j4mle/ctWVSwjZlldCdm4xALFRDnq0TLY5IhHxFSXlIhJyvCZ7aqRcQojnJz99W6cSpfkSIiFDv80iEnJ6tEgmJtJ6ecvaU8yOgiNZ20wkcKl0RSR0KSkXkZATHemgT2v35E71K5dQoaRcJHQpKReRkKTJnhJqSsorWZaT59rvr84rIiFFSbmIhKSBmuwpIWbxljzKK00AOjRJIC0h2uaIRMSXlJSLSEjyHClfnJ1HaUWljdGI1J/6k4uENiXlIhKS0hNjaNs4HoCyCifLcvJtjkikfjyT8kHtlJSLhBol5SISslTCIqHCNE2vuRGa5CkSepSUi0jI6q/JnhIiNu4uYk9hGQApcVF0SE+0OSIR8TUl5SISsjxHyjM37cU0TRujEak7z9KVAW1ScTgMG6MRkYagpFxEQlbX5kkkREcAsD2/lJw8LSIkwUn9yUVCn5JyEQlZEQ6Dfm1SXfuZqiuXIOU5J2KAknKRkKSkXERCmiZ7SrDLKy5n9Y4CwHqj2bd1qr0BiUiDUFIuIiFNkz0l2C3YvJfq6RDdWySREBNpb0Ai0iCUlItISBuQ4U7Kl+fkU1ymRYQkuHh+wjOobZqNkYhIQ1JSLiIhLSU+is5NrfZxFU6TxVty7Q1I5AhlblY9uUg4UFIuIiFvgGdrRJWwSBCpqHSycHOua1+dV0RCl5JyEQl5nomMJntKMFm1vYDCqpKr5smxtEyJtTkiEWkoSspFJOQNaJvq2p6/OVeLCEnQmL9ff3LD0KJBIqFKSbmIhLwO6YmkxEUBsKewjI27i2yOSOTwZKo/uUjYUFIuIiHP4TAY4LGIkEpYJFjM00qeImFDSbmIhAVN9pRgsz2/hC17iwGIjXLQs2WyzRGJSENSUi4iYUGTPSXYeP6c9mmdSlSE/mSLhDL9hotIWOibkYqjao7cqu0FFJSU2xuQyCFkqnRFJKwoKReRsJAQE0m35tbH/6YJC7Ny7Q1I5BA8y6wGtlFSLhLqlJSLSNjwHG3MVAmLBLCS8kqWZue59tV5RST0KSkXkbCxf79ykUC1NDuP8kqrn36H9ATSEqJtjkhEGpqSchEJGwPbpLm2F2zai9OpRYQkMKk/uUj4UVIuImEjIy2O9MQYAApKK1izY5/NEYnUTv3JRcKPknIRCRuGsd8iQupXLgHINE2vdoiDlJSLhAUl5SISVjTZUwLdpt1F7C4sAyA5NpKOTRJtjkhE/EFJuYiEFa9FhDRSLgFo/3pyR3WDfREJaUrKRSSs9GqVQlSEleSs31nInqoRSZFAof7kIuFJSbmIhJXYqAh6tkxx7S/QaLkEmPma5CkSlpSUi0jYUQmLBKr8knJWbS8AwGFA34xUewMSEb9RUi4iYWdAG032lMC0cHMuZlX7/O4tkkmIibQ3IBHxGyXlIhJ2PFf2XJSVR0Wl075gRDyoP7lI+FJSLiJhp0VKHC1TYgEoLq9k5bYCmyMSsaieXCR8KSkXkbA0QP3KJcBUOk2vicdKykXCi5JyEQlLmuwpgWbVtgIKyyoBaJYcQ6vUOJsjEhF/UlIuImFJkz0l0GTuN0puGFo0SCScKCkXkbDUo2UysVHWS+CWvcXsyC+xOSIJd5715AO0aJBI2FFSLiJhKSrCQZ/Wqa59lbCI3TI1yVMkrCkpF5GwpRIWCRRb84rZvKcIgJhIh9eqsyISHpSUi0jYGqgOLBIgPl+Q7doe1K4R0ZH68ywSbvRbLyJhq3+bVNf20ux8Sisq7QtGwpZpmnw8N8u1f9aA1jZGIyJ2UVIuImErPTGGdo3jASirdLI0O9/miCQc/blhDxt3W6UrSbGRTOjVwuaIRMQOSspFJKx5LiK0QJM9xQYfeYySn9avJXHRETZGIyJ2UVIuImFNkz3FTnnF5Xy3ZKtr/7zBbWyMRkTspKRcRMLa/pM9TdO0MRoJN18tzKa0wglAjxbJ9Gqlrisi4UpJuYiEtS7NkkiMiQRgR0Ep2bnFNkck4eSjee7SlfOGZNgYiYjYTUm5iIS1CIdBv4xU175KWMRflmbnuSYXR0c6OK1vK5sjEhE7KSkXkbDnOdlzvpJy8ZOPPUbJT+zVnJT4KBujERG7KSkXkbA3wKNf+fzNubbFIeGjpLzSa8GgiZrgKRL2lJSLSNjr79GBZfnWfIrKKmyMRsLB90u3UlBi/Zy1bRzPsA5pNkckInZTUi4iYS8lLoouzRIBqHSaLN6SZ3NEEuo8e5OfOygDwzBsjEZEAoGSchER1K9c/GfjrkJmr98DgMOAswe2tjkiEQkESspFRNBkT/Efzwme47o1pVlyrI3RiEigUFIuIoL3IkLzN2sRIWkYFZVOJmduce2fO0i9yUXEoqRcRATokJ5AalVLur1F5WzYVWhzRBKKpq3ayY6CUgCaJMUwtltTmyMSkUChpFxEBDAMQ3Xl0uA+9JjgedaA1kRF6M+wiFj0aiAiUsW7hCXXvkAkJO3IL2Hqqh2u/YmDVboiIm5KykVEqvT3XERII+XiY5Pnb6HSac1VGNI+jfbpCTZHJCKBREm5iEiVvq1TiXBY/aJXbS9g7Y59NkckocI0TT72KF05T6PkIrIfJeUiIlUSYiIZ27WJa/+l6etsjEZCyZ8b9rBxdxEASTGRTOjVwuaIRCTQKCkXEfFw3ZiOru0vFmSzZW+RjdFIqPAcJT+tf0vioiNsjEZEApGSchERDwPbpjG0fRoAFU6TV39bb3NEEuzyisv5dslW1/7EQW1sjEZEApWSchGR/dwwtpNr+8O5WezaV2pjNBLsvlqUQ2mFE4AeLZLp1SrZ5ohEJBApKRcR2c/IzumuxKm0wskbMzfYHJEEs4/mbnZtTxycgWEYNkYjIoFKSbmIyH4Mw+CGMe7R8nf/2ER+SbmNEUmwWpqdx9LsfACiIx2c3q+VzRGJSKBSUi4iUovjezanYxOrj3RBaQXv/rHJ5ogkGH08zz3Bc0Kv5qTER9kYjYgEMiXlIiK1cDgMrh3t7sTyxswNFJdV2hiRBJuS8kq+WJDt2tcKniJyMErKRUQO4PT+rWiVGgfA7sIyr1FPkUP5Yek28ksqAGiTFs+w9o1tjkhEApntSblhGBmGYbxgGMafhmFsMwyj1DCMHMMwZhiGcblhGPqsT0RsERXh4OqR7V37L09fR1lVFw2RQ/nIozf5xMEZOBya4CkiB2Z7Ug50BC4E8oAvgCeBr4G2wBvAT4ZhRNoWnYiEtYmD29A4IRqAnLwSvlyYfYhHiMDGXYX8sX43AA4Dzh7Y2uaIRCTQBUJSPgtoZJrmcaZpXmua5j9N0/wLVrI+DRgDnGljfCISxuKiI7jiaPdo+YvT11HpNG2MSIKBZ6nT2K5NaZYca2M0IhIMbE/KTdMsM02zxufBpmmWY42cA3T2a1AiIh4uHt6WpBjrA7v1Owv5adk2myOSQFZR6WRy5hbXviZ4isjhsD0pPxDDMCKAE6t2F9sZi4iEt+TYKC4e3ta1//y0tZimRsuldtNW7WRHgbUKbHpiDGO7NbU5IhEJBgFTq20YRjpwI2AATYBjgU7AJOCbw7xG5gHu6uaLGEUkfF1xdHten7mB0gonS7PzmbFmF6O6NLE7LAlAH3mUrpw9sDVREQE7/iUiASSQXinSgfuAe4HrsGrK/wtcZmpISkRslp4Yw3keZQjPT11rYzQSqHbkl/Dryh2u/XMHaYKniBwenyTlhmFsNAzDPILbe/tfwzTNlaZpGlij922BW4FrgN8Mw0g7nDhM0xxY2w1Y6YvvU0TC29WjOhBZ1dbuzw17yNy0x+aIJNB8Oj/bNRF4SPs0OjRJtDkiEQkWvhopXwesOoJbzoEuZJpmpWmam03TfAb4CzAMeNBHcYqI1FnrRvGc3r+Va/+FqetsjEYCjWmaXl1XJg7SBE8ROXw+qSk3TXO8L65Ti++rvo5poOvX4HQ62bNnDwUFBZSWlmoyl4QdwzCIiYkhKSmJtLQ0HI5AqnKz37WjO/Lp/C2YJkxZuYPlOfn0aJlsd1gSAOZs2MOGXYUAJMVEcmLvFjZHJCLBJND/2lYPSVX448mcTidZWVns3LmTkpISJeQSlkzTpKSkhJ07d5KVlYXTqRUsPXVqmsgJPZu79l+crtFysXiu4Hlqv5bERUfYGI2IBBvbu68YhjEUWGKaZtF+xxOBZ6p2v/VHLHv27KGoqIjIyEiaN29OQkKCRgkl7DidTgoLC9m2bRtFRUXs2bOH9PR0u8MKKNeP6cT3S61e5d8uzuFvx3ahXXqCzVGJnfKKy/lu6VbX/nmD29gYjYgEo0DIOO8CcgzD+NIwjGcNw3jcMIxJQBZwDNaKn4/6I5CCggIAmjdvTlJSkhJyCUsOh4OkpCSaN7dGg6t/L8Std+sURna23qg4TXj5N42Wh7uvFuVQUm59qtS9RTK9WqmkSUSOTCBkna9ijYR3By4BbsNKxjOxJnqONk1znz8CKS21FntISNCIl0j170H174V4u2FsJ9f25MwtbMsrsTEasdvHHqUr5w3OwDAMG6MRkWBke1Jumua3pmleaJpmF9M0U0zTjDJNs6lpmseYpvmKaZp+qSevigVAI+Qi4EoqNLeidkPbpzGgTSoA5ZUmr81Yb29AYptlOXksyc4DIDrSwen9Wh3iESIiNSn7FJFaaaTv4AzD8BotnzRnM3sLy2yMSOziOUo+oVdzUuKjbIxGRIKVknIRkToa160p3ZonAVBUVslbszbaG5D4XUl5JZ8vyHbtqze5iNSVknIRkToyDIPrxnR07b81ayP7Sv1WcScB4Mdl28gvsf7P26TFM6xDY5sjEpFgpaRc5BDGjBkTVKUc7dq1o127dnaHETZO6t2Cto3jAast3qQ/N9kckfjTh3PcpSvnDmqNwxE8rxUiEliUlMtBrV69mttuu40BAwaQlpZGVFQUaWlpDB06lL///e9kZmbaHaJfbdy4EcMwjug2bdo0n8YQbG8SQl1khINrR7tHy1+bsYGS8kobIxJ/2bS7kD/W7wbAYcDZA1W6IiJ1Z/viQRKYTNPkwQcf5MEHH8TpdDJgwAAmTpxIWloaBQUFLF68mGeffZYnn3yS5557jhtuuMHukP0iNTWV++67r8bxBx54AKDW+zRqHfrOHNCKp39Zzfb8UnYUlPLp/C1cOLSt3WFJA/t4nnuUfEzXpjRPibUxGhEJdkrKpVYPPvgg999/PxkZGXzwwQeMGDGixjk7duzg6aefJi8vz4YI7ZGamsr9999f43h1Ul7bfRL6YiIjuHpkBx7+dgUAL01fx8RBGURG6MPIhmCaJs9MWcMPS7dxQq/mXDu6I7FR/l3SvqLSyeTMLa79iYM1Si4i9aO/GFLD+vXrefjhh4mOjub777+vNSEHaNq0Kf/+97+54447XMcuu+wyDMNg/fr1PPvss/Tp04e4uDjGjBnjOmfNmjVccskltGrViujoaFq2bMkll1zCmjVrajxH9fU2btxY475p06ZhGEaNRLi6vKOiooJ///vfdO7cmZiYGDIyMvjHP/5BWVntbes+/PBDBg4cSFxcHE2bNuXiiy8mJyfn0P9gB1Fd352fn89tt91Gu3btiIqKcsV8JN9fdenM9OnTAbxKZDz/fasVFRVx++2306ZNG2JiYujUqROPP/64+o43kPOHtCG1qhVe1p5ivl2y9RCPkLqaNGczT/+yhpXbCnj6lzVMeGYGs9bu8msM01fvZHu+tbBWemIM47o19evzi0jo0Ui51PDmm29SUVHBBRdcQM+ePQ95fmRkzR+jm2++mRkzZnDSSSdx4oknEhFhjWLNnTuXY445hoKCAk499VR69OjBypUref/99/nyyy+ZMmUKgwYN8sn3ccEFFzBjxgwmTJhAcnIy3333HU888QQ7duzgzTff9Dr3qaee4rbbbiM1NZVLLrmE1NRUfvzxR4466ihSUlLqFUdZWRnjxo1jz549HHfccSQnJ9O+ffsjvk516cxbb73Fpk2bvEpl9i+RKS8v57jjjiMnJ4cJEyYQGRnJF198wZ133klJSUmtZTZSPwkxkVx2VDue/sV6c/nC1HWc0qelJv752Mpt+Tz49XKvYxt2FXLBa39yZv9W/Ouk7jROjGnwOD706E1+1sBWROlTERGpJyXlUsPvv/8OwLhx4+p8jfnz57NgwQKv5NM0TS655BLy8/N57733uPDCC133ffTRR5x33nlcdNFFLF++3Cerqq5bt45ly5aRlpYGwCOPPELfvn155513ePTRR2nevDlgjUDfeeedNGrUiPnz57sS3EcffZRzzjmHzz77rF5xbN26lR49ejB9+nTX0vV1UV06M23aNDZt2nTQUpmcnBz69u3Lzz//TFxcHGDVu3fp0oWnnnqKf/7zn0RFaYETX7vsqHa88tt6isoqWbW9gCkrd3Bsj2Z2hxUyisoquHHSAkornABkpMWRW1hOQVUbys8WZPPrqh3cNaEb5wzMaLA3RDsKSvh15Q7XvnqTi4gvKCk/Au3u/NbuEA7bxsdOqvNjt23bBkCrVjWXit64cSNvvfWW17HU1FRuueUWr2N33HFHjdHgWbNmsXLlSoYPH+6VkANMnDiR5557jpkzZzJz5kxGjRpV5/irPf74466EHCAhIYELL7yQBx98kHnz5nHyyScD8P7771NWVsadd97pNeLscDj4z3/+wxdffIHT6axXLE8++WS9EvK6+N///udKyMEqNzrttNN45513WLVqFb169fJrPOEgNT6ai4a15ZXf1gPw/NS1HNO9qbrl+MiDXy9n7Y59AMRFRfDmZYNJjo3igW+W8+1iq1wot6icf3y6hE8zs3nkjF50bpbk8zg+zcym0mmVgQ1pl0aHJok+fw4RCT/6vE1qqK45ri2R2LhxIw888IDX7emnn65x3pAhQ2ocmz9/PnDgEfjq4wsWLKhr6F5qK4PJyLBGtPbu3VsjrtGjR9c4v0OHDq7H1FVsbCx9+vSp1zWOVEpKCp06dapxvLbvX3zryqPbE11VyrAwK9fVMk/q5+tFOV4lIw+c2pNOTZNomhzL8xcM4M3LB9O6kftN6JyNezjxfzP474+rfNqi0jRNr64rmuApIr6ipFxqaNGiBQDZ2dk17hszZgymaWKaJuXl5Qe8RnVpiKfqLi3V1z/Q8+bm5h5pyLVKTU2tcay6/r2y0v1HujquZs1qLzOo7Xs5Ek2b+n+ktLbvHWr//sW3miXHcvag1q79F6auszGa0LB5dxH//GyJa//Uvi05x+PfGGBs16b8fOtorh3dkciqspXySpPnpq7l+Kd/Y8aanT6JZc6GPWzYVQhAUkwkJ/au/fVMRORIqXzlCNSnJCSYjBgxgqlTpzJlyhSuuOKKOl2jtiS0esJkdXnM/rZu3ep1HuCqLa+oqLl0ua+S9+rn2759e60TWw8U7+E6WELuj+9P/O/aUR35cM5mnCbMXLuLRVm59M1ItTusoFRW4eSvHy5w1Y23SYvnkTN61fp7FRcdwZ0TunF6/5b887MlzN+cC8Cm3UVc/PocTuvXkrtP6kGTpLpPBP3IY5T81H4tiYv2bytGEQldGimXGi677DIiIyOZPHkyK1as8Nl1+/fvD3DAFS6rjw8YMMB1rFGjRgBkZWXVOH/evHk+iav6+apbDXpav359rc/tK3X5/qo72Wi0O3C1aRzPKX1buvZfmLbWxmiC25M/rWJRVi4AkQ6DZ8/vT1LswScpd2uezORrj+KRM3qRFOsee/pyYQ7jn5zGB3M243QeeWvQ/JJyvvNodanSFRHxJSXlUkPHjh25++67KSsrY8KECcyaNavW8450JHfEiBF07dqVmTNnMnnyZK/7Jk+ezG+//UaXLl04+uijXcera9NfffVVr/OXLFnCM888c0TPfyAXXnghUVFRPPvss179wp1OJ7fffnu9J3keTF2+v8aNGwOwefPmBotL6u+6MR1d2z8u286a7QU2RhOcpq/eyctVk2YB/nFCt8P+xMHhMLhwaFum/G00p3q8QcovqeCuz5Zw7st/sGrbkf2ffLUwh5Jy6/Wge4tkereqX7tUERFPKl+RWt17772YpslDDz3EiBEjGDhwIEOGDCEtLY3c3Fw2btzIL7/8AnDYnVIMw+Dtt9/m2GOPZeLEiZx22ml069aNVatW8cUXX5CUlMQ777zj1Q7xtNNOo3PnznzwwQds2bKFoUOHsnnzZr788ktOO+00Pv7443p/r+3ateOxxx7jb3/7G/3792fixImkpKTw448/kpubS58+fVi8eHG9n6c2dfn+xo8fzyeffMKZZ57JiSeeSFxcHG3btuXiiy9ukBilbro1T+aY7k35ZYXVOu/F6ev4v3P72RtUENmRX8JtHy107Y/u0oQrjz7y/v5Nk2L53/n9OXtga+7+Yimb9xQBMG/TXk763wyuGdWBv47rfFhlKB95TDSdOKi1uuqIiE9ppFxqVb2S5PLly7nllluoqKhg0qRJPP7440yaNInt27dz3XXXkZmZyTvvvHPY1x06dChz587lggsu4I8//uA///kPs2bN4vzzz2fu3LkMHTrU6/zY2FimTJnCueeey9KlS3nuuedYv349kyZN4rrrrvPZ93vbbbcxadIk2rdvz1tvvcUbb7xBr169mDVrlqvEpCHU5fu76qqruOuuu8jLy+OJJ57gnnvu4fXXX2+wGKXurh/r7oDz5cIcsqoSQjk4p9Pkto8XsbvQWn23SVIMT57bt159x0d1acJPt47ihrHuiaAVTpMXpq3juKenM23VjoM+fllOHkuyrUnh0ZEOTu9fs2WsiEh9GOGw5LZhGJkDBgwYkJmZedDzquunu3fv7o+wRAKefifq7/xXZrvaIl4yvC0Pnqb+8IfywrS1PPHDKgAMA967cigjOqX77Pqrtxfwz8+WMG+Td2vQU/q25J6Tu9M0KbbGY+77cilv/7EJsLq//O/8/j6LR0RCy8CBA5k/f/580zQHHsnjNFIuItKArh/rri3/cG4WOwpKbIwm8GVu2suTP6127V8/pqNPE3KALs2S+Pgvw3nszN6kxLknjX69KIfxT07nvdmbvCaClpRX8vkCd4vY8zTBU0QagJJyEZEGdHSndPq0tiYEllU4eWPmRnsDCmB5ReXc9MEC12qZA9s24pZjujTIczkcBucNacOUv43mDI9SlIKSCu7+YilnvTSLldvyAfhx2TbyS6yWjBlpcQzr0LhBYhKR8KakXESkARmGwfVj3LXl783eRF7xgRfeClemaXLnZ4vJzi0GIDk2kmfO60dURMP+mUpPjOGpif1478qhtGsc7zq+YHMuJ/1vJo9+v4L3Z7s7HU0clFGv2nYRkQNRUi4i0sCO69GMTk0TAdhXWsG7f2y0N6AANGnOZr5f6l6o64mz+9C6UfxBHuFbR3dO54dbRnHTuE5ERVhJd6XT5OXp65mzcQ8ADgPOHqjSFRFpGErKRUQamMNhcN1od235G79vpLhMiz9VW7ktnwe/Xu7av2hYG07o5f/l62OjIrjtuK58f/NIhrRPq3H/mK5NaZ5ScxKoiIgvKCkXEfGDU/u1pFVqHAB7Csv4cK4WfwIoLqvkxkkLKK2wFuXp1jyJu0/qYWtMnZom8dE1w3ji7D6kxrsngl48rK2NUYlIqFNSLiLiB1ERDv4yuoNr/5Xf1lNW0XCrxQaLB79Zxtod+wCIi4rguQv6Ext16IV8GpphGJw7KIMpt43m9uO78vTEfozt1tTusEQkhCkpFxHxk3MHZZCeGA3A1rwSvvBosxeOvl6Uwwdz3Ktk3n9qDzo1TbIxopoaJ8Zww9hOWixIRBqcknIRET+JjYrgyqPdo+UvTV/nav8XbjbvLuKfny1x7Z/StyXnDtIkShEJX0rKRUT86KJhbUiKjQRg/a5CfvDoOBIuyiud/PXDBRSUWr2/26TF88gZvTAMtRoUkfClpFxExI+SYqO4dHg71/7zU9dimuE1Wv7fn1axKCsXgEiHwf/O709ybNTBHyQiEuKUlIuI+NnlI9oRG2W9/C7fms/jP6yitCI8WiROX72Tl6evd+3fcUJX+mWk2heQiEiAUFIuIuJnjRNjOG9wG9f+S9PXceqzv7N4S659QfnBjvwSbvtooWt/dJcmXOVRYy8iEs6UlEvQMQyDMWPGeB27//77MQyDadOmNchzbty4EcMwuOyyyxrk+hJ+/nZcF4Z6LFCzansBZ7wwiyd+WElJeeiNmjudJrd9vIjdhWUANEmK4clz+2rJehGRKkrKpVaGYXjdIiIiSE9PZ9y4cbz//vt2h9cgakv2RRpKUmwUH1w9jAdO7UlcVV/uSqfJC9PWcfKzM1mwea/NEfrWS7+tY+baXQAYBjx1bj/SE2NsjkpEJHBE2h2ABLb77rsPgPLyclatWsUXX3zB1KlTyczM5P/+7/9sjs7txhtv5LzzzqNNmzaHPrkOWrVqxYoVK0hJSWmQ60t4cjgMLj2qHWO7NuWOTxcxe/0eANbu2MdZL87i6lEduPWYLgGxmE59ZG7ay5M/rXbtXz+mI0d3TrcxIhGRwKOkXA7q/vvv99qfMmUKxx57LE8//TQ33XQT7dq1syWu/aWnp5Oe3nB/5KOioujWrVuDXV/CW5vG8Uy6ahjvz9nMo9+toKisEqcJL09fz8/Lt/Ofs/sysG0ju8Osk7zicm76YIGrH/uANqncckwXm6MSEQk8Kl+RIzJ+/Hi6deuGaZrMnTsX8K7nnjRpEkOHDiUxMdErYS8qKuLRRx+lX79+JCQkkJiYyPDhw/nggw9qfZ6ysjIeeughOnbsSExMDO3bt+fuu++mtLS01vMPVlO+cuVKrrjiCtq1a0dMTAxNmzZl5MiRvPjiiwC89dZbrv7I06dP9yrbqX5TcrCa8q1bt3LDDTfQrl07oqOjadKkCWeeeSaZmZk1zq1+rrfeeoupU6cyZswYkpKSSE5O5qSTTmLFihUH+qeXEOdwGFw8rC0/3jKKozo2dh1fv7OQs1+axcPfLKe4LLhqzU3T5M5PF5OdWwxAcmwkz5zXn6gI/ekREdmfRsrliFX3VN5/oY8nn3ySn3/+mVNOOYWxY8eSl5cHQG5uLuPGjWPBggUMGDCAK664AqfTyY8//sgFF1zAsmXLePjhh72uf+655/Lll1/SsWNHbrzxRsrKynjjjTdYsmQJR+Lbb7/lnHPOobS0lBNOOIHzzz+f3NxcFi1axBNPPMF1111Hv379uO+++3jggQdo27atV+J9qBrzDRs2cPTRR5OTk8O4ceM4//zzycrK4pNPPuHbb7/l008/5eSTT67xuG+++YYvv/ySCRMmcO2117J8+XK+++475s6dy/Llyxt01F8CW0ZaPO9fNZQP5mTxyLfLKSyrxDThtZkbmLJyB0+c3YfB7dIOfaEAMGnOZr73WBzp8bP6kJEWb2NEIiIBzDTNkL8BmQMGDDAPZfny5eby5csPeV44AEzrx8Pbzz//bBqGYRqGYW7cuNE0TdO87777TMCMj48358+fX+Mxl156qQmYjz/+uNfx4uJi8/jjjzcNwzAXLFjgOv7++++bgDls2DCzuLjYdXz37t1mhw4dTMAcPXq017WqY5g6darr2M6dO83k5GQzKirKnDZtWo24srKyanzP+1+32oYNG0zAvPTSS72OH3fccSZgPvzww17Hf//9dzMiIsJMS0szCwoKXMfffPNNEzAjIiLMX375xesxd955Z63/TnbS74S9svYUmhe9Ntts+49vXLd2d35j3v/VUrOwtNzu8A5qxdY8s8u/vnPF/c/PFtsdkoiIXwwYMMAEMs0jzFc1Un4k7g+iSX735/nmMlXlG54TPU3T5NZbb6Vt27Ze515zzTX079/f69ju3bt57733GDRoEHfccYfXfbGxsTz++OP8+OOPTJo0iX79+gHw5ptvAvDvf/+b2NhY1/lpaWncc889XH755YcV+9tvv01+fj433XQTo0ePrnF/69atD+s6B7JlyxZ++ukn2rRpU+N7O+qoozj//PN57733+Oyzz7jkkku87j/vvPMYP36817FrrrmGxx57jDlz5tQrLgkdrRvF884VQ/h4XhYPf7OCgtIKTBPe/H0jv67cwRNn9WFoh8aHvpCfFZdVcuOkBZRWOAHo2iyJe07uYXNUIiKBTUm5HNQDDzwAWKUqqampjBw5kiuvvJKLLrqoxrlDhgypcWzu3LlUVlZ61Wd7Ki8vB/CqpZ4/fz4Oh4Ojjz66xvlH0rJw9uzZAEyYMOGwH3MkFixYAMDIkSOJiqq5RPi4ceN47733WLBgQY2kfNCgQTXOz8jIAGDv3tBqhSf1YxgGEwe3YWTnJtz12RKmr94JwKbdRUx8ZTaXDm/LHSd0IyEmcF7OH/xmGWt37AMgNsrBcxf0D/oOMiIiDS1wXsUlIJlV9eOHo3nz5jWO7d69G7CS8+qJobXZt2+fazsvL4+0tLRaE93anuNAcnNzAaudYUOorplv0aJFrfdXH6+Ow1NqamqNY5GR1q9jZWVwTeYT/2iZGsdblw9mcuYWHvxmOQUlFQC8/ccmfl21g8fP6sNRHe2fi/D1ohw+mJPl2n/g1J50bpZkY0QiIsFBSfmR8FFJSKjaf+In4Orrfeuttx52X/OUlBT27NlDeXl5jcR827ZtB3hUTdWJb3Z2Nr179z7sxx2u6u/tQDFt3brV6zyR+jIMg3MGZTCycxP++fkSfl25A4CsPcVc8OqfXDSsDXdO6E6iH0fNyyqcrNlRwLLsfJbm5PHZ/GzXfSf3acG5gzL8FouISDBTUi4NasiQITgcDmbMmHHYjxkwYAC//PILM2fOZOzYsV731dby8ECGDRvG5MmT+f777znhhBMOeb7D4TiiUerq+vmZM2dSUVHhGumuNnXqVMD6fkR8qXlKLK9fOojPF2Rz/1fLyK8aNX9v9mamrtzJE2f3YUQn34+al5RXsmJrPktz8lmWncfSnDxWb9tHWaWzxrkZaXH8+8zetb5ZFxGRmtQsVhpU06ZNufDCC5k3bx4PPfQQFRUVNc5Zt24dGzZscO1XT+T817/+RUlJiev4nj17vFonHsqll15KcnIyL774Ir/99luN+7ds2eK137hxY7KysmqcdyCtW7fm2GOPZePGjTz99NNe9/35559MmjSJRo0accYZZxz2NUUOl2EYnDmgNb/cNppjujdzHc/OLebC1/7kn58voaCkvM7X31dawZwNe3hj5gZu+3ghxz/1Gz3v+5EzXpjFPV8s5cO5WSzNzq81IU9PjOG58weQHFuzBE1ERGqnkXJpcM899xxr1qzh3nvv5d133+Xoo4+mWbNm5OTksGLFCubOncsHH3xA+/btATj//PP56KOP+Oqrr+jVqxennXYa5eXlTJ48mcGDB7Nu3brDet709HQmTZrE2WefzdixY5kwYQJ9+vQhPz+fxYsXk5WV5fVmYPz48Xz44YeccsopDBw4kMjISEaNGsWoUaMO+BwvvfQSI0aM4Pbbb+enn35i0KBBrj7lDoeDN998k6Qk1dNKw2maHMurlwzkq0U53PfVMnKLrER80p+bmbZyB4+d1YdRXZoc9Bp7C8tYlmOVnyzNzmNZTj4bdhUedgytG8XRq2UKvVol07NVCoPaNiJJCbmIyBFRUi4NLjk5menTp/PKK68wadIkPv30U0pKSmjWrBmdO3fmqaee4thjj3WdbxgGn3zyCY899hhvvfUWzz33HC1atODyyy/n3nvv9WqTeCgnnXQS8+bN4/HHH2fKlCn89NNPNGrUiG7dunHXXXd5nfvMM89gGAZTpkzhu+++w+l0ct999x00Ke/QoQPz5s3j4Ycf5rvvvmPatGkkJydzwgkn8K9//YvBgwcf+T+YyBEyDIPT+rVieMfG3PPFUn5cth2AnLwSLnljDhMHZfCvk7uTHBvFjoISq/67qvxkaXa+a8XNQz8PtE9PoGfLFHq1TKZXqxR6tkwmNT66Ib89EZGwYBxJd41gZRhG5oABAwbUtuy5p+q2fN27d/dHWCIBT78Twcc0Tb5ZvJV7v1zK3iJ3+Up6YjQOw2BHQelhXSfCYdC5aaKVgLeyEvDuLZL9OolURCQYDRw4kPnWaooDj+RxenUVEQkhhmFwSt+WDO/YmPu+XMa3S6wuQLv2lR3wMdERDrq1SHIl4D1bptCteZJ6i4uI+JGSchGREJSeGMPzFw7gxKpR892FVlIeFxVBj5bJ9Gpp1X/3aplC52aJREVo3r+IiJ2UlIuIhLCT+rRgdNcmLMvOo3FiDO3TE4hwqE2hiEigUVIuIhLiEmMiGdqhsd1hiIjIQejzShERERERmykpFxERERGxmZJyEalVOLRLFRERCRRKyj0YhjX5yemsuWy0SLipTsqrfy9ERESk4Sgp9xATEwNAYeHhLy8tEqqqfw+qfy9ERESk4Sgp95CUlATAtm3bKCgowOl06iN8CSumaeJ0OikoKGDbtm2A+/dCREREGo5aInpIS0ujsLCQoqIitmzZYnc4IraLj48nLS3N7jBERERCnpJyDw6Hg4yMDPbs2UNBQQGlpaUaKZewYxgGMTExJCUlkZaWhsOhD9REREQampLy/TgcDtLT00lPT7c7FBEREREJExoCExERERGxmZJyERERERGbKSkXEREREbGZknIREREREZspKRcRERERsZmSchERERERmykpFxERERGxmREOi+MYhrE7Li4urXv37naHIiIiIiIhbMWKFRQXF+8xTbPxkTwuXJLyDUAysNHPT92t6utKPz+vBC79TIgn/TyIJ/08yP70MxGc2gH5pmm2P5IHhUVSbhfDMDIBTNMcaHcsEhj0MyGe9PMgnvTzIPvTz0R4UU25iIiIiIjNlJSLiIiIiNhMSbmIiIiIiM2UlIuIiIiI2ExJuYiIiIiIzdR9RURERETEZhopFxERERGxmZJyERERERGbKSkXEREREbGZknIREREREZspKRcRERERsZmSchERERERmykpFxERERGxmZLyBmAYRmvDMN4wDCPHMIxSwzA2GobxtGEYjeyOTfyv6v/fPMBtm93xie8ZhnG2YRjPGoYxwzCM/Kr/6/cO8ZijDMP4zjCMPYZhFBmGsdgwjFsMw4jwV9zScI7kZ8IwjHYHec0wDcP40N/xi+8YhtHYMIyrDMP43DCMtYZhFBuGkWcYxkzDMK40DKPW3EyvEaEv0u4AQo1hGB2BWUBT4EtgJTAEuBk4wTCMEaZp7rYxRLFHHvB0Lcf3+TkO8Y+7gb5Y/79bgG4HO9kwjNOAT4ES4CNgD3AK8BQwAjinIYMVvziin4kqi4Avajm+1HdhiQ3OAV4EtgJTgc1AM+BM4DVggmEY55geqzvqNSI8aEVPHzMM40fgOOAm0zSf9Tj+f8CtwMumaV5rV3zif4ZhbAQwTbOdvZGIvxiGMRYr8VoLjMb6w/u+aZoX1XJuctV5KcAI0zTnVR2PBX4FhgPnm6ap0dEgdoQ/E+2ADcDbpmle5scwxQ8MwxgHJADfmqbp9DjeHJgDZABnm6b5adVxvUaECZWv+JBhGB2wEvKNwPP73X0fUAhcbBhGgp9DExE/Mk1zqmmaa8zDG/U4G2gCfFj9x7bqGiVYo6sA1zVAmOJHR/gzISHMNM1fTdP82jMhrzq+DXipaneMx116jQgTKl/xrXFVX3+q5ZetwDCM37GS9mHAFH8HJ7aKMQzjIqAN1puzxcBvpmlW2huWBIDq140farnvN6AIOMowjBjTNEv9F5YEgJaGYfwFaAzsBv4wTXOxzTFJwyqv+lrhcUyvEWFCSblvda36uvoA96/BSsq7oKQ83DQH3t3v2AbDMC43TXO6HQFJwDjg64ZpmhWGYWwAegIdgBX+DExsd2zVzcUwjGnApaZpbrYlImkwhmFEApdU7Xom4HqNCBMqX/GtlKqveQe4v/p4asOHIgHkTWA8VmKeAPQGXgbaAd8bhtHXvtAkAOh1Q/ZXBDwEDAQaVd2q69DHAFNUBhmSHgN6Ad+Zpvmjx3G9RoQJJeX+ZVR9VU1hGDFN84GqGsLtpmkWmaa5tGqy7/8BccD99kYoAU6vG2HGNM0dpmnea5rmfNM0c6tuv2F90von0Am4yt4oxZcMw7gJ+BtWx7aLj/ThVV/1GhHklJT7VvW71ZQD3J+833kS3qon9IyyNQqxm1435LCYplmB1TIP9LoRMgzDuAF4BlgOjDVNc89+p+g1IkwoKfetVVVfuxzg/s5VXw9Ucy7hZUfVV30MHd4O+LpRVWPaHmvS13p/BiUBa2fVV71uhADDMG4BnsPqPT+2qgPL/vQaESaUlPvW1Kqvx+2/IpdhGElYDf6Lgdn+DkwC0vCqr3ohDW+/Vn09oZb7RgHxwCx1VZAqw6q+6nUjyBmG8Q+sxX8WYiXkOw5wql4jwoSSch8yTXMd8BPWBL4b9rv7AayRjXdM0yz0c2hiE8MwehqGkVbL8bZYoyMAB11+XULeZGAXcJ5hGIOqD1YtDPJw1e6LdgQm9jAMY6hhGNG1HB+HtQgd6HUjqBmGcQ/WxM5MYLxpmrsOcrpeI8KEVvT0McMwOgKzgKbAl1jtiYYCY7HKVo4yTXO3fRGKPxmGcT9wJ9anKBuAAqAjcBIQC3wHnGGaZpldMYrvGYZxOnB61W5z4Hiskc0ZVcd2mab59/3On4y1hPaHWEton4rVCm0ycK4WnQluR/IzUdX2sCcwDWsVUIA+uPtV32OaZnUyJkHGMIxLgbeASuBZaq8F32ia5lsejzkdvUaEPCXlDcAwjAzgQayPmhoDW4EvgAdqmcAhIcwwjNHAtUB/3C0Rc7E+rnwXeFcvpKGn6s3YfQc5ZZNpmu32e8wI4F9YZU2xWMtqvwH8T4tMBb8j+ZkwDONK4Ays9njpQBSwHfgDeM40zRkHuogEvsP4WQCYbprmmP0ep9eIEKekXERERETEZqopFxERERGxmZJyERERERGbKSkXEREREbGZknIREREREZspKRcRERERsZmSchERERERmykpFxERERGxmZJyERERERGbKSkXEREREbGZknIREREREZspKRcRERERsZmSchERERERmykpFxERERGxmZJyERERERGbKSkXEREREbGZknIREREREZspKRcRERERsdn/Awt5d//FTdSNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 370
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw HUFL (High UseFul Load) prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[0,:,0], label='GroundTruth')\n",
    "plt.plot(preds[0,:,0], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
