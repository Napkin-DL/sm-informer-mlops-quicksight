{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Pipeline\n",
    "--------------\n",
    "\n",
    "[Amazon SageMaker 모델 구축 파이프라인](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines.html)를 이용하여 ML workflow의 각 단계별 수행을 통해, 모델 학습과 모델 registry에 등록하는 과정에 대한 파이프라인을 만듭니다. \n",
    "\n",
    "<p align=\"center\">\n",
    "<center><img src=\"./img/mdp_how_it_works.png\" height=\"250\" width=\"850\" alt=\"\"><center>\n",
    "<br><br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import 패키지 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "# import splitfolders\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import strftime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "region = sess.region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 저장소와 코드 저장소 설정\n",
    "### 2-1. 데이터 저장소 설정\n",
    "SageMaker에는 학습에 사용할 데이터 위치와 학습 코드의 위치를 설정합니다. 편의를 위해 default_bucket을 사용했으나, 실제 활용 시에는 이미 생성한 bucket을 활용하는 것도 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "sess = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "%store default_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 코드 저장소 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = boto3.client('iam')\n",
    "\n",
    "role=get_execution_role()\n",
    "base_role_name=role.split('/')[-1]\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=base_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AWSCodeCommitFullAccess'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codecommit = boto3.client('codecommit')\n",
    "repository_name = 'informer2020'\n",
    "\n",
    "try:\n",
    "    response = codecommit.create_repository(\n",
    "        repositoryName=repository_name,\n",
    "        repositoryDescription='Data Scientists share their training code using this Repository'\n",
    "    )\n",
    "except:\n",
    "    \n",
    "    print(\"Repository already exists\")\n",
    "    response = codecommit.get_repository(\n",
    "        repositoryName=repository_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_commit_repo = response['repositoryMetadata']['cloneUrlHttp']\n",
    "code_commit_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git init\n",
    "!git remote add repo_codecommit $code_commit_repo\n",
    "!git add Informer2020\n",
    "!git commit -m \"Inform2020-update\"\n",
    "!git push repo_codecommit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. CodeCommit Credentials 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = 'XXXXX' ## ==> IAM에서 사용자 아이디 확인\n",
    "codecommit_cred = 'codecommit-cred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = iam_client.list_service_specific_credentials(\n",
    "        UserName=user_name,\n",
    "        ServiceName='codecommit.amazonaws.com'\n",
    "    )\n",
    "    if len(response['ServiceSpecificCredentials']) > 0:\n",
    "        response = iam_client.delete_service_specific_credential(\n",
    "            UserName=user_name,\n",
    "            ServiceSpecificCredentialId=response['ServiceSpecificCredentials'][-1]['ServiceSpecificCredentialId']\n",
    "        )\n",
    "except:\n",
    "    print(\"Create new codecommit crendentials\")\n",
    "    pass\n",
    "finally:\n",
    "    response = iam_client.create_service_specific_credential(\n",
    "        UserName=user_name,\n",
    "        ServiceName='codecommit.amazonaws.com'\n",
    "    )\n",
    "    ServiceUserName = response['ServiceSpecificCredential']['ServiceUserName']\n",
    "    ServicePassword = response['ServiceSpecificCredential']['ServicePassword']\n",
    "print(f\"ServiceUserName : {ServiceUserName} \\nServicePassword : {ServicePassword}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Secret Manager (Optional)\n",
    "CodeCommit의 Credentials 정보를 Secret Manager에 Key, Value로 넣어놓고 안전하게 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client.attach_role_policy(\n",
    "    RoleName=base_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/SecretsManagerReadWrite'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_client = boto3.client('secretsmanager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "secret_string = json.dumps({\n",
    "      \"username\": ServiceUserName,\n",
    "      \"password\": ServicePassword\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_list = sec_client.list_secrets()['SecretList']\n",
    "\n",
    "if len(sec_list) == 0:\n",
    "    sec_response = sec_client.create_secret(\n",
    "        Name=codecommit_cred,\n",
    "        Description='This credential uses git_config for SageMaker in Lambda',\n",
    "        SecretString=secret_string,\n",
    "        Tags=[\n",
    "            {\n",
    "                'Key': 'Name',\n",
    "                'Value': 'codecommit_credentials'\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    sec_response = sec_client.update_secret(\n",
    "        SecretId=sec_list[0]['ARN'],\n",
    "        SecretString=secret_string\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name = sec_response['ARN']\n",
    "secret_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SageMaker Pipelines 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments 관리\n",
    "\n",
    "Amazon SageMaker에는 실험을 관리할 수 있는 [SageMaker Experiments](https://aws.amazon.com/ko/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings/) 서비스가 있습니다. 반복적인 실험에 대해 로깅을 남기기 위한 실험 이름 (create_experiment)과 trial (create_trial) 이름을 설정하는 함수입니다. <br> 이러한 메타 정보를 이용하여 향후 ML의 실험 관리가 용이해 질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                          tags=[{'Key': 'modelname', 'Value': 'informer'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name, i_type, i_cnt, spot=False):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    algo = 'informer'\n",
    "    \n",
    "    spot = 's' if spot else 'd'\n",
    "    i_type = i_type[3:9].replace('.','-')\n",
    "        \n",
    "    trial = \"-\".join([i_type,str(i_cnt),algo, spot])\n",
    "       \n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{trial}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 실험 설정\n",
    "\n",
    "학습 시 사용한 소스코드와 output 정보를 저장할 위치를 선정합니다. 이 값은 필수로 설정하지 않아도 되지만, 코드와 결과물을 S3에 저장할 때 체계적으로 정리하는데 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_location = f's3://{default_bucket}/poc_informer/sm_codes'\n",
    "output_path = f's3://{default_bucket}/poc_informer/output' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험에서 표준 출력으로 보여지는 metrics 값을 정규 표현식을 이용하여 SageMaker에서 값을 capture할 수 있습니다. 이 값은 필수로 설정하지 않아도 되지만, SageMaker Experiments에 Metrics 정보를 남길 수 있어서 실험 관리에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'Epoch', 'Regex': 'Epoch: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "    {'Name': 'train_loss', 'Regex': 'Train Loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "    {'Name': 'valid_loss', 'Regex': 'Valid Loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "    {'Name': 'test_loss', 'Regex': 'Test Loss: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 실험 조건을 테스트하기 위해 hyperparameters로 argument 값들을 노트북에서 설정할 수 있으며, 이 값은 학습 스크립트에서 argument인 변수로 받아서 활용이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'model' : 'informer', # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "        'data' : 'ETTh1', # data\n",
    "        'root_path' : 'ETT-small/', # root path of data file\n",
    "        'data_path' : 'ETTh1.csv', # data file\n",
    "        'features' : 'M', # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "        'target' : 'OT', # target feature in S or MS task\n",
    "        'freq' : 'h', # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "        'checkpoints' : 'informer_checkpoints', # location of model checkpoints\n",
    "\n",
    "        'seq_len' : 96, # input sequence length of Informer encoder\n",
    "        'label_len' : 48, # start token length of Informer decoder\n",
    "        'pred_len' : 24, # prediction sequence length\n",
    "        # Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "        'enc_in' : 7, # encoder input size\n",
    "        'dec_in' : 7, # decoder input size\n",
    "        'c_out' : 7, # output size\n",
    "        'factor' : 5, # probsparse attn factor\n",
    "        'd_model' : 512, # dimension of model\n",
    "        'n_heads' : 8, # num of heads\n",
    "        'e_layers' : 2, # num of encoder layers\n",
    "        'd_layers' : 1, # num of decoder layers\n",
    "        'd_ff' : 2048, # dimension of fcn in model\n",
    "        'dropout' : 0.05, # dropout\n",
    "        'attn' : 'prob', # attention used in encoder, options:[prob, full]\n",
    "        'embed' : 'timeF', # time features encoding, options:[timeF, fixed, learned]\n",
    "        'activation' : 'gelu', # activation\n",
    "        'distil' : True, # whether to use distilling in encoder\n",
    "        'output_attention' : False, # whether to output attention in ecoder\n",
    "        'mix' : True,\n",
    "        'padding' : 0,\n",
    "        'freq' : 'h',\n",
    "        'do_predict' : True,\n",
    "        'batch_size' : 32,\n",
    "        'learning_rate' : 0.0001,\n",
    "        'loss' : 'mse',\n",
    "        'lradj' : 'type1',\n",
    "        'use_amp' : False, # whether to use automatic mixed precision training\n",
    "\n",
    "        'num_workers' : 0,\n",
    "        'itr' : 1,\n",
    "        'train_epochs' : 1,  ## Training epochs\n",
    "        'patience' : 3,\n",
    "        'des' : 'exp',\n",
    "        'use_multi_gpu' : True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산학습과 spot 학습을 사용할지를 선정할 수 있습니다. <br>\n",
    "분산학습의 경우 [SageMaker data parallel library](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)를 사용하고자 할 경우 distribution을 아래와 같이 설정한 후 사용할 수 있습니다. 학습 스크립트는 분산 학습 Library로 구현이 필요합니다. 이번 Pipeline에는 분산설정을 추가하지 않았습니다. <br>\n",
    "[spot 학습](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)을 사용하고자 할 경우 학습 파라미터에 spot 파라미터를 True로 변경한 다음, 자원이 없을 때 대기하는 시간인 max_wait (초)를 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'informer-poc-exp1'\n",
    "distribution = None\n",
    "do_spot_training = True\n",
    "max_wait = None\n",
    "max_run = 1*30*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type=\"ml.m5.xlarge\"\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline parameters, checkpoints와 데이터 위치 설정\n",
    "\n",
    "[SageMaker Pipeline](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html)의 중요한 기능은 미리 단계를 정의한 다음, 파이프라인의 재정의 없이도 parameters를 실행 중인 단계에서 변경할 수 있다는 것입니다. parameters를 사용하여 이 작업을 수행할 수 있습니다. <br>\n",
    "ParameterInteger, ParameterFloat, ParameterString를 사용할 수 있으며, 이후 `pipeline.start(parameters=parameters)`를 호출할 때 수정할 수 있는 값을 미리 정의합니다. 특정 parameters만으로 이러한 방식의 정의가 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_param = ParameterString(\n",
    "    name=\"TrainingInstance\",\n",
    "    default_value=\"ml.c5.4xlarge\",\n",
    ")\n",
    "\n",
    "train_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. checkpoints와 데이터 위치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = None\n",
    "train_job_name = 'informer'\n",
    "\n",
    "if do_spot_training:\n",
    "    max_wait = max_run\n",
    "\n",
    "print(\"train_job_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {} \\nimage_uri : {} \\ndistribution : {}\".format(train_job_name, train_instance_param.default_value, train_count_param.default_value, image_uri, distribution))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'ETDataset'\n",
    "inputs = f's3://{default_bucket}/dataset/{prefix}'\n",
    "\n",
    "source_dir = 'Informer2020'\n",
    "checkpoint_s3_uri = f's3://{default_bucket}/poc_informer/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3. Git 설정 (Secret Manager 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    secret = {}\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager'\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    get_secret_value_response = client.get_secret_value(\n",
    "        SecretId=secret_name\n",
    "    )\n",
    "        \n",
    "    if 'SecretString' in get_secret_value_response:\n",
    "        secret = get_secret_value_response['SecretString']\n",
    "        secret = json.loads(secret)\n",
    "    else:\n",
    "        print(\"secret is not defined. Checking the Secrets Manager\")\n",
    "\n",
    "    return secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CodeCommit의 Credentials이 저장된 secret_name 사용이 필요합니다.\n",
    "sec_client = boto3.client('secretsmanager')\n",
    "secret_name = sec_client.list_secrets(SortOrder='desc')['SecretList'][0]['ARN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"region : {region}\\nsecret_name : {secret_name}\\nrole : {role}\\ncode_commit_repo : {code_commit_repo}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret=get_secret(secret_name)\n",
    "\n",
    "git_config = {'repo': code_commit_repo,\n",
    "              'branch': 'main',\n",
    "              'username': secret['username'],\n",
    "              'password': secret['password']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습을 위한 Estimator 선언\n",
    "\n",
    "AWS 서비스 활용 시 role (역할) 설정은 매우 중요합니다. 이 노트북에서 사용하는 role은 노트북과 training job을 실행할 때 사용하는 role이며, role을 이용하여 다양한 AWS 서비스에 대한 접근 권한을 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name, instance_type, instance_count, spot=do_spot_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='main_informer.py',\n",
    "    source_dir=source_dir,\n",
    "    git_config=git_config,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.10',\n",
    "    py_version='py38',\n",
    "    instance_count=train_count_param,    ## Parameter 값으로 변경\n",
    "    instance_type=train_instance_param,  ## Parameter 값으로 변경\n",
    "#     volume_size=256,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_run=max_run,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    use_spot_instances=do_spot_training,  # spot instance 활용\n",
    "    max_wait=max_wait,\n",
    "    base_job_name=f\"training-{job_name}\",\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training 단계 선언\n",
    "\n",
    "[training 단계](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html)를 사용하여 모델을 학습하는 training job을 생성합니다.<br>\n",
    "training 단계에는 estimator, training과 validation 데이터 입력 등이 필요합니다. <br>\n",
    "\n",
    "[caching](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html) 를 사용하면 SageMaker 파이프라인이 단계를 실행하기 전에 동일한 인수를 사용하여 호출된 단계의 이전 실행을 찾으려고 시도합니다. 주의할 사항은 파이프라인은 인수가 가리키는 데이터 또는 코드가 변경되었는지 여부를 확인하지 않습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, \n",
    "                           expire_after=\"7d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = TrainingStep(\n",
    "    name=\"InformerTrain\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"training\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=inputs\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation 단계 - output에서 압축풀어 test_report.json 가져오기\n",
    "\n",
    "[SageMaker Processing](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep)는 데이터 전처리, 평가 결과의 후처리, 그리고 평가를 수행하는데 활용합니다. <br>\n",
    "이 단계에서는 Processing job의 예시를 보여주기 위해 압축된 모델 결과에서 압축을 푸는 작업만 수행합니다. processing 단계는 processor, processing 코드를 정의하는 python 스크립트, processing을 위한 output, job 관련 arguments 등으로 구성됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_processor = FrameworkProcessor(\n",
    "    PyTorch,\n",
    "    framework_version=\"1.10\",\n",
    "    py_version='py38',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    code_location=code_location,\n",
    "    base_job_name=f\"generatingreport-{job_name}\",  # choose any name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 Train 단계에서의 model 산출물을 postprocessing의 input으로 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = ProcessingInput(\n",
    "    source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    destination=\"/opt/ml/processing/model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_report = PropertyFile(\n",
    "    name=\"TestReport\",\n",
    "    output_name=\"result\",\n",
    "    path=\"test_report.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "run_args = framework_processor.get_run_args(\n",
    "    code=\"postprocess.py\",\n",
    "    source_dir=\"Informer2020\",\n",
    "    git_config=git_config,\n",
    "    inputs=[model_input],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"result\", source=\"/opt/ml/processing/result\")\n",
    "    ],\n",
    "    job_name=f\"process-step-{job_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing_step = ProcessingStep(\n",
    "    name=\"PostProcessingforInformer\",  # choose any name\n",
    "    processor=framework_processor,\n",
    "    inputs=run_args.inputs,\n",
    "    outputs=run_args.outputs,\n",
    "    code=run_args.code,\n",
    "    property_files=[test_report],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model 등록 단계\n",
    "\n",
    "[register model 단계](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.step_collections.RegisterModel)를 사용하여 sagemaker.model.Model 또는 sagemaker.pipeline.PipelineModel을 SageMaker의 model registry에 등록합니다. <br>\n",
    "PipelineModel은 inference pipeline을 나타내며, inference 요청을 처리하는 container들의 순서를 구성합니다. <br>\n",
    "register model 단계에서는 등록된 모델의 metrics를 json 구조로 통합하여 등록할 수 있으며, 모델 승인에 대한 방법을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = \"ts-prediction-informer-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model step that will be conditionally executed\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/test_report.json\".format(\n",
    "            postprocessing_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_step = RegisterModel(\n",
    "    name=\"InformerRegisterModel\",\n",
    "    estimator=estimator,\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Condition 단계\n",
    "\n",
    "[condition 단계](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.condition_step.ConditionStep)를 사용하여 단계 properties의 조건을 평가하여 파이프라인에서 다음에 수행할 작업을 진행할지 여부를 판단합니다. <br>\n",
    "\n",
    "condition 단계에는 condition 목록, condition이 참으로 평가될 경우 실행할 단계 목록, condition이 거짓으로 평가될 경우 실행할 단계 목록 등이 필요합니다. <br>\n",
    "\n",
    "`[제한사항]`\n",
    "- SageMaker 파이프라인은 nested condition 단계의 사용을 지원하지 않습니다. 즉, condition 단계를 다른 조건 단계의 입력으로 전달할 수 없습니다.\n",
    "- condition 단계는 두 개의 분기에서 동일 단계를 사용할 수 없습니다. 즉, 두 개의 분기에서 동일 단계의 기능이 필요한 경우 단계를 복제하고 다른 이름을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition step for evaluating model quality and branching execution\n",
    "cond_lte = ConditionLessThanOrEqualTo(  # You can change the condition here\n",
    "    left=JsonGet(\n",
    "        step=postprocessing_step,\n",
    "        property_file=test_report,\n",
    "        json_path=\"regression_metrics.mse.value\",  # This should follow the structure of your report_dict defined in the postprocess.py file.\n",
    "    ),\n",
    "    right=1.0,  # You can change the threshold here\n",
    ")\n",
    "cond_step = ConditionStep(\n",
    "    name=\"TestMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[register_step],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pipeline 수행\n",
    "\n",
    "지금까지 선언한 Step (단계)를 모두 통합합니다. step의 순서는 DAG을 고려하여 자동으로 정의가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"ts-prediction-informer-pipeline\",\n",
    "    parameters=[train_instance_param, train_count_param, model_approval_status],\n",
    "    steps=[\n",
    "        training_step,\n",
    "        postprocessing_step,\n",
    "        cond_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker pipeline 서비스에 정의된 pipeline를 제출하게 됩니다. 기존 정의된 동일한 이름의 pipeline이 있는 경우 덮어쓰기가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special pipeline parameters can be defined or changed here\n",
    "parameters = {\"TrainingInstance\": \"ml.c5.4xlarge\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_response = pipeline.start(parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline의 진행 사항을 모니터링할 수 있습니다. wait() 함수는 종료가 될 때까지 대기하기 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_response.wait()\n",
    "start_response.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "각 step 별로 진행사항을 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_response.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model 등록 실행\n",
    "\n",
    "아래 함수를 이용하여 현재 pending 중인 모델을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_model = sm.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelApprovalStatus='PendingManualApproval',\n",
    "    SortBy='Name',\n",
    "    SortOrder='Descending'\n",
    ")\n",
    "pending_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "아래 명령어를 이용하여 실제 승인을 수행하게 됩니다. 아래 예시는 가장 최근 등록된 버전의 모델을 가져와서 승인하도록 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\" : pending_model['ModelPackageSummaryList'][0]['ModelPackageArn'],\n",
    "    \"ModelApprovalStatus\" : \"Approved\"\n",
    "    }\n",
    "    model_package_update_response = sm.update_model_package(**model_package_update_input_dict)\n",
    "except:\n",
    "    print(\"승인된 모델이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "승인된 모델 중에서 가장 최신 버전의 모델을 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved_model = sm.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelApprovalStatus='Approved',\n",
    "    SortBy='Name',\n",
    "    SortOrder='Descending'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkg = sm.describe_model_package(ModelPackageName=approved_model['ModelPackageSummaryList'][0]['ModelPackageArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. SageMaker Model 생성\n",
    "승인된 모델 정보를 이용하여 들어오는 데이터에 대한 전/후처리가 포함된 predictor.py 파일을 포함하여 SageMaker 모델을 생성합니다.\n",
    "predictor.py의 전처리는 전체 데이터셋 (CSV)에서 학습에 활용하지 않은 테스트용 데이터셋을 짤라 Ground Truth 값을 제거하고 모델 입력 형태로 변환하는 작업을 합니다. 후처리는 예측된 결과와 Ground Truth 값을 다시 붙여서 결과 CSV로 S3에 저장하도록 구현하였습니다. \n",
    "\n",
    "\n",
    "향후 활용시에는 각각의 데이터셋과 모델 환경에 맞게 predictor.py를 구현하여 활용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    entry_point='predictor.py',\n",
    "    source_dir='Informer2020',\n",
    "    git_config=git_config,\n",
    "    code_location=code_location,\n",
    "    model_data=model_pkg['InferenceSpecification']['Containers'][0]['ModelDataUrl'],\n",
    "    role=role,\n",
    "    framework_version=\"1.10\",\n",
    "    py_version=\"py38\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. SageMaker batch transform job 수행\n",
    "앞에서 생성한 model을 이용하여 데이터셋 (CSV)의 위치가 있는 S3 URI와 입력되는 데이터의 형태, 결과 파일이 저장되는 S3 URI, 이 작업을 수행하는 인스턴스 타입과 개수를 지정하여 예측을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer= model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f\"s3://{default_bucket}/poc_informer/batch_result\",\n",
    "    env={'default_bucket': default_bucket}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "\n",
    "job_name=model_package_group_name+\"-\"+strftime(\"%m%d-%H%M%s\")\n",
    "\n",
    "batch_transform = transformer.transform(\n",
    "    data=f's3://{default_bucket}/dataset/ETDataset/ETT-small/ETTh1.csv',\n",
    "    data_type='S3Prefix',\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    job_name=f\"tranform-{job_name}\",\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
