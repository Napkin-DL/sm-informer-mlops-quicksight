{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff525bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "# from exp.exp_informer import Exp_Informer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb93f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'ETTh1' # data\n",
    "args.root_path = '/home/ec2-user/SageMaker/timeseries_practise/ETDataset/ETT-small/' # root path of data file\n",
    "args.data_path = 'ETTh1.csv' # data file\n",
    "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'OT' # target feature in S or MS task\n",
    "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 96 # input sequence length of Informer encoder\n",
    "args.label_len = 48 # start token length of Informer decoder\n",
    "args.pred_len = 24 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 7 # encoder input size\n",
    "args.dec_in = 7 # decoder input size\n",
    "args.c_out = 7 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.freq = 'h'\n",
    "\n",
    "args.batch_size = 32 \n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 1\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4bc3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a38e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1c48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO SageMaker DP\n"
     ]
    }
   ],
   "source": [
    "from data.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from models.model import Informer, InformerStack\n",
    "\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate\n",
    "from utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dist.sm_dist as sm_dist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Exp_Informer(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Informer, self).__init__(args)\n",
    "    \n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'informer':Informer,\n",
    "            'informerstack':InformerStack,\n",
    "        }\n",
    "        \n",
    "        if self.args.model=='informer' or self.args.model=='informerstack':\n",
    "            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n",
    "            model = model_dict[self.args.model](\n",
    "                self.args.enc_in,\n",
    "                self.args.dec_in, \n",
    "                self.args.c_out, \n",
    "                self.args.seq_len, \n",
    "                self.args.label_len,\n",
    "                self.args.pred_len, \n",
    "                self.args.factor,\n",
    "                self.args.d_model, \n",
    "                self.args.n_heads, \n",
    "                e_layers, # self.args.e_layers,\n",
    "                self.args.d_layers, \n",
    "                self.args.d_ff,\n",
    "                self.args.dropout, \n",
    "                self.args.attn,\n",
    "                self.args.embed,\n",
    "                self.args.freq,\n",
    "                self.args.activation,\n",
    "                self.args.output_attention,\n",
    "                self.args.distil,\n",
    "                self.args.mix,\n",
    "                self.device\n",
    "            ).float()\n",
    "        \n",
    "        if self.args.use_gpu:\n",
    "            model = sm_dist.dist_model(model.to(self.device))\n",
    "            model.cuda(self.args.local_rank)\n",
    "#             model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        args = self.args\n",
    "        data_dict = {\n",
    "            'ETTh1':Dataset_ETT_hour,\n",
    "            'ETTh2':Dataset_ETT_hour,\n",
    "            'ETTm1':Dataset_ETT_minute,\n",
    "            'ETTm2':Dataset_ETT_minute,\n",
    "            'WTH':Dataset_Custom,\n",
    "            'ECL':Dataset_Custom,\n",
    "            'Solar':Dataset_Custom,\n",
    "            'custom':Dataset_Custom,\n",
    "        }\n",
    "        Data = data_dict[args.data]\n",
    "        timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "        if flag == 'test':\n",
    "            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "        elif flag=='pred':\n",
    "            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "            Data = Dataset_Pred\n",
    "        else:\n",
    "            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "                        \n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "            freq=freq,\n",
    "            cols=args.cols\n",
    "        )\n",
    "        \n",
    "        #######################################################\n",
    "        ####### SageMaker Distributed Data Parallel     #######\n",
    "        #######  - Add num_replicas and rank            #######\n",
    "        #######################################################\n",
    "        train_sampler = None\n",
    "        \n",
    "        if self.args.use_gpu:\n",
    "            if flag == 'train':\n",
    "                shuffle_flag = False\n",
    "                train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                    data_set, num_replicas=args.world_size, rank=args.rank\n",
    "                ) \n",
    "        #######################################################\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            sampler=train_sampler,\n",
    "            drop_last=drop_last)\n",
    "\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "    \n",
    "    def _select_criterion(self):\n",
    "        criterion =  nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = []\n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n",
    "            pred, true = self._process_one_batch(\n",
    "                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n",
    "            total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag = 'train')\n",
    "        vali_data, vali_loader = self._get_data(flag = 'val')\n",
    "        test_data, test_loader = self._get_data(flag = 'test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "\n",
    "        if not os.path.exists(path) and self.args.local_rank==0:\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "        \n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "        \n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion =  self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                \n",
    "                model_optim.zero_grad()\n",
    "                pred, true = self._process_one_batch(\n",
    "                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "                loss = criterion(pred, true)\n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "                if (i+1) % 100==0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time()-time_now)/iter_count\n",
    "                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "                \n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f}, Valid Loss: {3:.7f}, Test Loss: {4:.7f},\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch+1, self.args)\n",
    "        \n",
    "        \n",
    "        \n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            sm_dist.barrier()\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "    def test(self, setting):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        preds = []\n",
    "        trues = []\n",
    "        \n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n",
    "            pred, true = self._process_one_batch(\n",
    "                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            trues.append(true.detach().cpu().numpy())\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "#         print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "#         print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = os.path.join(self.args.checkpoints, 'results/' + setting +'/')\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "        print('mse:{}, mae:{}'.format(mse, mae))\n",
    "\n",
    "        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "        np.save(folder_path+'pred.npy', preds)\n",
    "        np.save(folder_path+'true.npy', trues)\n",
    "\n",
    "        report_dict = {\"mse\" : mse, \"mae\": mae}\n",
    "        \n",
    "\n",
    "        report_dict = {\n",
    "            \"test_metrics\": {\n",
    "                \"mse\": {\n",
    "                    \"value\": float(mse)\n",
    "                },\n",
    "                \"mae\": {\n",
    "                    \"value\": float(mae)\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        test_output_path = self.args.checkpoints+\"/test_report.json\"\n",
    "        print(\"Saving classification report to {}\".format(test_output_path))\n",
    "\n",
    "        with open(test_output_path, \"w\") as f:\n",
    "            f.write(json.dumps(report_dict))\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "        \n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path+'/'+'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        self.model.eval()\n",
    "        \n",
    "        preds = []\n",
    "        \n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "            pred, true = self._process_one_batch(\n",
    "                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        \n",
    "        # result save\n",
    "        folder_path = os.path.join(self.args.checkpoints, 'results/' + setting +'/')\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        np.save(folder_path+'real_prediction.npy', preds)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        batch_y = batch_y.float()\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "        # decoder input\n",
    "        if self.args.padding==0:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        elif self.args.padding==1:\n",
    "            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n",
    "        # encoder - decoder\n",
    "        if self.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if self.args.output_attention:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        if self.args.inverse:\n",
    "            outputs = dataset_object.inverse_transform(outputs)\n",
    "        f_dim = -1 if self.args.features=='MS' else 0\n",
    "        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n",
    "\n",
    "        return outputs, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d4d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'ETTh1':Dataset_ETT_hour,\n",
    "    'ETTh2':Dataset_ETT_hour,\n",
    "    'ETTm1':Dataset_ETT_minute,\n",
    "    'ETTm2':Dataset_ETT_minute,\n",
    "    'WTH':Dataset_Custom,\n",
    "    'ECL':Dataset_Custom,\n",
    "    'Solar':Dataset_Custom,\n",
    "    'custom':Dataset_Custom,\n",
    "}\n",
    "Data = data_dict[args.data]\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "\n",
    "shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "Data = Dataset_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7f2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path=args.root_path\n",
    "data_path=args.data_path\n",
    "flag=\"pred\"\n",
    "size=[args.seq_len, args.label_len, args.pred_len]\n",
    "features=args.features\n",
    "target=args.target\n",
    "inverse=args.inverse\n",
    "timeenc=timeenc\n",
    "freq=freq\n",
    "cols=args.cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0e366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = size[0]\n",
    "label_len = size[1]\n",
    "pred_len = size[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89bfce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.tools import StandardScaler\n",
    "from utils.timefeatures import time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff53c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e24ddfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../Informer2020/predict_data_re.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "345f300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "border1 = len(df_raw)-seq_len\n",
    "border2 = len(df_raw)\n",
    "\n",
    "cols_data = df_raw.columns[1:]\n",
    "df_data = df_raw[cols_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "396c109d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.831999778747560</td>\n",
       "      <td>3.617000102996830</td>\n",
       "      <td>4.76200008392334</td>\n",
       "      <td>1.9539999961853000</td>\n",
       "      <td>2.497999906539920</td>\n",
       "      <td>1.1269999742507900</td>\n",
       "      <td>6.683000087738040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.357999801635740</td>\n",
       "      <td>3.95199990272522</td>\n",
       "      <td>2.45199990272522</td>\n",
       "      <td>2.0969998836517300</td>\n",
       "      <td>2.924000024795530</td>\n",
       "      <td>1.371000051498410</td>\n",
       "      <td>6.401999950408940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.692999839782720</td>\n",
       "      <td>3.3489999771118200</td>\n",
       "      <td>2.131999969482420</td>\n",
       "      <td>1.9900000095367400</td>\n",
       "      <td>3.13700008392334</td>\n",
       "      <td>1.4919999837875400</td>\n",
       "      <td>6.752999782562260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.223999977111820</td>\n",
       "      <td>2.1429998874664300</td>\n",
       "      <td>2.4159998893737800</td>\n",
       "      <td>1.1019999980926500</td>\n",
       "      <td>2.4670000076293900</td>\n",
       "      <td>1.2489999532699600</td>\n",
       "      <td>3.6579999923706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.425000190734860</td>\n",
       "      <td>3.0810000896453900</td>\n",
       "      <td>2.559000015258790</td>\n",
       "      <td>1.350000023841860</td>\n",
       "      <td>2.497999906539920</td>\n",
       "      <td>1.156999945640560</td>\n",
       "      <td>3.6579999923706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-1.6740000247955300</td>\n",
       "      <td>3.5499999523162800</td>\n",
       "      <td>-5.614999771118160</td>\n",
       "      <td>2.131999969482420</td>\n",
       "      <td>3.4719998836517300</td>\n",
       "      <td>1.5230000019073500</td>\n",
       "      <td>10.904000282287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>-5.492000102996830</td>\n",
       "      <td>4.287000179290770</td>\n",
       "      <td>-9.131999969482420</td>\n",
       "      <td>2.2739999294281000</td>\n",
       "      <td>3.532999992370610</td>\n",
       "      <td>1.6749999523162800</td>\n",
       "      <td>11.043999671936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2.812999963760380</td>\n",
       "      <td>3.818000078201290</td>\n",
       "      <td>-0.8169999718666080</td>\n",
       "      <td>2.0969998836517300</td>\n",
       "      <td>3.7160000801086400</td>\n",
       "      <td>1.5230000019073500</td>\n",
       "      <td>10.270999908447300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>9.243000030517580</td>\n",
       "      <td>3.818000078201290</td>\n",
       "      <td>5.4720001220703100</td>\n",
       "      <td>2.0969998836517300</td>\n",
       "      <td>3.6549999713897700</td>\n",
       "      <td>1.4320000410080000</td>\n",
       "      <td>9.777999877929690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>10.11400032043460</td>\n",
       "      <td>3.5499999523162800</td>\n",
       "      <td>6.183000087738040</td>\n",
       "      <td>1.5640000104904200</td>\n",
       "      <td>3.7160000801086400</td>\n",
       "      <td>1.462000012397770</td>\n",
       "      <td>9.56700038909912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    HUFL                HULL                 MUFL  \\\n",
       "0      6.831999778747560   3.617000102996830     4.76200008392334   \n",
       "1      5.357999801635740    3.95199990272522     2.45199990272522   \n",
       "2      5.692999839782720  3.3489999771118200    2.131999969482420   \n",
       "3      5.223999977111820  2.1429998874664300   2.4159998893737800   \n",
       "4      5.425000190734860  3.0810000896453900    2.559000015258790   \n",
       "..                   ...                 ...                  ...   \n",
       "426  -1.6740000247955300  3.5499999523162800   -5.614999771118160   \n",
       "427   -5.492000102996830   4.287000179290770   -9.131999969482420   \n",
       "428    2.812999963760380   3.818000078201290  -0.8169999718666080   \n",
       "429    9.243000030517580   3.818000078201290   5.4720001220703100   \n",
       "430    10.11400032043460  3.5499999523162800    6.183000087738040   \n",
       "\n",
       "                   MULL                LUFL                LULL  \\\n",
       "0    1.9539999961853000   2.497999906539920  1.1269999742507900   \n",
       "1    2.0969998836517300   2.924000024795530   1.371000051498410   \n",
       "2    1.9900000095367400    3.13700008392334  1.4919999837875400   \n",
       "3    1.1019999980926500  2.4670000076293900  1.2489999532699600   \n",
       "4     1.350000023841860   2.497999906539920   1.156999945640560   \n",
       "..                  ...                 ...                 ...   \n",
       "426   2.131999969482420  3.4719998836517300  1.5230000019073500   \n",
       "427  2.2739999294281000   3.532999992370610  1.6749999523162800   \n",
       "428  2.0969998836517300  3.7160000801086400  1.5230000019073500   \n",
       "429  2.0969998836517300  3.6549999713897700  1.4320000410080000   \n",
       "430  1.5640000104904200  3.7160000801086400   1.462000012397770   \n",
       "\n",
       "                     OT  \n",
       "0     6.683000087738040  \n",
       "1     6.401999950408940  \n",
       "2     6.752999782562260  \n",
       "3    3.6579999923706100  \n",
       "4    3.6579999923706100  \n",
       "..                  ...  \n",
       "426  10.904000282287600  \n",
       "427  11.043999671936000  \n",
       "428  10.270999908447300  \n",
       "429   9.777999877929690  \n",
       "430    9.56700038909912  \n",
       "\n",
       "[431 rows x 7 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "afb1415b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-03dabeeb5017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/timeseries_practise/Informer2020/utils/tools.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         ret = um.true_divide(\n\u001b[0;32m--> 163\u001b[0;31m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../Informer2020/predict_data_re.txt\")\n",
    "\n",
    "# cols = list(df_raw.columns); cols.remove(target); cols.remove('date')\n",
    "# cols\n",
    "\n",
    "# df_raw = df_raw[['date']+cols+[target]]\n",
    "# df_raw\n",
    "\n",
    "border1 = len(df_raw)-seq_len\n",
    "border2 = len(df_raw)\n",
    "\n",
    "cols_data = df_raw.columns[1:]\n",
    "df_data = df_raw[cols_data]\n",
    "\n",
    "scaler.fit(df_data.values)\n",
    "data = scaler.transform(df_data.values)\n",
    "\n",
    "tmp_stamp = df_raw[['date']][border1:border2]\n",
    "\n",
    "tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "\n",
    "pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=pred_len+1, freq=freq)\n",
    "\n",
    "df_stamp = pd.DataFrame(columns = ['date'])\n",
    "df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
    "data_stamp = time_features(df_stamp, timeenc=timeenc, freq=freq[-1:])\n",
    "\n",
    "data_x = data[border1:border2]\n",
    "data_y = data[border1:border2]\n",
    "data_stamp = data_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dba1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_begin = 0\n",
    "s_end = s_begin + seq_len\n",
    "r_begin = s_end - label_len\n",
    "r_end = r_begin + label_len + pred_len\n",
    "\n",
    "seq_x = data_x[s_begin:s_end]\n",
    "\n",
    "seq_y = data_y[r_begin:r_begin+label_len]\n",
    "seq_x_mark = data_stamp[s_begin:s_end]\n",
    "seq_y_mark = data_stamp[r_begin:r_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c98683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879f283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='../model/results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/training_config.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249d5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = np.load(config_file, allow_pickle=True)\n",
    "args = config.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d93224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_one_batch(dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark, model):\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "    # decoder input\n",
    "    if args.padding==0:\n",
    "        dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "    elif args.padding==1:\n",
    "        dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float().to(device)\n",
    "    # encoder - decoder\n",
    "    if args.use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if args.output_attention:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    else:\n",
    "        if args.output_attention:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "        else:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    if args.inverse:\n",
    "        outputs = dataset_object.inverse_transform(outputs)\n",
    "    f_dim = -1 if args.features=='MS' else 0\n",
    "    batch_y = batch_y[:,-args.pred_len:,f_dim:].to(device)\n",
    "\n",
    "    return outputs, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec394355",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='../model/'\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b870ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informer Model loaded\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'informer':Informer,\n",
    "    'informerstack':InformerStack,\n",
    "}\n",
    "\n",
    "if args.model=='informer' or args.model=='informerstack':\n",
    "    e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "    model = model_dict[args.model](\n",
    "        args.enc_in,\n",
    "        args.dec_in, \n",
    "        args.c_out, \n",
    "        args.seq_len, \n",
    "        args.label_len,\n",
    "        args.pred_len, \n",
    "        args.factor,\n",
    "        args.d_model, \n",
    "        args.n_heads, \n",
    "        e_layers, # self.args.e_layers,\n",
    "        args.d_layers, \n",
    "        args.d_ff,\n",
    "        args.dropout, \n",
    "        args.attn,\n",
    "        args.embed,\n",
    "        args.freq,\n",
    "        args.activation,\n",
    "        args.output_attention,\n",
    "        args.distil,\n",
    "        args.mix,\n",
    "        device\n",
    "    ).float()\n",
    "\n",
    "# with open(os.path.join(model_dir, args.setting, \"checkpoint.pth\"), 'rb') as f:\n",
    "#     model.load_state_dict(torch.load(f))\n",
    "\n",
    "print(\"Informer Model loaded\")\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19353949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'ETTh1':Dataset_ETT_hour,\n",
    "    'ETTh2':Dataset_ETT_hour,\n",
    "    'ETTm1':Dataset_ETT_minute,\n",
    "    'ETTm2':Dataset_ETT_minute,\n",
    "    'WTH':Dataset_Custom,\n",
    "    'ECL':Dataset_Custom,\n",
    "    'Solar':Dataset_Custom,\n",
    "    'custom':Dataset_Custom,\n",
    "}\n",
    "Data = data_dict[args.data]\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "Data = Dataset_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72d41d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Dataset_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb8fe924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT\\n'], dtype='object')\n",
      "self.target : OT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_data = Data(\n",
    "    root_path=\"./\",\n",
    "    data_path=\"../Informer2020/predict_test.csv\",\n",
    "    flag=\"pred\",\n",
    "    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    features=args.features,\n",
    "    target=\"OT\\n\",\n",
    "    inverse=args.inverse,\n",
    "    timeenc=timeenc,\n",
    "    freq=freq,\n",
    "    cols=args.cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64edd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loader = DataLoader(\n",
    "    pred_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    sampler=None,\n",
    "    drop_last=drop_last)      \n",
    "\n",
    "#     pred_data = res['data_set']\n",
    "#     pred_loader = res['data_loader']\n",
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf1ffedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_begin.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7d0d4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark, r_begin) in enumerate(pred_loader):\n",
    "    print(batch_x.shape,batch_y.shape,batch_x_mark.shape,batch_y_mark.shape,r_begin)\n",
    "    pred, true = _process_one_batch(\n",
    "        pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark, model)\n",
    "    \n",
    "    pred = pred_data.scaler.inverse_transform(pred)\n",
    "#     true = pred_data.scaler.inverse_transform(true)\n",
    "    preds.append(pred.detach().cpu().numpy())\n",
    "#     trues.append(true.detach().cpu().numpy())\n",
    "    if i == 0:\n",
    "        start_point = r_begin.item()\n",
    "\n",
    "    end_point = r_begin.item()+pred_data.label_len\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])    \n",
    "\n",
    "prediction = preds[0,:,-1]\n",
    "\n",
    "# trues = np.array(trues)\n",
    "# trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])    \n",
    "\n",
    "# gt = trues[0,:,-1]\n",
    "\n",
    "pred_timestamp = pred_data.df_stamp\n",
    "pred_prediction = pred_data.prediction_data\n",
    "\n",
    "pred_dataset = pd.concat([pred_timestamp, pred_prediction], axis=1)\n",
    "pred_dataset = pred_dataset.reset_index()\n",
    "pred_dataset.drop('index', axis=1, inplace=True)\n",
    "\n",
    "start=pred_dataset.shape[0]-args.pred_len\n",
    "pred_result=pred_dataset.loc[start:].reset_index()\n",
    "final_result = pd.concat([pred_result, pd.DataFrame(prediction, columns=['Prediction'])], axis=1)\n",
    "final_result.drop('index', axis=1, inplace=True)\n",
    "\n",
    "final_result.to_csv(\"./prediciton_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7e631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256acd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d86e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c01216fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "535d067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'ETTh1':Dataset_ETT_hour,\n",
    "    'ETTh2':Dataset_ETT_hour,\n",
    "    'ETTm1':Dataset_ETT_minute,\n",
    "    'ETTm2':Dataset_ETT_minute,\n",
    "    'WTH':Dataset_Custom,\n",
    "    'ECL':Dataset_Custom,\n",
    "    'Solar':Dataset_Custom,\n",
    "    'custom':Dataset_Custom,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7de1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa5f9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../Informer2020/predict_test.csv\")\n",
    "args.target='OT\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06ab1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cols:\n",
    "    cols=args.cols.copy()\n",
    "    cols.remove(args.target)\n",
    "else:\n",
    "    cols = list(df_raw.columns); cols.remove(args.target); cols.remove('date')\n",
    "df_raw = df_raw[['date']+cols+[args.target]]\n",
    "\n",
    "border1 = len(df_raw)-args.seq_len\n",
    "border2 = len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b726e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.features=='M' or args.features=='MS':\n",
    "    cols_data = df_raw.columns[1:]\n",
    "    df_data = df_raw[cols_data]\n",
    "elif args.features=='S':\n",
    "    df_data = df_raw[[args.target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7753d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85456813",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_stamp = df_raw[['date']][border1:border2]\n",
    "tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=args.pred_len+1, freq=args.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bc3df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stamp = pd.DataFrame(columns = ['date'])\n",
    "df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
    "data_stamp = time_features(df_stamp, timeenc=timeenc, freq=freq[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c95b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 7), (96, 7))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaed6b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 24)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.label_len, args.pred_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5020da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd5f6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_begin = index\n",
    "s_end = s_begin + args.seq_len\n",
    "r_begin = s_end - args.label_len\n",
    "r_end = r_begin + args.label_len + args.pred_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65ba8628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 96, 48, 120)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_begin, s_end, r_begin, r_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4136d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_x = data_x[s_begin:s_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31944f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_x = data_x[s_begin:s_end]\n",
    "if args.inverse:\n",
    "    seq_y = data_x[r_begin:r_begin+args.label_len]\n",
    "\n",
    "else:\n",
    "    seq_y = data_y[r_begin:r_begin+args.label_len]\n",
    "\n",
    "seq_x_mark = data_stamp[s_begin:s_end]\n",
    "seq_y_mark = data_stamp[r_begin:r_end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1474cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark,r_begin) in enumerate(pred_loader):\n",
    "    pred, true = _process_one_batch(\n",
    "        pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark, model)\n",
    "    if i == 0:\n",
    "        start_point = r_begin.item()\n",
    "\n",
    "    end_point = r_begin.item()+pred_data.label_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a67d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-06-22 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-06-22 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-06-22 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-06-22 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-06-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-06-26 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2018-06-26 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2018-06-26 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-06-26 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date\n",
       "11  2018-06-22 20:00:00\n",
       "12  2018-06-22 21:00:00\n",
       "13  2018-06-22 22:00:00\n",
       "14  2018-06-22 23:00:00\n",
       "15  2018-06-23 00:00:00\n",
       "..                  ...\n",
       "102 2018-06-26 15:00:00\n",
       "103 2018-06-26 16:00:00\n",
       "104 2018-06-26 17:00:00\n",
       "105 2018-06-26 18:00:00\n",
       "106 2018-06-26 19:00:00\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd696364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-06-22 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-06-22 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-06-22 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-06-22 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-06-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-06-26 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2018-06-26 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2018-06-26 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-06-26 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date\n",
       "11  2018-06-22 20:00:00\n",
       "12  2018-06-22 21:00:00\n",
       "13  2018-06-22 22:00:00\n",
       "14  2018-06-22 23:00:00\n",
       "15  2018-06-23 00:00:00\n",
       "..                  ...\n",
       "102 2018-06-26 15:00:00\n",
       "103 2018-06-26 16:00:00\n",
       "104 2018-06-26 17:00:00\n",
       "105 2018-06-26 18:00:00\n",
       "106 2018-06-26 19:00:00\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31098b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-22 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-22 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-22 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-22 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-23 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2018-06-27 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2018-06-27 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2018-06-27 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2018-06-27 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2018-06-27 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  HUFL  HULL  MUFL  MULL  LUFL  LULL  OT\\n\n",
       "0   2018-06-22 20:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "1   2018-06-22 21:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "2   2018-06-22 22:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "3   2018-06-22 23:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "4   2018-06-23 00:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "..                  ...   ...   ...   ...   ...   ...   ...   ...\n",
       "115 2018-06-27 15:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "116 2018-06-27 16:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "117 2018-06-27 17:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "118 2018-06-27 18:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "119 2018-06-27 19:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "\n",
       "[120 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pred_data.df_stamp,pred_data.prediction_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be637ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e7af21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_timestamp = pred_data.df_stamp[start_point:end_point]['date']\n",
    "pred_timestamp = pred_timestamp.reset_index()['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17e75ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_y_df=pd.DataFrame(pred_data.data_x[start_point:end_point], columns=pred_data.cols+[pred_data.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca871e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array=pd.concat([pred_timestamp,seq_y_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f278853",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-e94a466e068d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "preds = np.array(preds)\n",
    "preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])    \n",
    "\n",
    "prediction = preds[0,:,-1]\n",
    "\n",
    "print(f\"prediction : {prediction}\")\n",
    "\n",
    "# f = open(\"informer_result.csv\", 'a')\n",
    "# f.write(data_dir)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9830726b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-d33f74140b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7749\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7750\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7751\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7752\u001b[0m         )\n\u001b[1;32m   7753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 )\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "pred_data.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcfcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'informer':Informer,\n",
    "    'informerstack':InformerStack,\n",
    "}\n",
    "\n",
    "if args.model=='informer' or args.model=='informerstack':\n",
    "    e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "    model = model_dict[args.model](\n",
    "        args.enc_in,\n",
    "        args.dec_in, \n",
    "        args.c_out, \n",
    "        args.seq_len, \n",
    "        args.label_len,\n",
    "        args.pred_len, \n",
    "        args.factor,\n",
    "        args.d_model, \n",
    "        args.n_heads, \n",
    "        e_layers, # self.args.e_layers,\n",
    "        args.d_layers, \n",
    "        args.d_ff,\n",
    "        args.dropout, \n",
    "        args.attn,\n",
    "        args.embed,\n",
    "        args.freq,\n",
    "        args.activation,\n",
    "        args.output_attention,\n",
    "        args.distil,\n",
    "        args.mix,\n",
    "    ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./utils/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bf451",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, dirs, files) in os.walk(path):\n",
    "    print(f\"root : {root}, dir : {dirs}, files : {files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bc46790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='../model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1e9bd997",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.setting='informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b08eb895",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='../model/results/informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtFalse_mxFalse_exp_0/training_config.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "96f6c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = np.load(config_file, allow_pickle=True)\n",
    "args = config.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8070958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_one_batch(dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "    device = 'cpu'\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "    # decoder input\n",
    "    if args.padding==0:\n",
    "        dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "    elif self.args.padding==1:\n",
    "        dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float().to(device)\n",
    "    # encoder - decoder\n",
    "    if args.use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if args.output_attention:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    else:\n",
    "        if args.output_attention:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "        else:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    if args.inverse:\n",
    "        outputs = dataset_object.inverse_transform(outputs)\n",
    "    f_dim = -1 if args.features=='MS' else 0\n",
    "    batch_y = batch_y[:,-args.pred_len:,f_dim:].to(device)\n",
    "\n",
    "    return outputs, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1bee87ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Informer:\n\tMissing key(s) in state_dict: \"enc_embedding.value_embedding.tokenConv.weight\", \"enc_embedding.value_embedding.tokenConv.bias\", \"enc_embedding.position_embedding.pe\", \"enc_embedding.temporal_embedding.embed.weight\", \"enc_embedding.temporal_embedding.embed.bias\", \"dec_embedding.value_embedding.tokenConv.weight\", \"dec_embedding.value_embedding.tokenConv.bias\", \"dec_embedding.position_embedding.pe\", \"dec_embedding.temporal_embedding.embed.weight\", \"dec_embedding.temporal_embedding.embed.bias\", \"encoder.attn_layers.0.attention.query_projection.weight\", \"encoder.attn_layers.0.attention.query_projection.bias\", \"encoder.attn_layers.0.attention.key_projection.weight\", \"encoder.attn_layers.0.attention.key_projection.bias\", \"encoder.attn_layers.0.attention.value_projection.weight\", \"encoder.attn_layers.0.attention.value_projection.bias\", \"encoder.attn_layers.0.attention.out_projection.weight\", \"encoder.attn_layers.0.attention.out_projection.bias\", \"encoder.attn_layers.0.conv1.weight\", \"encoder.attn_layers.0.conv1.bias\", \"encoder.attn_layers.0.conv2.weight\", \"encoder.attn_layers.0.conv2.bias\", \"encoder.attn_layers.0.norm1.weight\", \"encoder.attn_layers.0.norm1.bias\", \"encoder.attn_layers.0.norm2.weight\", \"encoder.attn_layers.0.norm2.bias\", \"encoder.attn_layers.1.attention.query_projection.weight\", \"encoder.attn_layers.1.attention.query_projection.bias\", \"encoder.attn_layers.1.attention.key_projection.weight\", \"encoder.attn_layers.1.attention.key_projection.bias\", \"encoder.attn_layers.1.attention.value_projection.weight\", \"encoder.attn_layers.1.attention.value_projection.bias\", \"encoder.attn_layers.1.attention.out_projection.weight\", \"encoder.attn_layers.1.attention.out_projection.bias\", \"encoder.attn_layers.1.conv1.weight\", \"encoder.attn_layers.1.conv1.bias\", \"encoder.attn_layers.1.conv2.weight\", \"encoder.attn_layers.1.conv2.bias\", \"encoder.attn_layers.1.norm1.weight\", \"encoder.attn_layers.1.norm1.bias\", \"encoder.attn_layers.1.norm2.weight\", \"encoder.attn_layers.1.norm2.bias\", \"encoder.norm.weight\", \"encoder.norm.bias\", \"decoder.layers.0.self_attention.query_projection.weight\", \"decoder.layers.0.self_attention.query_projection.bias\", \"decoder.layers.0.self_attention.key_projection.weight\", \"decoder.layers.0.self_attention.key_projection.bias\", \"decoder.layers.0.self_attention.value_projection.weight\", \"decoder.layers.0.self_attention.value_projection.bias\", \"decoder.layers.0.self_attention.out_projection.weight\", \"decoder.layers.0.self_attention.out_projection.bias\", \"decoder.layers.0.cross_attention.query_projection.weight\", \"decoder.layers.0.cross_attention.query_projection.bias\", \"decoder.layers.0.cross_attention.key_projection.weight\", \"decoder.layers.0.cross_attention.key_projection.bias\", \"decoder.layers.0.cross_attention.value_projection.weight\", \"decoder.layers.0.cross_attention.value_projection.bias\", \"decoder.layers.0.cross_attention.out_projection.weight\", \"decoder.layers.0.cross_attention.out_projection.bias\", \"decoder.layers.0.conv1.weight\", \"decoder.layers.0.conv1.bias\", \"decoder.layers.0.conv2.weight\", \"decoder.layers.0.conv2.bias\", \"decoder.layers.0.norm1.weight\", \"decoder.layers.0.norm1.bias\", \"decoder.layers.0.norm2.weight\", \"decoder.layers.0.norm2.bias\", \"decoder.layers.0.norm3.weight\", \"decoder.layers.0.norm3.bias\", \"decoder.norm.weight\", \"decoder.norm.bias\", \"projection.weight\", \"projection.bias\". \n\tUnexpected key(s) in state_dict: \"module.enc_embedding.value_embedding.tokenConv.weight\", \"module.enc_embedding.value_embedding.tokenConv.bias\", \"module.enc_embedding.position_embedding.pe\", \"module.enc_embedding.temporal_embedding.embed.weight\", \"module.enc_embedding.temporal_embedding.embed.bias\", \"module.dec_embedding.value_embedding.tokenConv.weight\", \"module.dec_embedding.value_embedding.tokenConv.bias\", \"module.dec_embedding.position_embedding.pe\", \"module.dec_embedding.temporal_embedding.embed.weight\", \"module.dec_embedding.temporal_embedding.embed.bias\", \"module.encoder.attn_layers.0.attention.query_projection.weight\", \"module.encoder.attn_layers.0.attention.query_projection.bias\", \"module.encoder.attn_layers.0.attention.key_projection.weight\", \"module.encoder.attn_layers.0.attention.key_projection.bias\", \"module.encoder.attn_layers.0.attention.value_projection.weight\", \"module.encoder.attn_layers.0.attention.value_projection.bias\", \"module.encoder.attn_layers.0.attention.out_projection.weight\", \"module.encoder.attn_layers.0.attention.out_projection.bias\", \"module.encoder.attn_layers.0.conv1.weight\", \"module.encoder.attn_layers.0.conv1.bias\", \"module.encoder.attn_layers.0.conv2.weight\", \"module.encoder.attn_layers.0.conv2.bias\", \"module.encoder.attn_layers.0.norm1.weight\", \"module.encoder.attn_layers.0.norm1.bias\", \"module.encoder.attn_layers.0.norm2.weight\", \"module.encoder.attn_layers.0.norm2.bias\", \"module.encoder.attn_layers.1.attention.query_projection.weight\", \"module.encoder.attn_layers.1.attention.query_projection.bias\", \"module.encoder.attn_layers.1.attention.key_projection.weight\", \"module.encoder.attn_layers.1.attention.key_projection.bias\", \"module.encoder.attn_layers.1.attention.value_projection.weight\", \"module.encoder.attn_layers.1.attention.value_projection.bias\", \"module.encoder.attn_layers.1.attention.out_projection.weight\", \"module.encoder.attn_layers.1.attention.out_projection.bias\", \"module.encoder.attn_layers.1.conv1.weight\", \"module.encoder.attn_layers.1.conv1.bias\", \"module.encoder.attn_layers.1.conv2.weight\", \"module.encoder.attn_layers.1.conv2.bias\", \"module.encoder.attn_layers.1.norm1.weight\", \"module.encoder.attn_layers.1.norm1.bias\", \"module.encoder.attn_layers.1.norm2.weight\", \"module.encoder.attn_layers.1.norm2.bias\", \"module.encoder.norm.weight\", \"module.encoder.norm.bias\", \"module.decoder.layers.0.self_attention.query_projection.weight\", \"module.decoder.layers.0.self_attention.query_projection.bias\", \"module.decoder.layers.0.self_attention.key_projection.weight\", \"module.decoder.layers.0.self_attention.key_projection.bias\", \"module.decoder.layers.0.self_attention.value_projection.weight\", \"module.decoder.layers.0.self_attention.value_projection.bias\", \"module.decoder.layers.0.self_attention.out_projection.weight\", \"module.decoder.layers.0.self_attention.out_projection.bias\", \"module.decoder.layers.0.cross_attention.query_projection.weight\", \"module.decoder.layers.0.cross_attention.query_projection.bias\", \"module.decoder.layers.0.cross_attention.key_projection.weight\", \"module.decoder.layers.0.cross_attention.key_projection.bias\", \"module.decoder.layers.0.cross_attention.value_projection.weight\", \"module.decoder.layers.0.cross_attention.value_projection.bias\", \"module.decoder.layers.0.cross_attention.out_projection.weight\", \"module.decoder.layers.0.cross_attention.out_projection.bias\", \"module.decoder.layers.0.conv1.weight\", \"module.decoder.layers.0.conv1.bias\", \"module.decoder.layers.0.conv2.weight\", \"module.decoder.layers.0.conv2.bias\", \"module.decoder.layers.0.norm1.weight\", \"module.decoder.layers.0.norm1.bias\", \"module.decoder.layers.0.norm2.weight\", \"module.decoder.layers.0.norm2.bias\", \"module.decoder.layers.0.norm3.weight\", \"module.decoder.layers.0.norm3.bias\", \"module.decoder.norm.weight\", \"module.decoder.norm.bias\", \"module.projection.weight\", \"module.projection.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-34d2a889f61d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"checkpoint.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Net loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Informer:\n\tMissing key(s) in state_dict: \"enc_embedding.value_embedding.tokenConv.weight\", \"enc_embedding.value_embedding.tokenConv.bias\", \"enc_embedding.position_embedding.pe\", \"enc_embedding.temporal_embedding.embed.weight\", \"enc_embedding.temporal_embedding.embed.bias\", \"dec_embedding.value_embedding.tokenConv.weight\", \"dec_embedding.value_embedding.tokenConv.bias\", \"dec_embedding.position_embedding.pe\", \"dec_embedding.temporal_embedding.embed.weight\", \"dec_embedding.temporal_embedding.embed.bias\", \"encoder.attn_layers.0.attention.query_projection.weight\", \"encoder.attn_layers.0.attention.query_projection.bias\", \"encoder.attn_layers.0.attention.key_projection.weight\", \"encoder.attn_layers.0.attention.key_projection.bias\", \"encoder.attn_layers.0.attention.value_projection.weight\", \"encoder.attn_layers.0.attention.value_projection.bias\", \"encoder.attn_layers.0.attention.out_projection.weight\", \"encoder.attn_layers.0.attention.out_projection.bias\", \"encoder.attn_layers.0.conv1.weight\", \"encoder.attn_layers.0.conv1.bias\", \"encoder.attn_layers.0.conv2.weight\", \"encoder.attn_layers.0.conv2.bias\", \"encoder.attn_layers.0.norm1.weight\", \"encoder.attn_layers.0.norm1.bias\", \"encoder.attn_layers.0.norm2.weight\", \"encoder.attn_layers.0.norm2.bias\", \"encoder.attn_layers.1.attention.query_projection.weight\", \"encoder.attn_layers.1.attention.query_projection.bias\", \"encoder.attn_layers.1.attention.key_projection.weight\", \"encoder.attn_layers.1.attention.key_projection.bias\", \"encoder.attn_layers.1.attention.value_projection.weight\", \"encoder.attn_layers.1.attention.value_projection.bias\", \"encoder.attn_layers.1.attention.out_projection.weight\", \"encoder.attn_layers.1.attention.out_projection.bias\", \"encoder.attn_layers.1.conv1.weight\", \"encoder.attn_layers.1.conv1.bias\", \"encoder.attn_layers.1.conv2.weight\", \"encoder.attn_layers.1.conv2.bias\", \"encoder.attn_layers.1.norm1.weight\", \"encoder.attn_layers.1.norm1.bias\", \"encoder.attn_layers.1.norm2.weight\", \"encoder.attn_layers.1.norm2.bias\", \"encoder.norm.weight\", \"encoder.norm.bias\", \"decoder.layers.0.self_attention.query_projection.weight\", \"decoder.layers.0.self_attention.query_projection.bias\", \"decoder.layers.0.self_attention.key_projection.weight\", \"decoder.layers.0.self_attention.key_projection.bias\", \"decoder.layers.0.self_attention.value_projection.weight\", \"decoder.layers.0.self_attention.value_projection.bias\", \"decoder.layers.0.self_attention.out_projection.weight\", \"decoder.layers.0.self_attention.out_projection.bias\", \"decoder.layers.0.cross_attention.query_projection.weight\", \"decoder.layers.0.cross_attention.query_projection.bias\", \"decoder.layers.0.cross_attention.key_projection.weight\", \"decoder.layers.0.cross_attention.key_projection.bias\", \"decoder.layers.0.cross_attention.value_projection.weight\", \"decoder.layers.0.cross_attention.value_projection.bias\", \"decoder.layers.0.cross_attention.out_projection.weight\", \"decoder.layers.0.cross_attention.out_projection.bias\", \"decoder.layers.0.conv1.weight\", \"decoder.layers.0.conv1.bias\", \"decoder.layers.0.conv2.weight\", \"decoder.layers.0.conv2.bias\", \"decoder.layers.0.norm1.weight\", \"decoder.layers.0.norm1.bias\", \"decoder.layers.0.norm2.weight\", \"decoder.layers.0.norm2.bias\", \"decoder.layers.0.norm3.weight\", \"decoder.layers.0.norm3.bias\", \"decoder.norm.weight\", \"decoder.norm.bias\", \"projection.weight\", \"projection.bias\". \n\tUnexpected key(s) in state_dict: \"module.enc_embedding.value_embedding.tokenConv.weight\", \"module.enc_embedding.value_embedding.tokenConv.bias\", \"module.enc_embedding.position_embedding.pe\", \"module.enc_embedding.temporal_embedding.embed.weight\", \"module.enc_embedding.temporal_embedding.embed.bias\", \"module.dec_embedding.value_embedding.tokenConv.weight\", \"module.dec_embedding.value_embedding.tokenConv.bias\", \"module.dec_embedding.position_embedding.pe\", \"module.dec_embedding.temporal_embedding.embed.weight\", \"module.dec_embedding.temporal_embedding.embed.bias\", \"module.encoder.attn_layers.0.attention.query_projection.weight\", \"module.encoder.attn_layers.0.attention.query_projection.bias\", \"module.encoder.attn_layers.0.attention.key_projection.weight\", \"module.encoder.attn_layers.0.attention.key_projection.bias\", \"module.encoder.attn_layers.0.attention.value_projection.weight\", \"module.encoder.attn_layers.0.attention.value_projection.bias\", \"module.encoder.attn_layers.0.attention.out_projection.weight\", \"module.encoder.attn_layers.0.attention.out_projection.bias\", \"module.encoder.attn_layers.0.conv1.weight\", \"module.encoder.attn_layers.0.conv1.bias\", \"module.encoder.attn_layers.0.conv2.weight\", \"module.encoder.attn_layers.0.conv2.bias\", \"module.encoder.attn_layers.0.norm1.weight\", \"module.encoder.attn_layers.0.norm1.bias\", \"module.encoder.attn_layers.0.norm2.weight\", \"module.encoder.attn_layers.0.norm2.bias\", \"module.encoder.attn_layers.1.attention.query_projection.weight\", \"module.encoder.attn_layers.1.attention.query_projection.bias\", \"module.encoder.attn_layers.1.attention.key_projection.weight\", \"module.encoder.attn_layers.1.attention.key_projection.bias\", \"module.encoder.attn_layers.1.attention.value_projection.weight\", \"module.encoder.attn_layers.1.attention.value_projection.bias\", \"module.encoder.attn_layers.1.attention.out_projection.weight\", \"module.encoder.attn_layers.1.attention.out_projection.bias\", \"module.encoder.attn_layers.1.conv1.weight\", \"module.encoder.attn_layers.1.conv1.bias\", \"module.encoder.attn_layers.1.conv2.weight\", \"module.encoder.attn_layers.1.conv2.bias\", \"module.encoder.attn_layers.1.norm1.weight\", \"module.encoder.attn_layers.1.norm1.bias\", \"module.encoder.attn_layers.1.norm2.weight\", \"module.encoder.attn_layers.1.norm2.bias\", \"module.encoder.norm.weight\", \"module.encoder.norm.bias\", \"module.decoder.layers.0.self_attention.query_projection.weight\", \"module.decoder.layers.0.self_attention.query_projection.bias\", \"module.decoder.layers.0.self_attention.key_projection.weight\", \"module.decoder.layers.0.self_attention.key_projection.bias\", \"module.decoder.layers.0.self_attention.value_projection.weight\", \"module.decoder.layers.0.self_attention.value_projection.bias\", \"module.decoder.layers.0.self_attention.out_projection.weight\", \"module.decoder.layers.0.self_attention.out_projection.bias\", \"module.decoder.layers.0.cross_attention.query_projection.weight\", \"module.decoder.layers.0.cross_attention.query_projection.bias\", \"module.decoder.layers.0.cross_attention.key_projection.weight\", \"module.decoder.layers.0.cross_attention.key_projection.bias\", \"module.decoder.layers.0.cross_attention.value_projection.weight\", \"module.decoder.layers.0.cross_attention.value_projection.bias\", \"module.decoder.layers.0.cross_attention.out_projection.weight\", \"module.decoder.layers.0.cross_attention.out_projection.bias\", \"module.decoder.layers.0.conv1.weight\", \"module.decoder.layers.0.conv1.bias\", \"module.decoder.layers.0.conv2.weight\", \"module.decoder.layers.0.conv2.bias\", \"module.decoder.layers.0.norm1.weight\", \"module.decoder.layers.0.norm1.bias\", \"module.decoder.layers.0.norm2.weight\", \"module.decoder.layers.0.norm2.bias\", \"module.decoder.layers.0.norm3.weight\", \"module.decoder.layers.0.norm3.bias\", \"module.decoder.norm.weight\", \"module.decoder.norm.bias\", \"module.projection.weight\", \"module.projection.bias\". "
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'informer':Informer,\n",
    "    'informerstack':InformerStack,\n",
    "}\n",
    "\n",
    "if args.model=='informer' or args.model=='informerstack':\n",
    "    e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "    model = model_dict[args.model](\n",
    "        args.enc_in,\n",
    "        args.dec_in, \n",
    "        args.c_out, \n",
    "        args.seq_len, \n",
    "        args.label_len,\n",
    "        args.pred_len, \n",
    "        args.factor,\n",
    "        args.d_model, \n",
    "        args.n_heads, \n",
    "        e_layers, # self.args.e_layers,\n",
    "        args.d_layers, \n",
    "        args.d_ff,\n",
    "        args.dropout, \n",
    "        args.attn,\n",
    "        args.embed,\n",
    "        args.freq,\n",
    "        args.activation,\n",
    "        args.output_attention,\n",
    "        args.distil,\n",
    "        args.mix,\n",
    "    ).float()\n",
    "\n",
    "with open(os.path.join(model_dir, args.setting, \"checkpoint.pth\"), 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "\n",
    "print(\"Net loaded\")\n",
    "model.eval()\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2fd709d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a0ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../ETDataset/ETT-small/ETTh1_small.csv',skiprows=1 )\n",
    "target=\"OT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fe42609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-22 10:00:00</td>\n",
       "      <td>5.358</td>\n",
       "      <td>3.952</td>\n",
       "      <td>2.452</td>\n",
       "      <td>2.097</td>\n",
       "      <td>2.924</td>\n",
       "      <td>1.371</td>\n",
       "      <td>6.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-22 11:00:00</td>\n",
       "      <td>5.693</td>\n",
       "      <td>3.349</td>\n",
       "      <td>2.132</td>\n",
       "      <td>1.990</td>\n",
       "      <td>3.137</td>\n",
       "      <td>1.492</td>\n",
       "      <td>6.753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL     OT\n",
       "0  2018-06-22 10:00:00  5.358  3.952  2.452  2.097  2.924  1.371  6.402\n",
       "1  2018-06-22 11:00:00  5.693  3.349  2.132  1.990  3.137  1.492  6.753"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d48f04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['date','HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4ca962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns=header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c06a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145fb1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_raw.columns : Index(['date', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')\n",
      "self.target : OT\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_raw.columns : {df_raw.columns}\")\n",
    "print(f\"self.target : {target}\")\n",
    "cols = list(df_raw.columns); cols.remove(target); cols.remove('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c5f5484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n"
     ]
    }
   ],
   "source": [
    "if None:\n",
    "    print(\"t\")\n",
    "else:\n",
    "    print('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac9df663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-22 11:00:00</td>\n",
       "      <td>5.693</td>\n",
       "      <td>3.349</td>\n",
       "      <td>2.132</td>\n",
       "      <td>1.990</td>\n",
       "      <td>3.137</td>\n",
       "      <td>1.492</td>\n",
       "      <td>6.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-22 12:00:00</td>\n",
       "      <td>5.224</td>\n",
       "      <td>2.143</td>\n",
       "      <td>2.416</td>\n",
       "      <td>1.102</td>\n",
       "      <td>2.467</td>\n",
       "      <td>1.249</td>\n",
       "      <td>3.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-22 13:00:00</td>\n",
       "      <td>5.425</td>\n",
       "      <td>3.081</td>\n",
       "      <td>2.559</td>\n",
       "      <td>1.350</td>\n",
       "      <td>2.498</td>\n",
       "      <td>1.157</td>\n",
       "      <td>3.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-06-22 14:00:00</td>\n",
       "      <td>1.808</td>\n",
       "      <td>2.478</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>1.315</td>\n",
       "      <td>2.071</td>\n",
       "      <td>1.097</td>\n",
       "      <td>4.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-06-22 15:00:00</td>\n",
       "      <td>1.541</td>\n",
       "      <td>3.014</td>\n",
       "      <td>-0.675</td>\n",
       "      <td>0.888</td>\n",
       "      <td>2.498</td>\n",
       "      <td>1.218</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-06-26 15:00:00</td>\n",
       "      <td>-1.674</td>\n",
       "      <td>3.550</td>\n",
       "      <td>-5.615</td>\n",
       "      <td>2.132</td>\n",
       "      <td>3.472</td>\n",
       "      <td>1.523</td>\n",
       "      <td>10.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2018-06-26 16:00:00</td>\n",
       "      <td>-5.492</td>\n",
       "      <td>4.287</td>\n",
       "      <td>-9.132</td>\n",
       "      <td>2.274</td>\n",
       "      <td>3.533</td>\n",
       "      <td>1.675</td>\n",
       "      <td>11.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2018-06-26 17:00:00</td>\n",
       "      <td>2.813</td>\n",
       "      <td>3.818</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>2.097</td>\n",
       "      <td>3.716</td>\n",
       "      <td>1.523</td>\n",
       "      <td>10.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-06-26 18:00:00</td>\n",
       "      <td>9.243</td>\n",
       "      <td>3.818</td>\n",
       "      <td>5.472</td>\n",
       "      <td>2.097</td>\n",
       "      <td>3.655</td>\n",
       "      <td>1.432</td>\n",
       "      <td>9.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "      <td>10.114</td>\n",
       "      <td>3.550</td>\n",
       "      <td>6.183</td>\n",
       "      <td>1.564</td>\n",
       "      <td>3.716</td>\n",
       "      <td>1.462</td>\n",
       "      <td>9.567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date    HUFL   HULL   MUFL   MULL   LUFL   LULL      OT\n",
       "2    2018-06-22 11:00:00   5.693  3.349  2.132  1.990  3.137  1.492   6.753\n",
       "3    2018-06-22 12:00:00   5.224  2.143  2.416  1.102  2.467  1.249   3.658\n",
       "4    2018-06-22 13:00:00   5.425  3.081  2.559  1.350  2.498  1.157   3.658\n",
       "5    2018-06-22 14:00:00   1.808  2.478 -0.462  1.315  2.071  1.097   4.150\n",
       "6    2018-06-22 15:00:00   1.541  3.014 -0.675  0.888  2.498  1.218   4.643\n",
       "..                   ...     ...    ...    ...    ...    ...    ...     ...\n",
       "102  2018-06-26 15:00:00  -1.674  3.550 -5.615  2.132  3.472  1.523  10.904\n",
       "103  2018-06-26 16:00:00  -5.492  4.287 -9.132  2.274  3.533  1.675  11.044\n",
       "104  2018-06-26 17:00:00   2.813  3.818 -0.817  2.097  3.716  1.523  10.271\n",
       "105  2018-06-26 18:00:00   9.243  3.818  5.472  2.097  3.655  1.432   9.778\n",
       "106  2018-06-26 19:00:00  10.114  3.550  6.183  1.564  3.716  1.462   9.567\n",
       "\n",
       "[105 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cb7ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header=['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db55df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw[['date']+cols+[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96cdd4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_data = df_raw.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "162cfba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96484b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c474333a3d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"df_raw.columns : {df_raw.columns}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "if self.cols:\n",
    "    cols=cols.copy()\n",
    "    cols.remove(self.target)\n",
    "else:\n",
    "    print(f\"df_raw.columns : {df_raw.columns}\")\n",
    "    print(f\"self.target : {self.target}\")\n",
    "    cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n",
    "df_raw = df_raw[['date']+cols+[self.target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2031295",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_raw.columns : {df_raw.columns}\")\n",
    "print(f\"self.target : {self.target}\")\n",
    "cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
